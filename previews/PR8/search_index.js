var documenterSearchIndex = {"docs":
[{"location":"arc/#Introduction","page":"arc","title":"Introduction","text":"","category":"section"},{"location":"arc/#Purpose","page":"arc","title":"Purpose","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"The arc package uses a regularization method to find a (local) unconstrained minimizer of a differentiable objective function mathbff(x) of many variables mathbfx. The method offers the choice of direct and iterative solution of the key regularization subproblems, and is most suitable for large problems. First derivatives are required, and if second derivatives can be calculated, they will be exploited–-if the product of second derivatives with a vector may be found, but not the derivatives themselves, that may also be exploited.","category":"page"},{"location":"arc/#Authors","page":"arc","title":"Authors","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England, and M. Porcelli, University of Bologna, Italy.","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"arc/#Originally-released","page":"arc","title":"Originally released","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"May 2011, C interface August 2021.","category":"page"},{"location":"arc/#Terminology","page":"arc","title":"Terminology","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"The gradient nabla_x f(x) of f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"arc/#Method","page":"arc","title":"Method","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"An adaptive cubic regularization method is used. In this, an improvement to a current estimate of the required minimizer, x_k is sought by computing a step s_k. The step is chosen to approximately minimize a model m_k(s) of f(x_k + s) that includes a weighted term sigma_k s_k^3 for some specified positive weight sigma_k. The quality of the resulting step s_k is assessed by computing the \"ratio\" (f(x_k) - f(x_k + s_k)) (m_k(0) - m_k(s_k)). The step is deemed to have succeeded if the ratio exceeds a given eta_s  0, and in this case x_k+1 = x_k + s_k. Otherwise x_k+1 = x_k, and the weight is increased by powers of a given increase factor up to a given limit. If the ratio is larger than eta_v geq eta_d, the weight will be decreased by powers of a given decrease factor again up to a given limit. The method will terminate as soon as nabla_x f(x_k) is smaller than a specified value.","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"Either linear or quadratic models m_k(s) may be used. The former will be taken as the first two terms f(x_k) + s^T nabla_x f(x_k) of a Taylor series about x_k, while the latter uses an approximation to the first three terms f(x_k) + s^T nabla_x f(x_k) + frac12 s^T B_k s, for which B_k is a symmetric approximation to the Hessian nabla_xxf(x_k); possible approximations include the true Hessian, limited-memory secant and sparsity approximations and a scaled identity matrix. Normally a two-norm regularization will be used, but this may change if preconditioning is employed.","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"An approximate minimizer of the cubic model is found using either a direct approach involving factorization or an iterative (conjugate-gradient/Lanczos) approach based on approximations to the required solution from a so-called Krlov subspace. The direct approach is based on the knowledge that the required solution satisfies the linear system of equations (B_k + lambda_k I) s_k = - nabla_x f(x_k) involving a scalar Lagrange multiplier lambda_k. This multiplier is found by uni-variate root finding, using a safeguarded Newton-like process, by the GALAHAD packages RQS or DPS (depending on the norm chosen). The iterative approach uses the GALAHAD packag GLRT, and is best accelerated by preconditioning with good approximations to B_k using GALAHAD's PSLS. The iterative approach has the advantage that only matrix-vector products B_k v are required, and thus B_k is not required explicitly. However when factorizations of B_k are possible, the direct approach is often more efficient.","category":"page"},{"location":"arc/#References","page":"arc","title":"References","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"The generic adaptive cubic regularization method is described in detail in","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"C. Cartis, N. I. M. Gould and Ph. L. Toint, “Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results” Mathematical Programming 127(2) (2011) 245-295,","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"and uses “tricks” as suggested in","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"N. I. M. Gould, M. Porcelli and Ph. L. Toint, “Updating the regularization parameter in the adaptive cubic regularization algorithm”. Computational Optimization and Applications 53(1) (2012) 1-22.","category":"page"},{"location":"arc/#Call-order","page":"arc","title":"Call order","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"To solve a given problem, functions from the arc package must be called in the following order:","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_initialize - provide default control parameters and","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"set up initial data structures","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_read_specfile (optional) - override control values","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"by reading replacement values from a file","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_import - set up problem data structures and fixed","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"values","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_reset_control (optional) - possibly change control","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"solve the problem by calling one of\narc_solve_with_mat - solve using function calls to","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_solve_without_mat - solve using function calls to","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_information (optional) - recover information about","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"the solution and solution process","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"arc_terminate - deallocate data structures","category":"page"},{"location":"arc/#Symmetric-matrix-storage-formats","page":"arc","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"The symmetric n by n matrix H = nabla_xxf may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"Both C-style (0 based) and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"arc/","page":"arc","title":"arc","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"arc/#Dense-storage-format","page":"arc","title":"Dense storage format","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"The matrix H is stored as a compact dense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + j of the storage array Hval will hold the value H{ij}$ (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"arc/#Sparse-co-ordinate-storage-format","page":"arc","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1, are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"arc/#Sparse-row-wise-storage-format","page":"arc","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"arc/","page":"arc","title":"arc","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of the entries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"eqp/#Introduction","page":"eqp","title":"Introduction","text":"","category":"section"},{"location":"eqp/#Purpose","page":"eqp","title":"Purpose","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"This package uses an iterative method to solve the equality-constrained quadratic programming problem mboxminimize q(x) = frac12 x^T H x + g^T x + f  n minimize q(x) = 12 x^T H x + g^T x + f n subject to the linear constraints (1)  A x + c = 0 where the n by n symmetric matrix H, the m by n matrix A, the vectors g and c Full advantage is taken of any zero coefficients in the matrices H and A.","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The package may alternatively be used to minimize the (shifted) squared- least-distance objective frac12 sum_j=1^n w_j^2 ( x_j - x_j^0 )^2 + g^T x + f \\n  minimize 1/2 \\sum{j=1}^n wj^2 ( xj - xj^0 )^2+ g^T x + f, \\n subject to the linear constraint (1), for given vectors w and x^0.","category":"page"},{"location":"eqp/#Authors","page":"eqp","title":"Authors","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"eqp/#Originally-released","page":"eqp","title":"Originally released","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"March 2006, C interface January 2021.","category":"page"},{"location":"eqp/#Terminology","page":"eqp","title":"Terminology","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The required solution x necessarily satisfies the primal optimality conditions (2)  A x + c = 0 \\n (2) A x + c = 0 \\n and the dual optimality conditions [H x + g - A^T y = 0 \\;\\; (\\mbox{or} \\;\\; W^{2} (x -x^0) + g - A^T y = 0 \\;\\;\\mbox{for the shifted-least-distance type objective})] H x + g - A^T y = 0  (mboxor W^2 (x -x^0) + g - A^T y = 0  mboxfor the shifted-least-distance type objective) \\n (3) H x + g - A^T y = 0  (or W^2 (x -x^0) + g - A^T y = 0 for the shifted-least-distance type objective) \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, and where the vector y is known as the Lagrange multipliers for the linear constraints.","category":"page"},{"location":"eqp/#Method","page":"eqp","title":"Method","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"A solution to the problem is found in two phases. In the first, a point x_F satisfying (2) is found. In the second, the required solution x = x_F + s is determined by finding s to minimize q(s) = frac12 s^T H s + g_F^T s + f_F subject to the homogeneous constraints A s = zero, where g_F = H x_F + g and f_F = frac12 x_F^T H x_F + g^T x_F + f. The required constrained minimizer of q(s) is obtained by implictly applying the preconditioned conjugate-gradient method in the null space of A. Any preconditioner of the form $ KG = \\mat{cc}{ G & A^T \\ A& 0 }$ \\n KG = ( GA^T ) ( A 0) \\n is suitable, and the GALAHAD package SBLS provides a number of possibilities. In order to ensure that the minimizer obtained is finite, an additional, precautionary trust-region constraint s leq Delta for some suitable positive radius Delta is imposed, and the GALAHAD package GLTR is used to solve this additionally-constrained problem.","category":"page"},{"location":"eqp/#Reference","page":"eqp","title":"Reference","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The preconditioning aspcets are described in detail in","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"H. S. Dollar, N. I. M. Gould and A. J. Wathen. “On implicit-factorization constraint preconditioners”. InLarge Scale Nonlinear Optimization (G. Di Pillo and M. Roma, eds.) Springer Series on Nonconvex Optimization and Its Applications, Vol. 83, Springer Verlag (2006) 61-82","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"and","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"H. S. Dollar, N. I. M. Gould, W. H. A. Schilders and A. J. Wathen “On iterative methods and implicit-factorization preconditioners for regularized saddle-point systems”. SIAM Journal on Matrix Analysis and Applications, 28(1) (2006) 170-189,","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"while the constrained conjugate-gradient method is discussed in","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"N. I. M. Gould, S. Lucidi, M. Roma and Ph. L. Toint, Solving the trust-region subproblem using the Lanczos method. SIAM Journal on Optimization 9:2 (1999), 504-525.","category":"page"},{"location":"eqp/#Call-order","page":"eqp","title":"Call order","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"To solve a given problem, functions from the eqp package must be called in the following order:","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_initialize - provide default control parameters and","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"set up initial data structures","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_read_specfile (optional) - override control values","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"by reading replacement values from a file","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_import - set up problem data structures and fixed","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"values","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_reset_control (optional) - possibly change control","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"solve the problem by calling one of\neqp_solve_qp - solve the quadratic program\neqp_solve_sldqp - solve the shifted least-distance problem\neqpresolveqp (optional) - resolve the problem with the","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"same Hessian and Jacobian, but different g, f and/or c","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_information (optional) - recover information about","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"the solution and solution process","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"eqp_terminate - deallocate data structures","category":"page"},{"location":"eqp/#Unsymmetric-matrix-storage-formats","page":"eqp","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"eqp/#Dense-storage-format","page":"eqp","title":"Dense storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"eqp/#Sparse-co-ordinate-storage-format","page":"eqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"eqp/#Sparse-row-wise-storage-format","page":"eqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"eqp/#Symmetric-matrix-storage-formats","page":"eqp","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"eqp/#Dense-storage-format-2","page":"eqp","title":"Dense storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"eqp/#Sparse-co-ordinate-storage-format-2","page":"eqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"eqp/#Sparse-row-wise-storage-format-2","page":"eqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"eqp/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"eqp","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"eqp/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"eqp","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"eqp/#symmetric_matrix_identity-The-identity-matrix-format","page":"eqp","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"eqp/","page":"eqp","title":"eqp","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"dps/#Introduction","page":"dps","title":"Introduction","text":"","category":"section"},{"location":"dps/#Purpose","page":"dps","title":"Purpose","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"Given a real n by n symmetric matrix H, this package construct a symmetric, positive definite matrix M so that H is diagonal in the norm v_M = sqrtv^T M v induced by M. Subsequently the package can be use to solve the trust-region subproblem \\mbox{(1)}\\;\\; \\mbox{minimize}\\;\\; q(x) = \\frac{1}{2} x^T H x + c^T x","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"f \\;\\; \\mbox{subject to}\\;\\; \\|x\\||_{M} \\leq \\Delta$","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"or the regularized quadratic problem mbox(2)mboxminimize q(x) + frac1p sigma x_M^phspace50mm mbox for a real n vector c and scalars f, Delta0, sigma0 and p geq 2.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"A factorization of the matrix H will be required, so this package is most suited for the case where such a factorization, either dense or sparse, may be found efficiently.","category":"page"},{"location":"dps/#Authors","page":"dps","title":"Authors","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"dps/#Originally-released","page":"dps","title":"Originally released","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"August 2011, C interface December 2021.","category":"page"},{"location":"dps/#Terminology","page":"dps","title":"Terminology","text":"","category":"section"},{"location":"dps/#Method","page":"dps","title":"Method","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"The required solution x_* necessarily satisfies the optimality condition H x_* + lambda_* M x_* + c = 0, where lambda_* geq 0 is a Lagrange multiplier that corresponds to the constraint x_MleqDelta in the trust-region case (1), and is given by lambda_* = sigma x_*^p-2 for the regularization problem (2). In addition H + lambda_* M will be positive semi-definite; in most instances it will actually be positive definite, but in special “hard” cases singularity is a possibility.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"The matrix H is decomposed as H = P L D L^T P^T by calling the GALAHAD package SLS. Here P is a permutation matrix, L is unit lower triangular and D is block diagonal, with blocks of dimension at most two. The spectral decomposition of each diagonal block of D is computed, and each eigenvalue theta is replaced by max (  theta   theta_min )  where theta_min is a positive user-supplied value. The resulting block diagonal matrix is B, from which we define the modified-absolute-value M = P L B L^T P^T an alternative due to Goldfarb uses instead the simpler M = P L L^T P^T","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"Given the factors of H (and M), the required solution is found by making the change of variables y = B^12 L^T P^T x (or y = L^T P^T x in the Goldfarb case) which results in “diagonal” trust-region and regularization subproblems, whose solution may be easily obtained suing a Newton or higher-order iteration of a resulting “secular” equation.If subsequent problems, for which H and c are unchanged, are to be attempted, the existing factorization and solution may easily be exploited.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"The dominant cost is that for the factorization of the symmetric, but potentially indefinite, matrix H using the GALAHAD package SLS.","category":"page"},{"location":"dps/#Reference","page":"dps","title":"Reference","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"The method is described in detail for the trust-region case in","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"N. I. M. Gould and J. Nocedal (1998). The modified absolute-value factorization for trust-region minimization. In “High Performance Algorithms and Software in Nonlinear Optimization” (R. De Leone, A. Murli, P. M. Pardalos and G. Toraldo, eds.), Kluwer Academic Publishers, pp. 225-241,","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"while the adaptation for the regularization case is obvious. The method used to solve the diagonal trust-region and regularization subproblems are as given by","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"H. S. Dollar, N. I. M. Gould and D. P. Robinson (2010). On solving trust-region and other regularised subproblems in optimization. Mathematical Programming Computation 2(1) 21-57","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"with simplifications due to the diagonal Hessian.","category":"page"},{"location":"dps/#Call-order","page":"dps","title":"Call order","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"To solve a given problem, functions from the dps package must be called in the following order:","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dps_initialize - provide default control parameters and","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"set up initial data structures","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dps_read_specfile (optional) - override control values","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"by reading replacement values from a file","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dps_import - import control and matrix data structures\ndps_reset_control (optional) - possibly change control","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"one of\ndps_solvetrproblem - solve the trust-region problem (1)\ndps_solverqproblem - solve the regularized-quadratic","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"problem (2)","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"optionally one of\ndpsresolvetr_problem - resolve the trust-region problem","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"(1) when the non-matrix data has changed","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dpsresolverq_problem - resolve the regularized-quadratic","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"problem (2) when the non-matrix data has changed","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dps_information (optional) - recover information about","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"the solution and solution process","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"dps_terminate - deallocate data structures","category":"page"},{"location":"dps/#Symmetric-matrix-storage-formats","page":"dps","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"The symmetric n by n coefficient matrix H may be presented and stored in a variety of convenient input formats.Crucially symmetry is exploitedby only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"dps/","page":"dps","title":"dps","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"dps/#Dense-storage-format","page":"dps","title":"Dense storage format","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array val will hold the value H_ij (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"dps/#Sparse-co-ordinate-storage-format","page":"dps","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays row and col and real array val, respectively, while the number of nonzeros is recorded as ne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"dps/#Sparse-row-wise-storage-format","page":"dps","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"dps/","page":"dps","title":"dps","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array ptr holds the position of the first entry in this row, while ptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of theentries in the i-th row are stored in components l = ptr(i), ldots, ptr(i+1)-1 of the integer array col, and real array val, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"lsrt/#Introduction","page":"lsrt","title":"Introduction","text":"","category":"section"},{"location":"lsrt/#Purpose","page":"lsrt","title":"Purpose","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"Given a real m by n matrix A, a real m vector b and scalars sigma0 and p geq 2, this package finds an **approximate minimizer of the regularised linear-least-squares objective function frac12 A x - b_2^2 + frac1p sigma  x _2^p. ** This problem commonly occurs as a subproblem in nonlinear optimization calculations involving cubic regularisation, and may be used to regularise the solution of under-determined or ill-conditioned linear least-squares problems. The method may be suitable for large m and/or n as no factorization involving A is required. Reverse communication is used to obtain matrix-vector products of the form u + A v and v + A^T u.","category":"page"},{"location":"lsrt/#Authors","page":"lsrt","title":"Authors","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lsrt/#Originally-released","page":"lsrt","title":"Originally released","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"November 2007, C interface December 2021.","category":"page"},{"location":"lsrt/#Terminology","page":"lsrt","title":"Terminology","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"The required solution x necessarily satisfies the optimality condition A^T ( A x - b ) + lambda x = 0, where the multiplier lambda = sigma x_2^p-2.","category":"page"},{"location":"lsrt/#Method","page":"lsrt","title":"Method","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"The method is iterative. Startingwith the vector u_1 = b, a bi-diagonalisation process is used to generate the vectors v_k and u_k+1 so that the n by k matrix V_k = ( v_1 ldots v_k) and the m by (k+1) matrix U_k = ( u_1 ldots u_k+1) together satisfy A V_k = U_k+1 B_k mboxand b = b_2 U_k+1 e_1 \\n \\n where B_k is (k+1) by k and lower bi-diagonal, U_k andV_k have orthonormal columns and e_1 is the first unit vector.The solution sought is of the form x_k = V_k y_k, where y_k solves the bi-diagonal regularised least-squares problem (1)  min  B_k y - b e_1 _2 + frac1p sigma y _2^p \\n  (1) min || Bk y - ||b|| e1 ||2+ 1/p sigma || y||^p2. \\n To minimize (1), the optimality conditions ( B_k^T ( B_k^ y(lambda) - b e_1^ ) + lambda y(lambda) = 0 \\n \\n where lambda = sigma y(lambda)_2^p-2 , are used as the basis of an iteration. The vector y(lambda) is equivalently the solution to the regularised least-squares problem (2)  minleft  vect B_k  lambda^frac12 I  y - b e_1^ right _2 \\n (2)min||Bk y - ||b|| e1 || ||lambda^{1/2} y|| \\n Thus, given an estimate lambda geq 0, (2) may be efficiently solved to give y(lambda). It is then simply a matter of adjusting lambda (for example by a Newton-like process) to solve the scalar nonlinear equation (3)  theta(lambda) equiv y(lambda) _2^p-2 - fraclambdasigma = 0 \\n  (3) theta(lambda) = || y(lambda) ||2^{p-2} - lambda/sigma = 0. \\n In practice (3) is reformulated, and a more rapidly converging iteration is used. Having foundyk a second pass in which x_k = V_k y_k is regenerated is needed–-this need only be done once x_k has implicitly deemed to be sufficiently close to optimality. As this second pass is an additional expense, a record is kept of the optimal objective function values for each value of k, and the second pass is only performed so far as to ensure a given fraction of the final optimal objective value. Large savings may be made in the second pass by choosing the required fraction to be significantly smaller than one.","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"Special code is used in the special case p=2, as in this case a single pass suffices.","category":"page"},{"location":"lsrt/#Reference","page":"lsrt","title":"Reference","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"A complete description of the un- and quadratically-regularised cases is given by","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"C. C. Paige and M. A. Saunders, LSQR: an algorithm for sparse linear equations and sparse leastsquares. ACM Transactions on Mathematical Software, 8(1):43–71, 1982","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"and","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"C. C. Paige and M. A. Saunders, ALGORITHM 583: LSQR: an algorithm for sparse linear equations and sparse least squares. ACM Transactions on Mathematical Software, 8(2):195–209, 1982.","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"Additional details on the Newton-like process needed to determine lambda and other details are described in","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"C. Cartis, N. I. M. Gould and Ph. L. Toint, Trust-region and other regularisation of linear least-squares problems. BIT 49(1):21-53 (2009).","category":"page"},{"location":"lsrt/#Call-order","page":"lsrt","title":"Call order","text":"","category":"section"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"To solve a given problem, functions from the lsrt package must be called in the following order:","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_initialize - provide default control parameters and","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"set up initial data structures","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_read_specfile (optional) - override control values","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"by reading replacement values from a file","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_import_control - import control parameters prior to","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"solution","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_solve_problem - solve the problem by reverse","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"communication, a sequence of calls are made under control of a status parameter, each exit either asks the user to provide additional informaton and to re-enter, or reports that either the solution has been found or that an error has occurred","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_information (optional) - recover information about","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"the solution and solution process","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"lsrt_terminate - deallocate data structures","category":"page"},{"location":"lsrt/","page":"lsrt","title":"lsrt","text":"See Section~\\ref{examples} for an example of use. See the <a href=\"examples.html\">examples tab</a> for an illustration of use. See the examples section for an illustration of use.","category":"page"},{"location":"tru/#Introduction","page":"tru","title":"Introduction","text":"","category":"section"},{"location":"tru/#Purpose","page":"tru","title":"Purpose","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"The tru package uses a trust-region method to find a (local) unconstrained minimizer of a differentiable objective function mathbff(x) of many variables mathbfx. The method offers the choice of direct and iterative solution of the key trust-region subproblems, and is most suitable for large problems. First derivatives are required, and if second derivatives can be calculated, they will be exploited–-if the product of second derivatives with a vector may be found, but not the derivatives themselves, that may also be exploited.","category":"page"},{"location":"tru/#Authors","page":"tru","title":"Authors","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England, and Ph. L. Toint, The University of Namur, Belgium.","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"tru/#Originally-released","page":"tru","title":"Originally released","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"July 2008, C interface August 2021.","category":"page"},{"location":"tru/#Terminology","page":"tru","title":"Terminology","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"The gradient nabla_x f(x) of f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"tru/#Method","page":"tru","title":"Method","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"A trust-region method is used. In this, an improvement to a current estimate of the required minimizer, x_k is sought by computing a step s_k. The step is chosen to approximately minimize a model m_k(s) of f(x_k + s) within a trust region s_k leq Delta_kfor some specified positive \"radius\" Delta_k. The quality of the resulting step s_k is assessed by computing the \"ratio\" (f(x_k) - f(x_k + s_k)) (m_k(0) - m_k(s_k)). The step is deemed to have succeeded if the ratio exceeds a given eta_s  0, and in this case x_k+1 = x_k + s_k. Otherwise x_k+1 = x_k, and the radius is reduced by powers of a given reduction factor until it is smaller than s_k. If the ratio is larger thaneta_v geq eta_d, the radius will be increased so that it exceeds s_k by a given increase factor. The method will terminate as soon as nabla_x f(x_k) is smaller than a specified value.","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"Either linear or quadratic models m_k(s) may be used. The former will be taken as the first two terms f(x_k) + s^T nabla_x f(x_k) of a Taylor series about x_k, while the latter uses an approximation to the first three terms f(x_k) + s^T nabla_x f(x_k) + frac12 s^T B_k s, for which B_k is a symmetric approximation to the Hessian nabla_xxf(x_k) ; possible approximations include the true Hessian, limited-memory secant and sparsity approximations and a scaled identity matrix. Normally a two-norm trust region will be used, but this may change if preconditioning is employed.","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"An approximate minimizer of the model within the trust region is found using either a direct approach involving factorization or an iterative (conjugate-gradient/Lanczos) approach based on approximations to the required solution from a so-called Krlov subspace. The direct approach is based on the knowledge that the required solution satisfies the linear system of equations (B_k + lambda_k I) s_k = - nabla_x f(x_k) involving a scalar Lagrange multiplier lambda_k. This multiplier is found by uni-variate root finding, using a safeguarded Newton-like process, by the GALAHAD packages TRS or DPS (depending on the norm chosen). The iterative approach uses the GALAHAD package GLTR, and is best accelerated by preconditioning with good approximations to B_k using GALAHAD's PSLS. The iterative approach has the advantage that only matrix-vector products B_k v are required, and thus B_k is not required explicitly. However when factorizations of B_k are possible, the direct approach is often more efficient.","category":"page"},{"location":"tru/#Reference","page":"tru","title":"Reference","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"The generic trust-region method is described in detail in","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint, \"Trust-region methods\", SIAM/MPS Series on Optimization (2000).","category":"page"},{"location":"tru/#Call-order","page":"tru","title":"Call order","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"To solve a given problem, functions from the tru package must be called in the following order:","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_initialize - provide default control parameters and","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"set up initial data structures","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_read_specfile (optional) - override control values","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"by reading replacement values from a file","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_import - set up problem data structures and fixed","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"values","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_reset_control (optional) - possibly change control","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"solve the problem by calling one of\ntru_solve_with_mat - solve using function calls to","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_solve_without_mat - solve using function calls to","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_information (optional) - recover information about","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"the solution and solution process","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"tru_terminate - deallocate data structures","category":"page"},{"location":"tru/#Symmetric-matrix-storage-formats","page":"tru","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"The symmetric n by n matrix H = nabla_xxf may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"tru/","page":"tru","title":"tru","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"tru/#Dense-storage-format","page":"tru","title":"Dense storage format","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value H{ij}$ (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"tru/#Sparse-co-ordinate-storage-format","page":"tru","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"tru/#Sparse-row-wise-storage-format","page":"tru","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"tru/","page":"tru","title":"tru","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [GALAHAD]","category":"page"},{"location":"trs/#Introduction","page":"trs","title":"Introduction","text":"","category":"section"},{"location":"trs/#Purpose","page":"trs","title":"Purpose","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Given real n by n symmetric matrices H and M (with M diagonally dominant), another real m by n matrix A, a real n vector c and scalars Delta0 and f, this package finds a global minimizer of the quadratic objective function  frac12 x^T Hx + c^T x + f, where the vector x is required to satisfy the constraint x_M leq Delta and possibly A x =0, and where the M-norm of x is x_M = sqrtx^T M x. This problem commonly occurs as atrust-region subproblem in nonlinear optimization calculations.The package may also be used to solve the related problem in which x is instead required to satisfy the equality constraint x_M = Delta.The matrix M need not be provided in the commonly-occurring ell_2-trust-region case for which M = I, the n by n identity matrix.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"Factorization of matrices of the form H + lambda M–-or mbox(1) matcc H + lambda M  A^T  A  0 \\n (1) ( H + lambda M A^T ) (A0) \\n in cases where A x = 0 is imposed–-for a succession of scalars lambda will be required, so this package is most suited for the case where such a factorization may be found efficiently. If this is not the case, the GALAHAD package GLTR may be preferred.","category":"page"},{"location":"trs/#Authors","page":"trs","title":"Authors","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"N. I. M. Gould and H. S. Thorne, STFC-Rutherford Appleton Laboratory, England, and D. P. Robinson, Oxford University, England.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"trs/#Originally-released","page":"trs","title":"Originally released","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"October 2008, C interface December 2021.","category":"page"},{"location":"trs/#Method","page":"trs","title":"Method","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"The method is iterative, and proceeds in two phases.Firstly, lower and upper bounds, lambda_L and lambda_U, on lambda_* are computed using Gershgorin's theorems and other eigenvalue bounds. The first phase of the computation proceeds by progressively shrinking the bound interval lambda_Llambda_U until a value lambda for which x(lambda)_M geq Delta is found.Here x(lambda) and its companion y(lambda) are defined to be a solution of \\mbox{(2)}\\;\\;\\; (H + \\lambda M)x(\\lambda)","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"A^T y(\\lambda) = - c \\;\\mbox{and}\\; A x(\\lambda) = 0.$","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"\\n  (2)(H + lambda M)x(lambda) + A^T y(lambda) = - c and A x(lambda) = 0; \\n along the way the possibility that H might be positive definite on the null-space of A and x(0)_M leq Delta is examined, and if this transpires the process is terminated with x_* = x(0). Once the terminating lambda from the first phase has been discovered, the second phase consists of applying Newton or higher-order iterations to the nonlinear “secular” equation x(lambda)_M = Delta with the knowledge that such iterations are both globally and ultimately rapidly convergent. It is possible in the “hard” case that the interval in the first-phase will shrink to the single point lambda_*, and precautions are taken, using inverse iteration with Rayleigh-quotient acceleration to ensure that this too happens rapidly.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"The dominant cost is the requirement that we solve a sequence of linear systems (2). In the absence of linear constraints, an efficient sparse Cholesky factorization with precautions to detect indefinite H + lambda M is used. If A x = 0 is required, a sparse symmetric, indefinite factorization of (1) is used rather than a Cholesky factorization.","category":"page"},{"location":"trs/#Reference","page":"trs","title":"Reference","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"The method is described in detail in","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"H. S. Dollar, N. I. M. Gould and D. P. Robinson. On solving trust-region and other regularised subproblems in optimization. Mathematical Programming Computation 2(1) (2010) 21–57.","category":"page"},{"location":"trs/#Call-order","page":"trs","title":"Call order","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"To solve a given problem, functions from the trs package must be called in the following order:","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_initialize - provide default control parameters and","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"set up initial data structures","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_read_specfile (optional) - override control values","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"by reading replacement values from a file","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_import - set up problem data structures and fixed","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"values","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_import_m - (optional) set up problem data structures","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"and fixed values for the scaling matrix M, if any","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_import_a - (optional) set up problem data structures","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"and fixed values for the constraint matrix A, if any","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_reset_control (optional) - possibly change control","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_solve_problem - solve the trust-region problem\ntrs_information (optional) - recover information about","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"the solution and solution process","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"trs_terminate - deallocate data structures","category":"page"},{"location":"trs/#Unsymmetric-matrix-storage-formats","page":"trs","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"trs/","page":"trs","title":"trs","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"trs/#Dense-storage-format","page":"trs","title":"Dense storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"trs/#Sparse-co-ordinate-storage-format","page":"trs","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"trs/#Sparse-row-wise-storage-format","page":"trs","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"trs/#Symmetric-matrix-storage-formats","page":"trs","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Likewise, the symmetric n by n objective Hessian matrix H and scaling matrix M may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal). In what follows, we refer to H but this applies equally to M.","category":"page"},{"location":"trs/#Dense-storage-format-2","page":"trs","title":"Dense storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"trs/#Sparse-co-ordinate-storage-format-2","page":"trs","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"trs/#Sparse-row-wise-storage-format-2","page":"trs","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"trs/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"trs","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"trs/","page":"trs","title":"trs","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"bgo/#Introduction","page":"bgo","title":"Introduction","text":"","category":"section"},{"location":"bgo/#Purpose","page":"bgo","title":"Purpose","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The bgo package uses a multi-start trust-region method to find an approximation to the global minimizer of a differentiable objective function f(x) of n variables x, subject to simple bounds x^l leq x leq x^u on the variables. Here, any of the components of the vectors of bounds x^l and x^u may be infinite. The method offers the choice of direct and iterative solution of the key trust-region subproblems, and is suitable for large problems. First derivatives are required, and if second derivatives can be calculated, they will be exploited–-if the product of second derivatives with a vector may be found but not the derivatives themselves, that may also be exploited.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The package offers both random multi-start and local-minimize-and probe methods to try to locate the global minimizer. There are no theoretical guarantees unless the sampling is huge, and realistically the success of the methods decreases as the dimension and nonconvexity increase.","category":"page"},{"location":"bgo/#Authors","page":"bgo","title":"Authors","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"bgo/#Originally-released","page":"bgo","title":"Originally released","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"July 2016, C interface August 2021.","category":"page"},{"location":"bgo/#Terminology","page":"bgo","title":"Terminology","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The gradient nabla_x f(x) of f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"bgo/#Method","page":"bgo","title":"Method","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"A choice of two methods is available. In the first, local-minimization-and-probe, approach, local minimization and univariate global minimization are intermixed. Given a current champion x^S_k, a local minimizer x_k of f(x) within the feasible box x^l leq x leq x^u is found using the GALAHAD package trb. Thereafter m random directions p are generated, and univariate local minimizer of f(x_k + alpha p) as a function of the scalar alpha along each p within the interval alpha^Lalpha^u, where alpha^L and alpha^u are the smallest and largest alpha for which x^l leq x_k + alpha p leq x^u, is performed using the GALAHAD package ugo. The point x_k + alpha p that gives the smallest value of f is then selected as the new champion x^S_k+1.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The random directions p are chosen in one of three ways. The simplest is to select the components as (ignore next phrase - doxygen bug!) p_i = mboxpseudo random in left beginarrayrl mbox-11  mboxif  x^l_i  x_ki  x^u_i \nmbox01  mboxif  x_ki= x^l_i \nmbox-10  mboxif x_ki= x^u_i endarray right  n  ( -11 if x^l_i  x_ki  x^u_i p_i = pseudo random in (01 if x_ki = x^l_i  ( -10 if x_ki = x^u_i n for each 1 leq i leq n. An alternative is to pick p by partitioning each dimension of the feasible “hypercube” box into m equal segments, and then selecting sub-boxes randomly within this hypercube using GALAHAD's Latin hypercube sampling package, lhs. Each components of p is then selected in its sub-box, either uniformly or pseudo randomly.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The other, random-multi-start, method provided selects m starting points at random, either componentwise pseudo randomly in the feasible box, or by  partitioning each component into m equal segments, assigning each to a sub-box using Latin hypercube sampling, and finally choosing the values either uniformly or pseudo randomly. Local minimizers within the feasible box are then computed by the GALAHAD package trb, and the best is assigned as the current champion. This process is then repeated until evaluation limits are achieved.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"If n=1, the GALAHAD package UGO is called directly.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"We reiterate that there are no theoretical guarantees unless the sampling is huge, and realistically the success of the methods decreases as the dimension and nonconvexity increase. Thus the methods used should best be viewed as heuristics.","category":"page"},{"location":"bgo/#References","page":"bgo","title":"References","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The generic bound-constrained trust-region method is described in detail in","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint (2000), Trust-region methods. SIAM/MPS Series on Optimization,","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"the univariate global minimization method employed is an extension of that due to","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"D. Lera and Ya. D. Sergeyev (2013), “Acceleration of univariate global optimization algorithms working with Lipschitz functions and Lipschitz first derivatives” SIAM J. Optimization Vol. 23, No. 1, pp. 508–529,","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"while the Latin-hypercube sampling method employed is that of","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"B. Beachkofski and R. Grandhi (2002). “Improved Distributed Hypercube Sampling”, 43rd AIAA structures, structural dynamics, and materials conference, pp. 2002-1274.","category":"page"},{"location":"bgo/#Call-order","page":"bgo","title":"Call order","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"To solve a given problem, functions from the bgo package must be called in the following order:","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_initialize - provide default control parameters and","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"set up initial data structures","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_read_specfile (optional) - override control values","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"by reading replacement values from a file","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_import - set up problem data structures and fixed","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"values","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_reset_control (optional) - possibly change control","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"solve the problem by calling one of\nbgo_solve_with_mat - solve using function calls to","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_solve_without_mat - solve using function calls to","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_information (optional) - recover information about","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"the solution and solution process","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"bgo_terminate - deallocate data structures","category":"page"},{"location":"bgo/#Symmetric-matrix-storage-formats","page":"bgo","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The symmetric n by n matrix H = nabla_xxf may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"bgo/","page":"bgo","title":"bgo","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"bgo/#Dense-storage-format","page":"bgo","title":"Dense storage format","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value H{ij}$ (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"bgo/#Sparse-co-ordinate-storage-format","page":"bgo","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"bgo/#Sparse-row-wise-storage-format","page":"bgo","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"bgo/","page":"bgo","title":"bgo","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"clls/#Introduction","page":"clls","title":"Introduction","text":"","category":"section"},{"location":"clls/#Purpose","page":"clls","title":"Purpose","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"This package uses a primal-dual interior-point crossover method to solve the constrained linear least-squares problem \\mbox{minimize}\\;\\; f(x) = \\frac{1}{2} \\| A x - b \\|^2","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"\\frac{1}{2} \\sigma \\| x \\|^2 $","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"\\n minimize f(x) := 1/2 ||Ax-b||^2 + 1/2 sigma ||x||^2 \\n subject to the general linear constraints c_i^lleql_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] li^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the m by n matrix A, the vectors li c^l, c^u, x^l, x^u and the scalar sigma are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix A or the matrix A of vectors l_i.","category":"page"},{"location":"clls/#Authors","page":"clls","title":"Authors","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"N. I. M. Gould and D. P. Robinson, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"clls/#Originally-released","page":"clls","title":"Originally released","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"July 2022.","category":"page"},{"location":"clls/#Terminology","page":"clls","title":"Terminology","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) L x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm A^T ( Ax-b ) = L^T y + z \\n (2a) A^T ( A x - b ) = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"clls/#Method","page":"clls","title":"Method","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"The method aims at each stage to reduce the overall violation of (1a), (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c y y^l y^u z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c y y^l y^u z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (1a), (2a) and a parameterized “residual trajectory” perturbation of (3); residual trajectories proposed by Zhang (1994) and Zhao and Sun (1999) are possibilities. An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1b) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate. The \"Schur-complement\" approach is usually to be preferred when all the weights are nonzero or when every variable is bounded (at least one side), but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"Optionally, the problem may be pre-processed temporarily to eliminate dependent constraints using the GALAHAD package FDC. This may improve the performance of the subsequent iteration.","category":"page"},{"location":"clls/#Reference","page":"clls","title":"Reference","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"and","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"G. Zhao and J. Sun (1999). On the rate of local convergence of high-order infeasible path-following algorithms for the P_ast linear complementarity problems, Computational Optimization and Applications 14(1) 293-307,","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"with many enhancements described by","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"N. I. M. Gould, D. Orban and D. P. Robinson (2013). Trajectory-following methods for large-scaledegenerate convex quadratic programming, Mathematical Programming Computation 5(2) 113-142.","category":"page"},{"location":"clls/#Call-order","page":"clls","title":"Call order","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"To solve a given problem, functions from the clls package must be called in the following order:","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"clls_initialize - provide default control parameters and","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"set up initial data structures","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"clls_read_specfile (optional) - override control values","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"by reading replacement values from a file","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"clls_import - set up problem data structures and fixed","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"values","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"clls_reset_control (optional) - possibly change control","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"solve the problem by calling one of\nclls_solve_qp - solve the quadratic program\nclls_solve_sldqp - solve the shifted least-distance problem\nclls_information (optional) - recover information about","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"the solution and solution process","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"clls_terminate - deallocate data structures","category":"page"},{"location":"clls/#Unsymmetric-matrix-storage-formats","page":"clls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"clls/","page":"clls","title":"clls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"clls/#Dense-storage-format","page":"clls","title":"Dense storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"clls/#Sparse-co-ordinate-storage-format","page":"clls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"clls/#Sparse-row-wise-storage-format","page":"clls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"clls/#Symmetric-matrix-storage-formats","page":"clls","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"clls/#Dense-storage-format-2","page":"clls","title":"Dense storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"clls/#Sparse-co-ordinate-storage-format-2","page":"clls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"clls/#Sparse-row-wise-storage-format-2","page":"clls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"clls/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"clls","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"clls/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"clls","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"clls/#symmetric_matrix_identity-The-identity-matrix-format","page":"clls","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"clls/#symmetric_matrix_zero-The-zero-matrix-format","page":"clls","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"clls/","page":"clls","title":"clls","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"lpb/#Introduction","page":"lpb","title":"Introduction","text":"","category":"section"},{"location":"lpb/#Purpose","page":"lpb","title":"Purpose","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"This package uses a primal-dual interior-point method to solve the linear programming problem mboxminimize q(x) = g^T x + f  n minimize q(x) = g^T x + f n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the vectors g, w, x^0, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix A whose rows are the transposes of the vectors a_i.","category":"page"},{"location":"lpb/#Authors","page":"lpb","title":"Authors","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lpb/#Originally-released","page":"lpb","title":"Originally released","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"August 2018, C interface September 2021.","category":"page"},{"location":"lpb/#Terminology","page":"lpb","title":"Terminology","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm g = A^T y + z}$ \\n (2a) g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"lpb/#Method","page":"lpb","title":"Method","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The method aims at each stage to reduce the overall violation of (1a), (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c y y^l y^u z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c y y^l y^u z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (1a), (2a) and a parameterized “residual trajectory” perturbation of (3); residual trajectories proposed by Zhang (1994) and Zhao and Sun (1999) are possibilities. An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1b) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate. The \"Schur-complement\" approach is usually to be preferred when all the weights are nonzero or when every variable is bounded (at least one side), but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Optionally, the problem may be pre-processed temporarily to eliminate dependent constraints using the GALAHAD package FDC. This may improve the performance of the subsequent iteration.","category":"page"},{"location":"lpb/#Reference","page":"lpb","title":"Reference","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"and","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"G. Zhao and J. Sun (1999). On the rate of local convergence of high-order infeasible path-following algorithms for the P_ast linear complementarity problems, Computational Optimization and Applications 14(1) 293-307,","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"with many enhancements described by","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"N. I. M. Gould, D. Orban and D. P. Robinson (2013). Trajectory-following methods for large-scaledegenerate convex quadratic programming, Mathematical Programming Computation 5(2) 113-142.","category":"page"},{"location":"lpb/#Call-order","page":"lpb","title":"Call order","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"To solve a given problem, functions from the lpb package must be called in the following order:","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_initialize - provide default control parameters and","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"set up initial data structures","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_read_specfile (optional) - override control values","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"by reading replacement values from a file","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_import - set up problem data structures and fixed","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"values","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_reset_control (optional) - possibly change control","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_solve_lp - solve the linear program\nlpb_information (optional) - recover information about","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"the solution and solution process","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"lpb_terminate - deallocate data structures","category":"page"},{"location":"lpb/#Unsymmetric-matrix-storage-formats","page":"lpb","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"lpb/#Dense-storage-format","page":"lpb","title":"Dense storage format","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"lpb/#Sparse-co-ordinate-storage-format","page":"lpb","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"lpb/#Sparse-row-wise-storage-format","page":"lpb","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"lpb/","page":"lpb","title":"lpb","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"slls/#Introduction","page":"slls","title":"Introduction","text":"","category":"section"},{"location":"slls/#Purpose","page":"slls","title":"Purpose","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"This package uses a preconditioned, projected-gradient method to solve the  simplex-constrained regularized linear least-squares problem mboxminimize q(x) = frac12  A x - b_2^2 + frac12 sigma x^2 \\n minimize q(x) := 1/2 || A x - b ||^2 + sigma ||x||^2 \\n where x is required to lie in the regular simplex e^T x = 1 mboxandx_j geq 0  j = 1 ldots  n \\n  e^T x = 1 and x_j [>=] 0, j = 1, ... , n, \\n where the m by n real matrix A, the vector b,and the non-negative weight sigma are given, and e is the vector of ones. Full advantage is taken of any zero coefficients of the Jacobian matrix A of the residuals c(x) = A x - b;the matrix need not be provided as there are options to obtain matrix-vector products involving A and its transpose either by reverse communication or from a user-provided subroutine.","category":"page"},{"location":"slls/#Authors","page":"slls","title":"Authors","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"slls/#Originally-released","page":"slls","title":"Originally released","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"October 2019, C interface July 2022.","category":"page"},{"location":"slls/#Terminology","page":"slls","title":"Terminology","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"The required solution x necessarily satisfies the primal optimality conditions e^T x = 1 mboxand x geq 0  \\n  e^T x = 1 and x [>=] 0, \\n the dual optimality conditions (A^T A + sigma I ) x = A^T b + z \\n  ( A^T A + sigma I ) x = A^T b + z \\n where the dual variables $ z \\geq 0,$ \\n  zl [>=] 0, \\n and the complementary slackness conditions x^T z = 0,\\hspace{12mm} $ \\n x^T z = 0, \\n where the vector inequalities hold component-wise.","category":"page"},{"location":"slls/#Method","page":"slls","title":"Method","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"The method is iterative. Each iteration proceeds in two stages. Firstly, a search direction s from the current estimate of the solution x is computed. This may be in a scaled steepest-descent direction, or, if the working set of variables on bounds has not changed dramatically, in a direction that provides an approximate minimizer of the objective over a subspace comprising the currently free-variables. The latter is computed either using an appropriate sparse factorization by the GALAHAD package SBLS, or by theconjugate-gradient least-squares (CGLS) method; tt may be necessary to regularize the subproblem very slightly to avoid a ill-posedness. Thereafter, a piecewise linesearch (arc search) is carried out along the arc x(alpha) = P( x + alpha s) for alpha  0, where the projection operator P(v) gives the nearest feasible point to v within the regular simplex; thus this arc bends the search direction into the feasible region. The arc search is performed either exactly, by passing through a set of increasing breakpoints at which it changes direction, or inexactly, by evaluating a sequence of different alphaon the arc. All computation is designed to exploit sparsity in A.","category":"page"},{"location":"slls/#Reference","page":"slls","title":"Reference","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"Full details are provided in","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"N. I. M. Gould (2022). Linear least-squares over the unit simplex. In preparation.","category":"page"},{"location":"slls/#Call-order","page":"slls","title":"Call order","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"To solve a given problem, functions from the slls package must be called in the following order:","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_initialize - provide default control parameters and","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"set up initial data structures","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_read_specfile (optional) - override control values","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"by reading replacement values from a file","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"set up problem data structures and fixed values by caling one of\nslls_import - in the case that A is explicitly","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"available","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_import_without_a - in the case that only the","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"effect of applying A and its transpose to a vector is possible","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_reset_control (optional) - possibly change control","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"solve the problem by calling one of\nslls_solvegivena - solve the problem using values","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"of A","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_solve_reverseaprod - solve the problem by returning","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"to the caller for products of A and its transpose with specified vectors","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_information (optional) - recover information about","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"the solution and solution process","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"slls_terminate - deallocate data structures","category":"page"},{"location":"slls/#Unsymmetric-matrix-storage-formats","page":"slls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"The unsymmetric m by n matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"slls/","page":"slls","title":"slls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"slls/#unsymmetric_matrix*dense*row-Dense-row-storage-format","page":"slls","title":"unsymmetric_matrixdenserow Dense row storage format","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"slls/#unsymmetric_matrix*dense*column-Dense-column-storage-format","page":"slls","title":"unsymmetric_matrixdensecolumn Dense column storage format","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"The matrix A is stored as a compactdense matrix by columns, that is, the values of the entries of each column in turn are stored in order within an appropriate real one-dimensional array. In this case, component m ast j + iof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"slls/#Sparse-co-ordinate-storage-format","page":"slls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"slls/#Sparse-row-wise-storage-format","page":"slls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessors.","category":"page"},{"location":"slls/#unsymmetric_matrix*column*wise-Sparse-column-wise-storage-format","page":"slls","title":"unsymmetric_matrixcolumnwise Sparse column-wise storage format","text":"","category":"section"},{"location":"slls/","page":"slls","title":"slls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in column j appear directly before those in column j+1. For the j-th column of A the j-th component of the integer array Aptr holds the position of the first entry in this column, while Aptr(n) holds the total number of entries plus one. The row indices i, 0 leq i leq m-1, and values A_ij of thenonzero entries in the j-th column are stored in components l = Aptr(j), ldots, Aptr(j+1)-1,0 leq j leq n-1, of the integer array Arow, and real array Aval, respectively. Once again, for sparse matrices, this scheme almost always requires less storage than the dense of coordinate formats.","category":"page"},{"location":"rqs/#Introduction","page":"rqs","title":"Introduction","text":"","category":"section"},{"location":"rqs/#Purpose","page":"rqs","title":"Purpose","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Given real n by n symmetric matrices H and M (with Mdiagonally dominant), another real m by n matrix A, a real n vector c and scalars sigma0, p2 and f, this package finds an approximate minimizer of the regularised quadratic objective function frac12 x^T H x + c^T x + f + frac1p sigma x_M^p, where the vector x may additionally be required to satisfy A x = 0, and where the M-norm of x is x_M = sqrtx^T M x. This problem commonly occurs as a subproblem in nonlinear optimization calculations.The matrix M need not be provided in the commonly-occurring ell_2-regularisation case for which M =I, the n by n identity matrix.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Factorization of matrices of the form H + lambda M–-or mbox(1) matcc H + lambda M  A^T  A  0 \\n (1)( H + lambda M A^T )  ( A 0) \\n in cases where A x = 0 is imposed–-for a succession of scalars lambda will be required, so this package is most suited for the case where such a factorization may be found efficiently. If this is not the case, the GALAHAD package GLRT may be preferred.","category":"page"},{"location":"rqs/#Authors","page":"rqs","title":"Authors","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"N. I. M. Gould and H. S. Thorne, STFC-Rutherford Appleton Laboratory, England, and D. P. Robinson, Oxford University, England.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"rqs/#Originally-released","page":"rqs","title":"Originally released","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"November 2008, C interface December 2021.","category":"page"},{"location":"rqs/#Method","page":"rqs","title":"Method","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The required solution x_* necessarily satisfies the optimality condition H x_* + lambda_* M x_* + A^T y_* + c = 0 and A x_* = 0, where lambda_* = sigmax_*^p-2 is a Lagrange multiplier corresponding to the regularisation and y_* are Lagrange multipliers for the linear constraints A x = 0, if any.In addition in all cases, the matrix H + lambda_* M will be positive semi-definite on the null-space of A; in most instances it will actually be positive definite, but in special “hard” cases singularity is a possibility.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The method is iterative, and proceeds in two phases.Firstly, lower and upper bounds, lambda_L and lambda_U, on lambda_* are computed using Gershgorin's theorems and other eigenvalue bounds. The first phase of the computation proceeds by progressively shrinking the bound interval lambda_Llambda_U until a value lambda for which x(lambda)_M geq sigma x(lambda)_M^p-2 is found.Here x(lambda) and its companion y(lambda) are defined to be a solution of \\mbox{(2)}\\;\\;\\; (H + \\lambda M)x(\\lambda)","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"A^T y(\\lambda) = - c \\;\\mbox{and}\\; A x(\\lambda) = 0.$","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"\\n  (2)(H + lambda M)x(lambda) + A^T y(lambda) = - c and A x(lambda) = 0. \\n Once the terminating lambda from the first phase has been discovered, the second phase consists of applying Newton or higher-order iterations to the nonlinear “secular” equation x(lambda)_M = sigma x(lambda)_M^p-2 with the knowledge that such iterations are both globally and ultimately rapidly convergent. It is possible in the “hard” case that the interval in the first-phase will shrink to the single point lambda_*, and precautions are taken, using inverse iteration with Rayleigh-quotient acceleration to ensure that this too happens rapidly.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The dominant cost is the requirement that we solve a sequence of linear systems (2). In the absence of linear constraints, an efficient sparse Cholesky factorization with precautions to detect indefinite H + lambda M is used. If A x = 0 is required, a sparse symmetric, indefinite factorization of (1) is used rather than a Cholesky factorization.","category":"page"},{"location":"rqs/#Reference","page":"rqs","title":"Reference","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The method is described in detail in","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"H. S. Dollar, N. I. M. Gould and D. P. Robinson. On solving trust-region and other regularised subproblems in optimization. Mathematical Programming Computation 2(1) (2010) 21–57.","category":"page"},{"location":"rqs/#Call-order","page":"rqs","title":"Call order","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"To solve a given problem, functions from the rqs package must be called in the following order:","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_initialize - provide default control parameters and","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"set up initial data structures","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_read_specfile (optional) - override control values","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"by reading replacement values from a file","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_import - set up problem data structures and fixed","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"values","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_import_m - (optional) set up problem data structures","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"and fixed values for the scaling matrix M, if any","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_import_a - (optional) set up problem data structures","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"and fixed values for the constraint matrix A, if any","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_reset_control (optional) - possibly change control","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_solve_problem - solve the regularised quadratic problem\nrqs_information (optional) - recover information about","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"the solution and solution process","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"rqs_terminate - deallocate data structures","category":"page"},{"location":"rqs/#Unsymmetric-matrix-storage-formats","page":"rqs","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"rqs/#Dense-storage-format","page":"rqs","title":"Dense storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"rqs/#Sparse-co-ordinate-storage-format","page":"rqs","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"rqs/#Sparse-row-wise-storage-format","page":"rqs","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"rqs/#Symmetric-matrix-storage-formats","page":"rqs","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Likewise, the symmetric n by n objective Hessian matrix H and scaling matrix M may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal). In what follows, we refer to H but this applies equally to M.","category":"page"},{"location":"rqs/#Dense-storage-format-2","page":"rqs","title":"Dense storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"rqs/#Sparse-co-ordinate-storage-format-2","page":"rqs","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"rqs/#Sparse-row-wise-storage-format-2","page":"rqs","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"rqs/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"rqs","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"rqs/","page":"rqs","title":"rqs","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"icfs/#Introduction","page":"icfs","title":"Introduction","text":"","category":"section"},{"location":"icfs/#Purpose","page":"icfs","title":"Purpose","text":"","category":"section"},{"location":"icfs/","page":"icfs","title":"icfs","text":"Given a symmetric matrix bmA, this package ** computes a symmetric, positive-definite approximation bmL bmL^T using an incomplete Cholesky factorization**; the resulting matrix bmL is lower triangular. Subsequently, the solution bmx to the either of the linear systems bmL bmx = bmb and bmL^T bmx = bmb may be found for a given vector bmb.","category":"page"},{"location":"icfs/#Authors","page":"icfs","title":"Authors","text":"","category":"section"},{"location":"icfs/","page":"icfs","title":"icfs","text":"C.-J, Lin and J. J. Moré, Argonne National Laboratory,","category":"page"},{"location":"icfs/","page":"icfs","title":"icfs","text":"C interface, additionally N. I. M. Gould and J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"icfs/","page":"icfs","title":"icfs","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"icfs/#Originally-released","page":"icfs","title":"Originally released","text":"","category":"section"},{"location":"icfs/","page":"icfs","title":"icfs","text":"May 1998, C interface December 2022.","category":"page"},{"location":"lsqp/#Introduction","page":"lsqp","title":"Introduction","text":"","category":"section"},{"location":"lsqp/#Purpose","page":"lsqp","title":"Purpose","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"This package uses a primal-dual interior-point trust-region method to solve the linear or separable convex quadratic programming  problem \\mbox{minimize}\\;\\; \\frac{1}{2} \\sum{j=1}^n wj^2 ( xj - xj^0 )^2","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"g^T x + f $","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"\\n  minimize 1/2 \\sum{j=1}^n wj^2 ( xj - xj^0 )^2+ g^T x + f \\n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the vectors g, w, x^0, c^l, c^u, x^l,x^u and the scalar f are given. Any of the constraint bounds ci^l c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix A of vectors a_i.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"In the special case where w = 0, g = 0 and f = 0, the so-called analytic center of the feasible set will be found, while linear programming, or constrained least distance, problems may be solved by picking w = 0, or g = 0 and f = 0, respectively.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The more-modern GALAHAD package CQP offers similar functionality, and is often to be preferred.","category":"page"},{"location":"lsqp/#Authors","page":"lsqp","title":"Authors","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England, and Philippe L. Toint, University of Namur, Belgium.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lsqp/#Originally-released","page":"lsqp","title":"Originally released","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"October 2001, C interface January 2022.","category":"page"},{"location":"lsqp/#Terminology","page":"lsqp","title":"Terminology","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm W^2 (x -x^0) + g = A^T y + z  \\n (2a) W^2 (x -x^0) + g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"lsqp/#Method","page":"lsqp","title":"Method","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"When w neq 0 or g neq 0, the method aims at each stage to reduce the overall violation of (1a), (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c y y^l y^u z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c y y^l y^u z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (1a), (2a) and a parameterized “residual trajectory” perturbation of (3). An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1b) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate. The \"Schur-complement\" approach is usually to be preferred when all the weights are nonzero or when every variable is bounded (at least one side), but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"When w = 0 and g = 0, the method aims instead firstly to find an interior primal feasible point, that is to ensure that (1a) is satisfied. One this has been achieved, attention is switched to mninizing the potential function [\\phi (x,\\;c) =  \\sum{i=1}^{m} \\log ( c{i}-c_{i}^{l} )","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"\\sum{i=1}^{m} \\log ( c{i}^{u}-c_{i} )\n\\sum{j=1}^{n} \\log ( x{j}-x_{j}^{l} )\n\\sum{j=1}^{n} \\log ( x{j}^{u}-x_{j} ),]","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"phi (xc) =\n sum_i=1^m log ( c_i-c_i^l )\n + sum_i=1^m log ( c_i^u-c_i )\n + sum_j=1^n log ( x_j-x_j^l )\n + sum_j=1^n log ( x_j^u-x_j ) ","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"\\n phi(x,c) = sum{i=1}^m log (ci-ci^l)+ sum{i=1}^m log (ci^u-ci ) + sum{j=1}^n log (xj-xj^l ) + sum{j=1}^n log (xj^u-xj ) \\n while ensuring that (1a) remain satisfied and that x and c are strictly interior points for (1b). The global minimizer of this minimization problem is known as the analytic center of the feasible region, and may be viewed as a feasible point that is as far from the boundary of the constraints as possible. Note that terms in the above sumations corresponding to infinite bounds are ignored, and that equality constraints are treated specially. Appropriate \"primal\" Newton corrections are used to generate a sequence of improving points converging to the analytic center, while the iteration is stabilized by performing inesearches along these corrections with respect to phi(xc).","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"In order to make the solution as efficient as possible, the variables and constraints are reordered internally by the GALAHAD package QPP prior to solution.In particular, fixed variables, and free (unbounded on both sides) constraints are temporarily removed. Optionally, the problem may be pre-processed temporarily to eliminate dependent constraints using the GALAHAD package FDC. This may improve the performance of the subsequent iteration.","category":"page"},{"location":"lsqp/#Reference","page":"lsqp","title":"Reference","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"with a number of enhancements described by","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"A. R. Conn, N. I. M. Gould, D. Orban and Ph. L. Toint (1999). A primal-dual trust-region algorithm for minimizing a non-convex function subject to general inequality and linear equality constraints. Mathematical Programming 87 215-249.","category":"page"},{"location":"lsqp/#Call-order","page":"lsqp","title":"Call order","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"To solve a given problem, functions from the lsqp package must be called in the following order:","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_initialize - provide default control parameters and","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"set up initial data structures","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_read_specfile (optional) - override control values","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"by reading replacement values from a file","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_import - set up problem data structures and fixed","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"values","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_reset_control (optional) - possibly change control","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_solve_qp - solve the quadratic program\nlsqp_information (optional) - recover information about","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"the solution and solution process","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"lsqp_terminate - deallocate data structures","category":"page"},{"location":"lsqp/#Unsymmetric-matrix-storage-formats","page":"lsqp","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"lsqp/#Dense-storage-format","page":"lsqp","title":"Dense storage format","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"lsqp/#Sparse-co-ordinate-storage-format","page":"lsqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"lsqp/#Sparse-row-wise-storage-format","page":"lsqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"lsqp/","page":"lsqp","title":"lsqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"lms/#Introduction","page":"lms","title":"Introduction","text":"","category":"section"},{"location":"lms/#Purpose","page":"lms","title":"Purpose","text":"","category":"section"},{"location":"lms/","page":"lms","title":"lms","text":"Given a sequence of vectors s_k and y_k \\mbox{and scale factors} delta_k, {s<sub>k</sub>} and {y<sub>k</sub>} and scalars {&#948<sub>k</sub>}, {sk} and {yk} and scalars {deltak}, **obtain the product of a limited-memory secant approximation Hk$ (or its inverse) with a given vector**, using one of a variety of well-established formulae.","category":"page"},{"location":"lms/","page":"lms","title":"lms","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"lms/#Authors","page":"lms","title":"Authors","text":"","category":"section"},{"location":"lms/","page":"lms","title":"lms","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lms/","page":"lms","title":"lms","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lms/","page":"lms","title":"lms","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lms/#Originally-released","page":"lms","title":"Originally released","text":"","category":"section"},{"location":"lms/","page":"lms","title":"lms","text":"July 2014, C interface January 2022.","category":"page"},{"location":"lms/#Method","page":"lms","title":"Method","text":"","category":"section"},{"location":"lms/","page":"lms","title":"lms","text":"Given a sequence of vectors s_k and y_k \\mbox{and scale factors} delta_k, {s<sub>k</sub>} and {y<sub>k</sub>} and scalars {&#948<sub>k</sub>}, {sk} and {yk} and scalars {deltak}, a limited-memory secant approximation Hk$ is chosen  so that H_max(k-m0) = delta_k I, H_k-j s_k-j = y_k-j  and  H_k-j+1 - H_k-j is “small” for j = min(k-1m-1) ldots 0. Different ways of quantifying “small” distinguish different methods, but the crucial observation is that it is possible to construct H_k quickly from s_k, y_k and delta_k,  and to apply it and its inverseto a given vector v.  It is also possible to apply similar formulae to the “shifted” matrix H_k + lambda_k I that occurs in trust-region methods.","category":"page"},{"location":"lms/#Reference","page":"lms","title":"Reference","text":"","category":"section"},{"location":"lms/","page":"lms","title":"lms","text":"The basic methods are those given by","category":"page"},{"location":"lms/","page":"lms","title":"lms","text":"R. H. Byrd, J. Nocedal and R. B. Schnabel (1994) Representations of quasi-Newton matrices and their use in limited memory methods. Mathenatical Programming, 63(2) 129-156,","category":"page"},{"location":"lms/","page":"lms","title":"lms","text":"with obvious extensions.","category":"page"},{"location":"psls/#Introduction","page":"psls","title":"Introduction","text":"","category":"section"},{"location":"psls/#Purpose","page":"psls","title":"Purpose","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"Given an n by nsparse symmetric matrix A =a_ij, this package builds a suitable symmetric, positive definite (or diagonally dominant)-preconditioner P of A or a symmetric sub-matrix thereof. The matrix A need not be definite. Facilities are provided to apply the preconditioner to a given vector, and to remove rows and columns (symmetrically) from the initial preconditioner without a full re-factorization.","category":"page"},{"location":"psls/#Authors","page":"psls","title":"Authors","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"psls/#Originally-released","page":"psls","title":"Originally released","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"April 2008, C interface January 2022.","category":"page"},{"location":"psls/#Method-and-references","page":"psls","title":"Method and references","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"The basic preconditioners are described in detail in Section 3.3.10 of","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint (1992). LANCELOT. A fortran package for large-scale nonlinear optimization (release A). Springer Verlag Series in Computational Mathematics 17, Berlin,","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"along with the more modern versions implements in ICFS due to","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"C.-J. Lin and J. J. More' (1999). Incomplete Cholesky factorizations with limited memory. SIAM Journal on Scientific Computing 21 21-45,","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"and in HSL_MI28 described by","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"J. A. Scott and M. Tuma (2013). HSL MI28: an efficient and robust limited-memory incomplete Cholesky factorization code. ACM Transactions on Mathematical Software 40(4) (2014), Article 24.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"The factorization methods used by the GALAHAD package SLS in conjunction with some preconditioners are described in the documentation to that package. The key features of the external solvers supported by SLS are given in the following table.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"(ignore next paragraph - doxygen bug!)","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"<table> <caption>External solver characteristics</caption> <tr><th> solver <th> factorization <th> indefinite A <th> out-of-core <th> parallelised <tr><td> SILS/MA27 <td> multifrontal <td> yes <td> no <td> no <tr><td> HSLMA57 <td> multifrontal <td> yes <td> no <td> no <tr><td> HSLMA77 <td> multifrontal <td> yes <td> yes <td> OpenMP core <tr><td> HSLMA86 <td> left-looking <td> yes <td> no <td> OpenMP fully <tr><td> HSLMA87 <td> left-looking <td> no <td> no <td> OpenMP fully <tr><td> HSLMA97 <td> multifrontal <td> yes <td> no <td> OpenMP core <tr><td> SSIDS <td> multifrontal <td> yes <td> no <td> CUDA core <tr><td> PARDISO <td> left-right-looking <td> yes <td> no <td> OpenMP fully <tr><td> MKLPARDISO <td> left-right-looking <td> yes <td> optionally  <td> OpenMP fully <tr><td> WSMP <td> left-right-looking <td> yes <td> no <td> OpenMP fully <tr><td> POTR <td> dense <td> no <td> no <td> with parallel LAPACK <tr><td> SYTR <td> dense <td> yes <td> no <td> with parallel LAPACK <tr><td> PBTR <td> dense band <td> no <td> no <td> with parallel LAPACK </table>","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"External solver characteristics (ooc = out-of-core factorization)","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"solver factorization indefinite Aoocparallelised  SILS/MA27 multifrontalyes nono  HSLMA57multifrontalyes nono  HSLMA77multifrontalyesyesOpenMP core  HSLMA86left-lookingyes noOpenMP fully  HSLMA87left-looking no noOpenMP fully  HSLMA97multifrontalyes noOpenMP core  SSIDS multifrontalyes noCUDA core  PARDISO left-right-lookingyes noOpenMP fully  MKLPARDISO left-right-lookingyesoptionallyOpenMP fully  WSMPleft-right-lookingyes noOpenMP fully  POTRdenseno nowith parallel LAPACK  SYTRdense yes nowith parallel LAPACK  PBTRdense band no nowith parallel LAPACK","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"Note that ** the solvers themselves do not form part of this package and must be obtained separately.** Dummy instances are provided for solvers that are unavailable.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"Orderings to reduce the bandwidth, as implemented in HSL's MC61, are due to","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"J. K. Reid and J. A. Scott (1999) Ordering symmetric sparse matrices for small profile and wavefront International Journal for Numerical Methods in Engineering 45 1737-1755.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"If a subset of the rows and columns are specified, the remaining rows/columns are removed before processing. Any subsequent removal of rows and columns is achieved using the GALAHAD Schur-complement updating package SCU unless a complete re-factorization is likely more efficient.","category":"page"},{"location":"psls/#Call-order","page":"psls","title":"Call order","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"To solve a given problem, functions from the psls package must be called in the following order:","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_initialize - provide default control parameters and","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"set up initial data structures","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_read_specfile (optional) - override control values","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"by reading replacement values from a file","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_import - set up matrix data structures for A","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"prior to solution","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_reset_control (optional) - possibly change control","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"one of\npslsformpreconditioner - form and factorize a","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"preconditioner P of the matrix A","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"pslsformsubset_preconditioner - form and factorize a","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"preconditioner P of a symmetric submatrix of the matrix A","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"pslsupdatepreconditioner (optional) - update the","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"preconditioner P when rows (amd columns) are removed","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"pslsapplypreconditioner - solve the linear system of","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"equations Px=b","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_information (optional) - recover information about","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"the preconditioner and solution process","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"psls_terminate - deallocate data structures","category":"page"},{"location":"psls/#Symmetric-matrix-storage-formats","page":"psls","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"The symmetric n by n coefficient matrix A may be presented and stored in a variety of convenient input formats.Crucially symmetry is exploitedby only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"psls/","page":"psls","title":"psls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"psls/#Dense-storage-format","page":"psls","title":"Dense storage format","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since A is symmetric, only the lower triangular part (that is the part A_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array val will hold the value A_ij (and, by symmetry, A_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"psls/#Sparse-co-ordinate-storage-format","page":"psls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays row and col and real array val, respectively, while the number of nonzeros is recorded as ne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"psls/#Sparse-row-wise-storage-format","page":"psls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"psls/","page":"psls","title":"psls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array ptr holds the position of the first entry in this row, while ptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values A_ij of theentries in the i-th row are stored in components l = ptr(i), ldots, ptr(i+1)-1 of the integer array col, and real array val, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"sils/#Introduction","page":"sils","title":"Introduction","text":"","category":"section"},{"location":"sils/#Purpose","page":"sils","title":"Purpose","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"This package solves sparse symmetric system of linear equations.. Given an n by n sparse matrix A = a_ij, and an n vector b, the package solves the system A x = b. The matrix A need not be definite. There is an option for iterative refinement.","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces. Extended functionality is available using the GALAHAD package sls.","category":"page"},{"location":"sils/#Authors","page":"sils","title":"Authors","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"sils/#Originally-released","page":"sils","title":"Originally released","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"April 2001, C interface December 2021.","category":"page"},{"location":"sils/#Method","page":"sils","title":"Method","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"The method used is a direct method based on a sparse variant of Gaussian elimination and is discussed further by","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"I. S. Duff and J. K. Reid (1983), ACM Trans. Math. Software 9 pp.302-325.","category":"page"},{"location":"sils/#Symmetric-matrix-storage-formats","page":"sils","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"The symmetric n by n coefficient matrix A may be presented and stored in a variety of convenient input formats.Crucially symmetry is exploitedby only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"sils/","page":"sils","title":"sils","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"sils/#Dense-storage-format","page":"sils","title":"Dense storage format","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since A is symmetric, only the lower triangular part (that is the part A_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array val will hold the value A_ij (and, by symmetry, A_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"sils/#Sparse-co-ordinate-storage-format","page":"sils","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays row and col and real array val, respectively, while the number of nonzeros is recorded as ne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"sils/#Sparse-row-wise-storage-format","page":"sils","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"sils/","page":"sils","title":"sils","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array ptr holds the position of the first entry in this row, while ptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values A_ij of theentries in the i-th row are stored in components l = ptr(i), ldots, ptr(i+1)-1 of the integer array col, and real array val, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"convert/#Introduction","page":"convert","title":"Introduction","text":"","category":"section"},{"location":"convert/#Purpose","page":"convert","title":"Purpose","text":"","category":"section"},{"location":"convert/","page":"convert","title":"convert","text":"Given a real matrix A stored in one format, convert it to another","category":"page"},{"location":"convert/","page":"convert","title":"convert","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"convert/#Authors","page":"convert","title":"Authors","text":"","category":"section"},{"location":"convert/","page":"convert","title":"convert","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"convert/","page":"convert","title":"convert","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"convert/","page":"convert","title":"convert","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"convert/#Originally-released","page":"convert","title":"Originally released","text":"","category":"section"},{"location":"convert/","page":"convert","title":"convert","text":"June 2014, C interface February 2022.","category":"page"},{"location":"roots/#Introduction","page":"roots","title":"Introduction","text":"","category":"section"},{"location":"roots/#Purpose","page":"roots","title":"Purpose","text":"","category":"section"},{"location":"roots/","page":"roots","title":"roots","text":"Use classical formulae together with Newton’s method to find all the real roots of a real polynomial.","category":"page"},{"location":"roots/","page":"roots","title":"roots","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"roots/#Authors","page":"roots","title":"Authors","text":"","category":"section"},{"location":"roots/","page":"roots","title":"roots","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"roots/","page":"roots","title":"roots","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"roots/","page":"roots","title":"roots","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"roots/#Originally-released","page":"roots","title":"Originally released","text":"","category":"section"},{"location":"roots/","page":"roots","title":"roots","text":"April 2005, C interface January 2022.","category":"page"},{"location":"roots/#Method","page":"roots","title":"Method","text":"","category":"section"},{"location":"roots/","page":"roots","title":"roots","text":"Littlewood and Ferrari's algorithms are used to find estimates of the real roots of cubic and quartic polynomials, respectively; a stabilized version of the well-known formula is used in the quadratic case. Newton's method is used to further refine the computed roots if necessary.Madsen and Reid's method is used for polynomials whose degree exceeds four.","category":"page"},{"location":"nls/#Introduction","page":"nls","title":"Introduction","text":"","category":"section"},{"location":"nls/#Purpose","page":"nls","title":"Purpose","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"This package uses a regularization method to find a (local) unconstrained minimizer of a differentiable weighted sum-of-squares objective function mathbff(x) =  frac12 sum_i=1^m w_i^ c_i^2(x) equiv frac12 c(x)^2_W \\n f(x):= 1/2 sum{i=1}^m wi ci^2(x) = 1/2 ||c(x)||^2W \\n of many variables mathbfx involving positive weights mathbfw_i, mathbfi=1ldotsm. The method offers the choice of direct and iterative solution of the key regularization subproblems, and is most suitable for large problems. First derivatives of the <i>residual function</i> c(x) are required, and if second derivatives of the c_i(x) can be calculated, they may be exploited–-if suitable products of the first or second derivatives with a vector may be found but not the derivatives themselves, that can also be used to advantage.","category":"page"},{"location":"nls/#Authors","page":"nls","title":"Authors","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"nls/#Originally-released","page":"nls","title":"Originally released","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"October 2016, C interface August 2021.","category":"page"},{"location":"nls/#Terminology","page":"nls","title":"Terminology","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The gradient nabla_x f(x) of a function f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"The algorithm used by the package is iterative. From the current best estimate of the minimizer x_k, a trial improved point x_k + s_k is sought. The correction s_k is chosen to improve a model m_k(s) of %the stabilised objective function f_rhop(x_k+s) built around the objective function f(x_k+s) built around x_k. The model is the sum of two basic components, a suitable approximation t_k(s) of f(x_k+s), %another approximation of (rhor) x_k+s_r^r (if rho  0), and a regularization term (sigma_kp) s_S_k^p involving a weight sigma_k, power p and a norm s_S_k = sqrts^T S_k s for a given positive definite scaling matrix S_k that is included to prevent large corrections. The weightsigma_k is adjusted as the algorithm progresses toensure convergence.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"The model t_k(s) is a truncated Taylor-series approximation, and this relies on being able to compute or estimate derivatives of c(x). Various models are provided, and each has different derivative requirements. We denote the m by n <i>residual Jacobian</i> J(x) equiv nabla_x c(x) as the matrixwhose ij-th component J(x)_ij = partial c_i(x)  partial x_j  mboxfor i=1ldotsm and j=1ldotsn.}$ \\n J(x){i,j} := partial ci(x) / \\partial xj \\n \\manonly for i=1,...,m and j=1,...,n.For a given m-vector y, the <i>weighted-residual Hessian</i> is the sum H(x,y) := \\sum{\\ell=1}^m y\\ell H\\ell(x), \\;\\; \\mbox{where}\\;\\; H\\ell(x){i,j} := \\partial^2 c\\ell(x) / \\partial xi \\partial xj \\;\\; \\mbox{for ij=1ldotsn}$ \\n H(x,y) := sum{\\ell=1}^m y\\ell H\\ell(x), where \\n Hl(x){i,j} := partial^2 cl(x) / partial xi partial xj \\n for i,j=1,...,nis the Hessian of c\\ell(x) Finally for a given vector v, we define the <i>residual-Hessians-vector product matrix</i> P(xv) = (H_1(x) v ldots H_m(x) v) \\n P(x,v) := (H1(x) v, ..., Hm(x) v). \\n The models t_k(s) provided are, -# the first-order Taylor approximation f(x_k) + g(x_k)^T s, where g(x) = J^T(x) W c(x), -# a barely second-order approximation f(x_k) + g(x_k)^T s + frac12 s^T W s, -# the Gauss-Newton approximation frac12  c(x_k) + J(x_k) s^2_W, -# the Newton (second-order Taylor) approximation f(x_k) + g(x_k)^T s + frac12 s^T  J^T(x_k) W J(x_k) + H(x_kW c(x_k)) s, and -# the tensor Gauss-Newton approximation frac12  c(x_k) + J(x_k) s +  frac12 s^T cdot P(x_ks) ^2_W, where the i-th component of s^T cdot P(x_ks) is shorthand for the scalar s^T H_i(x_k) s, where W is the diagonal matrix of weights w_i, i = 1 ldots m.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"Access to a particular model requires that the user is either able to provide the derivatives needed (“<i>matrix available</i>”) or that the products of these derivatives (and their transposes) with specified vectors are possible (“<i>matrix free</i>”).","category":"page"},{"location":"nls/#Method","page":"nls","title":"Method","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"An adaptive regularization method is used. In this, an improvement to a current estimate of the required minimizer, x_k is sought by computing a step s_k. The step is chosen to approximately minimize a model t_k(s) of f_rhor(x_k+s) that includes a weighted regularization term (sigma_kp) s_S_k^p for some specified positive weight sigma_k. The quality of the resulting step s_k is assessed by computing the \"ratio\" %(f_rhop(x_k) - f_rhop(x_k+s_k))(t_k(0)-t_k(s_k)). (f(x_k) - f(x_k + s_k))(t_k(0) - t_k(s_k)). The step is deemed to have succeeded if the ratio exceeds a given eta_s  0, and in this case x_k+1 = x_k + s_k. Otherwise x_k+1 = x_k, and the weight is increased by powers of a given increase factor up to a given limit. If the ratio is larger than eta_v geq eta_d, the weight will be decreased by powers of a given decrease factor again up to a given limit. The method will terminate as soon as f(x_k) or nabla_x f(x_k) is smaller than a specified value.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"A choice of linear, quadratic or quartic models t_k(s) is available (see the \\ref section), and normally a two-norm regularization willbe used, but this may change if preconditioning is employed.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"If linear or quadratic models are employed, an appropriate, approximate model minimizer is found using either a direct approach involving factorization of a shift of the model Hessian B_k or an iterative (conjugate-gradient/Lanczos) approach based on approximations to the required solution from a so-called Krlov subspace. The direct approach is based on the knowledge that the required solution satisfies the linear system of equations (B_k + lambda_k I) s_k = - nabla_x f(x_k) involving a scalar Lagrange multiplier lambda_k. This multiplier is found by uni-variate root finding, using a safeguarded Newton-like process, by the GALAHAD packages RQS. The iterative approach uses the GALAHAD packag GLRT, and is best accelerated by preconditioning with good approximations to the Hessian of the model using GALAHAD's PSLS. The iterative approach has the advantage that only Hessian matrix-vector products are required, and thus the Hessian B_k is not required explicitly. However when factorizations of the Hessian are possible, the direct approach is often more efficient.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"When a quartic model is used, the model is itself of least-squares form, and the package calls itself recursively to approximately minimize its model. The quartic model often gives a better approximation, but at the cost of more involved derivative requirements.","category":"page"},{"location":"nls/#Reference","page":"nls","title":"Reference","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The generic adaptive cubic regularization method is described in detail in","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"C. Cartis,N. I. M. Gould and Ph. L. Toint, “Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results”, Mathematical Programming 127(2) (2011) 245-295,","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"and uses “tricks” as suggested in","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"N. I. M. Gould, M. Porcelli and Ph. L. Toint, “Updating the regularization parameter in the adaptive cubic regularization algorithm”. Computational Optimization and Applications 53(1) (2012) 1-22.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"The specific methods employed here are discussed in","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"N. I. M. Gould, J. A. Scott and T. Rees, “Convergence and evaluation-complexity analysis of a regularized tensor-Newton method for solving nonlinear least-squares problems”. Computational Optimization and Applications 73(1) (2019) 1–35.","category":"page"},{"location":"nls/#Call-order","page":"nls","title":"Call order","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"To solve a given problem, functions from the nls package must be called in the following order:","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_initialize - provide default control parameters and","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"set up initial data structures","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_read_specfile (optional) - override control values","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"by reading replacement values from a file","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_import - set up problem data structures and fixed","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"values","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_reset_control (optional) - possibly change control","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"solve the problem by calling one of\nnls_solve_with_mat - solve using function calls to","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_solve_without_mat - solve using function calls to","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_information (optional) - recover information about","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"the solution and solution process","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"nls_terminate - deallocate data structures","category":"page"},{"location":"nls/#Unsymmetric-matrix-storage-formats","page":"nls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The unsymmetric m by n Jacobian matrix J equiv nabla_x c(x) and the residual-Hessians-vector product matrix P(xv) may be presented and stored in a variety of convenient input formats. Let A be J or P as appropriate.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"nls/","page":"nls","title":"nls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"nls/#Dense-storage-format","page":"nls","title":"Dense storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"nls/#unsymmetric_matrix*dense*cols-Dense-by-columns-storage-format","page":"nls","title":"unsymmetric_matrixdensecols Dense by columns storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The matrix A is stored as a compactdense matrix by columns, that is, the values of the entries of each column in turn are stored in order within an appropriate real one-dimensional array. In this case, component m ast j + iof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"nls/#Sparse-co-ordinate-storage-format","page":"nls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"nls/#Sparse-row-wise-storage-format","page":"nls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"nls/#unsymmetric_matrix*column*wise-Sparse-column-wise-storage-format","page":"nls","title":"unsymmetric_matrixcolumnwise Sparse column-wise storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Once again only the nonzero entries are stored, but this time they are ordered so that those in column j appear directly before those in column j+1. For the j-th column of A the j-th component of the integer array Aptr holds the position of the first entry in this column, while Aptr(n) holds the total number of entries plus one. The row indices i, 0 leq i leq m-1, and values A_ij of thenonzero entries in the j-th columnsare stored in components l = Aptr(j), ldots, Aptr(j+1)-1, 0 leq j leq n-1, of the integer array Arow, and real array Aval, respectively. As before, for sparse matrices, this scheme almost always requires less storage than the co-ordinate format.","category":"page"},{"location":"nls/#Symmetric-matrix-storage-formats","page":"nls","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Likewise, the symmetric n by n weighted-residual Hessian matrix H = H(xy) may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"nls/#Dense-storage-format-2","page":"nls","title":"Dense storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"nls/#Sparse-co-ordinate-storage-format-2","page":"nls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"nls/#Sparse-row-wise-storage-format-2","page":"nls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"nls/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"nls","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"nls/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"nls","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"nls/#symmetric_matrix_identity-The-identity-matrix-format","page":"nls","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"nls/#symmetric_matrix_zero-The-zero-matrix-format","page":"nls","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"nls/","page":"nls","title":"nls","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"sec/#Introduction","page":"sec","title":"Introduction","text":"","category":"section"},{"location":"sec/#Purpose","page":"sec","title":"Purpose","text":"","category":"section"},{"location":"sec/","page":"sec","title":"sec","text":"Build and update dense BFGS and SR1 secant approximations to a Hessian.","category":"page"},{"location":"sec/","page":"sec","title":"sec","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"sec/#Authors","page":"sec","title":"Authors","text":"","category":"section"},{"location":"sec/","page":"sec","title":"sec","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"sec/","page":"sec","title":"sec","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"sec/","page":"sec","title":"sec","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"sec/#Originally-released","page":"sec","title":"Originally released","text":"","category":"section"},{"location":"sec/","page":"sec","title":"sec","text":"May 2008, C interface January 2022.","category":"page"},{"location":"ugo/#Introduction","page":"ugo","title":"Introduction","text":"","category":"section"},{"location":"ugo/#Purpose","page":"ugo","title":"Purpose","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"The ugo package aims to find the global minimizer of a univariate twice-continuously differentiable function f(x) of a single variable over the finite interval x^l leq x leq x^u. Function and derivative values may be provided either via a subroutine call, or by a return to the calling program. Second derivatives may be used to advantage if they are available.","category":"page"},{"location":"ugo/#Authors","page":"ugo","title":"Authors","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"ugo/#Originally-released","page":"ugo","title":"Originally released","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"July 2016, C interface August 2021.","category":"page"},{"location":"ugo/#Method","page":"ugo","title":"Method","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"The algorithm starts by splitting the interval x^lx^u into a specified number of subintervals x_ix_i+1 of equal length, and evaluating f and its derivatives at each x_i. A surrogate (approximating) lower bound function is constructed on each subinterval using the function and derivative values at each end, and an estimate of the first- and second-derivative Lipschitz constant. This surrogate is minimized, the true objective evaluated at the best predicted point, and the corresponding interval split again at this point. Any interval whose surrogate lower bound value exceeds an evaluated actual value is discarded. The method continues until only one interval of a maximum permitted width remains.","category":"page"},{"location":"ugo/#References","page":"ugo","title":"References","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"Many ingredients in the algorithm are based on the paper","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"D. Lera and Ya. D. Sergeyev (2013), “Acceleration of univariate global optimization algorithms working with Lipschitz functions and Lipschitz first derivatives” SIAM J. Optimization Vol. 23, No. 1, pp. 508–529,","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"but adapted to use second derivatives.","category":"page"},{"location":"ugo/#Call-order","page":"ugo","title":"Call order","text":"","category":"section"},{"location":"ugo/","page":"ugo","title":"ugo","text":"To solve a given problem, functions from the ugo package must be called in the following order:","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_initialize - provide default control parameters and","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"set up initial data structures","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_read_specfile (optional) - override control values","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"by reading replacement values from a file","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_import - set up problem data structures and fixed","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"values","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_reset_control (optional) - possibly change control","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"solve the problem by calling one of\nugo_solve_direct - solve using function calls to","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"evaluate function and derivative values, or","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_solve_reverse - solve returning to the","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"calling program to obtain function and derivative values","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_information (optional) - recover information about","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"the solution and solution process","category":"page"},{"location":"ugo/","page":"ugo","title":"ugo","text":"ugo_terminate - deallocate data structures","category":"page"},{"location":"fit/#Introduction","page":"fit","title":"Introduction","text":"","category":"section"},{"location":"fit/#Purpose","page":"fit","title":"Purpose","text":"","category":"section"},{"location":"fit/","page":"fit","title":"fit","text":"Fit polynomials to function and derivative data.","category":"page"},{"location":"fit/","page":"fit","title":"fit","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"fit/#Authors","page":"fit","title":"Authors","text":"","category":"section"},{"location":"fit/","page":"fit","title":"fit","text":"N. I. M. Gould and D. P. Robinson, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"fit/","page":"fit","title":"fit","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"fit/","page":"fit","title":"fit","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"fit/#Originally-released","page":"fit","title":"Originally released","text":"","category":"section"},{"location":"fit/","page":"fit","title":"fit","text":"March 2010, C interface January 2022.","category":"page"},{"location":"wcp/#Introduction","page":"wcp","title":"Introduction","text":"","category":"section"},{"location":"wcp/#Purpose","page":"wcp","title":"Purpose","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"This package uses a primal-dual interior-point method to find a well-centered interior point x for a set of general linear constraints mbox(1)  c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  (1)ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints \\mbox{(2)} \\;\\; xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  (2) xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the vectors a{i} c^l, c^u, x^l and x^u are given. More specifically, if possible, the package finds a solution to the system ofprimal optimality equations mbox(3)  A x = c \\n (3) A x = c, \\n dual optimality equations mbox(4) hspace3mm g = A^T y + z  y = y^l + y^u mboxand  z = z^l + z^u}$ \\n (4) g = A^T y + z, y = y^l + y^u and z = z^l + z^u, \\n and perturbed complementary slackness equations mbox(5)  ( c_i - c^l_i ) y^l_i = (mu_c^l)_i mboxand ( c_i - c_i^u ) y^u_i = (mu_c^u)_i   i = 1 ldots  m \\n (ci - c^li) y^li = (muc^l)i and (ci - ci^u) y^ui = (muc^u)i, i = 1,...,m, \\n and mbox(6)  ((x_j - x^l_j ) z_j^l = (mu_x^l)_jmboxand ( x_j - x^u_j ) z_j^u = (mu_x^u)_j   j = 1 ldots  n \\n (xj - c^lj) z^lj = (mux^l)j and (xj - xj^u) z^uj = (mux^u)i, j = 1,...,n, \\n for which [ \\mbox{(7)} \\;\\; c^l \\leq c \\leq c^u, \\;\\; x^l \\leq x \\leq x^u, \\;\\; y^l \\geq 0 , \\;\\;y^u \\leq 0 , \\;\\; z^l \\geq 0 \\;\\; \\mbox{and} \\;\\; z^u \\leq 0 ] $ \\mbox{(7)} \\;\\; c^l \\leq c \\leq c^u, \\;\\; x^l \\leq x \\leq x^u, \\;\\; y^l \\geq 0 , \\;\\;y^u \\leq 0 , \\;\\; z^l \\geq 0 \\;\\; \\mbox{and} \\;\\; z^u \\leq 0 $ \\n (7) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0 \\n Here A is the matrix whose rows are the a_i^T, i = 1 ldots  m, mu_c^l, mu_c^u, mu_x^l and mu_x^u are vectors of strictly positive {\\em targets}, g is another given vector, and (y^l y^u) and (z^l z^u) are dual variables for the linear constraints and simple bounds respectively; c gives the constraint value A x. Since (5)-(7) normally imply that [ \\mbox{(8)} \\;\\; c^l < c < c^u, \\;\\; x^l < x < x^u, \\;\\; y^l > 0 , \\;\\;y^u < 0 , \\;\\; z^l > 0 \\;\\; \\mbox{and} \\;\\; z^u < 0 ] $ \\mbox{(8)} \\;\\; c^l < c < c^u, \\;\\; x^l < x < x^u, \\;\\; y^l > 0 , \\;\\;y^u < 0 , \\;\\; z^l > 0 \\;\\; \\mbox{and} \\;\\; z^u < 0 $ \\n (8) c^l < c < c^u, x^l <; x < x^u, y^l > 0, y^u < 0, z^l > 0 and z^u < 0 \\n such a primal-dual point (x c y^l y^u z^l z^l) may be used, for example, as a feasible starting point for primal-dual interior-point methods for solving the linear programming problem of minimizing g^T x subject to (1) and (2).","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Full advantage is taken of any zero coefficients in the vectors a_i.Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. The package identifies infeasible problems, and problems for which there is no strict interior, that is one or more of (8) only holds as an equality for all feasible points.","category":"page"},{"location":"wcp/#Authors","page":"wcp","title":"Authors","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"C. Cartis and N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"wcp/#Originally-released","page":"wcp","title":"Originally released","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"July 2006, C interface January 2022.","category":"page"},{"location":"wcp/#Terminology","page":"wcp","title":"Terminology","text":"","category":"section"},{"location":"wcp/#Method","page":"wcp","title":"Method","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"The algorithm is iterative, and at each major iteration attempts to find a solution to the perturbed system (3), (4), mbox(9) ( c_i - c^l_i + (theta_c^l)_i ) ( y^l_i + (theta_y^l)_i ) = (mu_c^l)_i mboxand ( c_i - c_i^u - (theta_c^u)_i ) ( y^u_i - (theta_y^u)_i ) = (mu_c^u)_i   i = 1 ldots  m \\n  ( ci - c^li + (thetac^l)i ) ( y^li + (thetay^l)i ) (9) = (muc^l)i and  ( ci - ci^u - (thetac^u)i )( y^ui - (thetay^u)i ) = (muc^u)i,i = 1,...,m \\n mbox(10) ( x_j - x^l_j + (theta_x^l)_j ) ( z^l_j + (theta_z^l)_j ) = (mu_x^l)_j mboxand ( x_j - x_j^u - (theta_x^u)_j ) ( z^u_j - (theta_z^u)_j ) = (mu_x^u)_j   j = 1 ldots  n \\n  ( xj - x^lj + (\\thetax^l)j )( z^lj + (\\thetaz^l)j ) (10) = (\\mux^l)j and  ( xj - xj^u - (\\thetax^u)j ) ( z^uj - (\\thetaz^u)j )  = (\\mux^u)j, j = 1,...,n, \\n and mbox(11) c^l - theta_c^l  c  c^u + theta_c^u  x^l - theta_x^l  x  x^u + theta_x^u   y^l  - theta_y^l    y^u  theta_y^u    z^l  - theta_z^l  mboxand   z^u  theta_z^u  \\n c^l - thetac^l < c < c^u + thetac^u, x^l - thetax^l < x < x^u + thetax^u, y^l > - thetay^l, y^u < thetay^u, z^l > - thetaz^l and z^u < thetaz^, \\n where the vectors of perturbations theta^l_c,theta^u_c,theta^l_x,theta^u_x, theta^l_x,theta^u_x,theta^l_y,theta^u_y, theta^l_z andtheta^u_z, are non-negative. Rather than solve (3)-(4) and (9)-(11) exactly, we instead seek a feasible point for the easier relaxation(3)-(4) and mbox(12) beginarrayrcccll gamma (mu_c^l)_i  leq  ( c_i - c^l_i + (theta_c^l)_i ) ( y^l_i + (theta_y^l)_i )  leq  (mu_c^l)_i  gamma  mboxand \ngamma (mu_c^u)_i  leq  ( c_i - c_i^u - (theta_c^u)_i ) ( y^u_i - (theta_y^u)_i )  leq  (mu_c^u)_i gamma  i = 1 ldots  m mboxand \ngamma (mu_x^l)_j  leq  ( x_j - x^l_j + (theta_x^l)_j ) ( z^l_j + (theta_z^l)_j )  leq  (mu_x^l)_j gamma  mboxand \ngamma (mu_x^u)_j leq  ( x_j - x_j^u - (theta_x^u)_j ) ( z^u_j - (theta_z^u)_j )  leq  (mu_x^u)_j gamma  j = 1 ldots  n endarray \\n  gamma (muc^l)i [<=] ( ci - c^li + (thetac^l)i ) ( y^li + (thetay^l)i ) [<=](muc^l)i / gamma and  gamma (muc^u)i [<=] ( ci - ci^u - (thetac^u)i ) ( y^ui - (thetay^u)i )  (12) [<=](muc^u)i, /gamma i = 1,...,m, and  gamma (mux^l)j [<=] ( xj - x^lj + (thetax^l)j ) ( z^lj + (thetaz^l)j ) [<=](mux^l)j /gamma and  gamma (mux^u)j [<=] ( xj - xj^u - (thetax^u)j ) ( z^uj - (thetaz^u)j ) [<=](mux^u)j /gamma , j = 1,...,n, \\n for some gamma in (01 which is allowed to be smaller than one if there is a nonzero perturbation.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Given any solution to (3)-(4) and (12) satisfying (11), the perturbations are reduced (sometimes to zero) so as to ensure that the current solution is feasible for the next perturbed problem. Specifically, the perturbation (theta^l_c)_i for the constraint c_i geq c^l_i is set to zero if c_i is larger than some given parameter epsilon  0. If not, but c_i is strictly positive, the perturbation will be reduced by a multiplier rho in (01). Otherwise, the new perturbation will be set to xi (theta^l_c)_i + ( 1 - xi ) ( c_i^l - c_i ) for some factor xi in (01). Identical rules are used to reduce the remaining primal and dual perturbations. The targets mu_c^l, mu_c^u, mu_x^l and mu_x^u will also be increased by the factor beta geq 1 for those (primal and/or dual) variables with strictly positive perturbations so as to try to accelerate the convergence.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Ultimately the intention is to drive all the perturbations to zero. It can be shown that if the original problem (3)-(6) and (8) has a solution, the perturbations will be zero after a finite number of major iterations. Equally, if there is no interior solution(8) the sets of (primal and dual) variables that are necessarily at (one of) their bounds for all feasible points–-we refer to these as {\\em implicit} equalities–-will be identified, as will the possibility that there is no point (interior or otherwise) in the primal and/or dual feasible regions.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Each major iteration requires the solution u = (xcz^lz^uy^ly^u) of the nonlinear system (3), (4) and (9)-(11) for fixed perturbations, using a minor iteration. The minor iteration uses a stabilized (predictor-corrector) Newton method, in which the arc u(alpha) = u + alpha dotu + alpha^2 ddotu alpha in 01 u(alpha) = u + alpha acuteu + alpha^2 ddotu alpha in 01 u(alpha) = u + alpha u' + alpha^2 u”, alpha in [0,1], \ninvolving the standard Newton step dotu &uacute; u' \nfor the equations (3), (4), (9) and (10), optionally augmented by a corrector ddotu &uuml; u” \naccount for the nonlinearity in (9) and (10), is truncated so as to ensure that (c_i(alpha) - c^l_i + (theta_c^l)_i)(y^l_i(alpha) + (theta_y^l)_i) geq tau (mu_c^l)_i mboxand (c_i(alpha) - c_i^u - (theta_c^u)_i)(y^u_i(alpha) - (theta_y^u)_i) geq tau (mu_c^u)_i  i = 1 ldots  m \\n (ci(alpha) - c^li + (thetac^l)i)(y^li(alpha) + (thetaz^l)i) [>=] tau (muc^l)i and (ci(alpha) - ci^u - (thetac^u)i ) (y^ui(alpha) - (thetaz^u)i) [>=] tau (muc^u)i, i = 1,...,m \\n and (x_j(alpha) - x^l_j + (theta_x^l)_j)(z^l_j(alpha) + (theta_z^l)_j) geq tau (mu_x^l)_j mboxand (x_j(alpha) - x_j^u - (theta_x^u)_j ) (z^u_j(alpha) - (theta_z^u)_j) geq tau (mu_x^u)_j  j = 1 ldots  n \\n (xj(alpha) - x^lj + (thetax^l)j)(z^lj(alpha) + (thetaz^l)j) [>=] tau (mux^l)j and (xj(alpha) - xj^u - (thetax^u)j ) (z^uj(alpha) - (thetaz^u)j) [>=] tau (mux^u)j, j = 1,...,n \\n for some tau in (01), always holds, and also so that the norm of the residuals to (3), (4), (9) and (10) is reduced as much as possible. The Newton and corrector systems are solved using a factorization of the Jacobian of its defining functions (the so-called “augmented system” approach) or of a reduced system in which some of the trivial equations are eliminated (the “Schur-complement” approach). The factors are obtained using the GALAHAD package SBLS.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"In order to make the solution as efficient as possible, the variables and constraints are reordered internally by the GALAHAD package QPP prior to solution. In particular, fixed variables, and free (unbounded on both sides) constraints are temporarily removed. In addition, an attempt to identify and remove linearly dependent equality constraints may be made by factorizing [ \\mat{cc}{\\alpha I & A^TE \\ AE & 0}, ] $  \\left( \\begin{array}{cc} \\alpha I & A^TE \\ AE & 0 \\end{array}, \\right) $ \\n ( alpha I AE^T ), (AE0 ) \\n where A_Edenotes the gradients of the equality constraints and alpha  0 is a given scaling factor, using the GALAHAD package SBLS, and examining small pivot blocks.","category":"page"},{"location":"wcp/#Reference","page":"wcp","title":"Reference","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"The basic algorithm, its convergence analysis and results of numerical experiments are given in","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"C. Cartis and N. I. M. Gould (2006). Finding a point n the relative interior of a polyhedron. Technical Report TR-2006-016, Rutherford Appleton Laboratory.","category":"page"},{"location":"wcp/#Call-order","page":"wcp","title":"Call order","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"To solve a given problem, functions from the wcp package must be called in the following order:","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcp_initialize - provide default control parameters and","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"set up initial data structures","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcp_read_specfile (optional) - override control values","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"by reading replacement values from a file","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcp_import - set up problem data structures and fixed","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"values","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcp_reset_control (optional) - possibly change control","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcpfindwcp - find a well-centered point\nwcp_information (optional) - recover information about","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"the solution and solution process","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"wcp_terminate - deallocate data structures","category":"page"},{"location":"wcp/#Unsymmetric-matrix-storage-formats","page":"wcp","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"wcp/#Dense-storage-format","page":"wcp","title":"Dense storage format","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"wcp/#Sparse-co-ordinate-storage-format","page":"wcp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"wcp/#Sparse-row-wise-storage-format","page":"wcp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"wcp/","page":"wcp","title":"wcp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"bqp/#Introduction","page":"bqp","title":"Introduction","text":"","category":"section"},{"location":"bqp/#Purpose","page":"bqp","title":"Purpose","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"This package usesa preconditioned, projected-gradient method to solve the convex bound-constrained quadratic programming problem mboxminimize q(x) = frac12 x^T H x + g^T x + f  n minimize q(x) = 12 x^T H x + g^T x + f n subject to the simple bound constraints x_j^lleqx_j leq x_j^u  j = 1 ldots  n \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric postive semi-definite matrix H, the vectors g, x^l, x^u and the scalar f are given. Any of the constraint bounds xj^l$ and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H; the matrix need not be provided as there are options to obtain matrix-vector products involving H by reverse communication.","category":"page"},{"location":"bqp/#Authors","page":"bqp","title":"Authors","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"bqp/#Originally-released","page":"bqp","title":"Originally released","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"November 2009, C interface February 2022.","category":"page"},{"location":"bqp/#Terminology","page":"bqp","title":"Terminology","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"The required solution x necessarily satisfies the primal optimality conditions x^l leq x leq x^u \\n  x^l [<=] x [<=] x^u, \\n the dual optimality conditions H x + g = z \\n  H x + g = z \\n where $ z = z^l + z^u, \\,\\,  z^l \\geq 0 \\;\\; \\mbox{and} \\;\\; z^u \\leq 0,$ \\n  z = z^l + z^u, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  n (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0 n where the vector z is known asthe dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"bqp/#Method","page":"bqp","title":"Method","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"The method is iterative. Each iteration proceeds in two stages. Firstly, the so-called generalized Cauchy point for the quadratic objective is found.(The purpose of this point is to ensure that the algorithm converges and that the set of bounds which are satisfied as equations at the solution is rapidly identified.)Thereafter an improvement to the objective is sought using either a direct-matrix or truncated conjugate-gradient algorithm.","category":"page"},{"location":"bqp/#Reference","page":"bqp","title":"Reference","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"This is a specialised version of the method presented in","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint (1988). Global convergence of a class of trust region algorithms for optimization with simple bounds. SIAM Journal on Numerical Analysis 25 433-460,","category":"page"},{"location":"bqp/#Call-order","page":"bqp","title":"Call order","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"To solve a given problem, functions from the bqp package must be called in the following order:","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_initialize - provide default control parameters and","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"set up initial data structures","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_read_specfile (optional) - override control values","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"by reading replacement values from a file","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"set up problem data structures and fixed values by caling one of\nbqp_import - in the case that H is explicitly","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"available","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_import_without_h - in the case that only the","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"effect of applying H to a vector is possible","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_reset_control (optional) - possibly change control","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"solve the problem by calling one of\nbqp_solvegivenh - solve the problem using values","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"of H","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_solve_reversehprod - solve the problem by returning","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"to the caller for products of H with specified vectors","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_information (optional) - recover information about","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"the solution and solution process","category":"page"},{"location":"bqp/","page":"bqp","title":"bqp","text":"bqp_terminate - deallocate data structures","category":"page"},{"location":"bqp/#Symmetric-matrix-storage-formats","page":"bqp","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"If it is explicitly available, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"bqp/#Dense-storage-format","page":"bqp","title":"Dense storage format","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"bqp/#Sparse-co-ordinate-storage-format","page":"bqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"bqp/#Sparse-row-wise-storage-format","page":"bqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"bqp/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"bqp","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"bqp/","page":"bqp","title":"bqp","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"#Home","page":"Home","title":"GALAHAD.jl documentation","text":"","category":"section"},{"location":"#Installing","page":"Home","title":"Installing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> ]\npkg> add GALAHAD","category":"page"},{"location":"gltr/#Introduction","page":"gltr","title":"Introduction","text":"","category":"section"},{"location":"gltr/#Purpose","page":"gltr","title":"Purpose","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"Given real n by n symmetric matrices H and M (with M positive definite), a real n vector c and scalars Delta0 and f_0, this package finds an ** approximate minimizer of the quadratic objective function frac12 x^T H x+c^T x + f_0, where the vector x is required to satisfy the constraint x_M leqDelta**, and where the M-norm of x is x_M = sqrtx^T M x. This problem commonly occurs as a trust-region subproblem in nonlinear optimization calculations. The method may be suitable for large n as no factorization of H is required. Reverse communication is used to obtain matrix-vector products of the form H z and M^-1 z.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"The package may also be used to solve the related problem in which x is instead required to satisfy the equality constraint x_M = Delta.","category":"page"},{"location":"gltr/#Authors","page":"gltr","title":"Authors","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"gltr/#Originally-released","page":"gltr","title":"Originally released","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"April 1997, C interface December 2021.","category":"page"},{"location":"gltr/#Terminology","page":"gltr","title":"Terminology","text":"","category":"section"},{"location":"gltr/#Method","page":"gltr","title":"Method","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"The required solution x necessarily satisfies the optimality condition H x + lambda M x + c = 0, where lambda geq 0is a Lagrange multiplier corresponding to the constraint x_MleqDelta. In addition, the matrix H + lambda M will be positive definite.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"The method is iterative. Startingwith the vector M^-1 c, a matrix of Lanczos vectors is built one column at a time so that the k-th column is generated during iteration k. These columns span a so-called Krylov space. The resulting n by k matrix Q_k  has the property that Q_k^T H Q_k^=T_k^, where T_k is tridiagonal. An approximation to the required solution may then be expressed formally as x_k+1=Q_k y_k \\n  x{k+1}=Qk yk, \\n where yk $ solves the “tridiagonal” subproblem of minimizing (1)  frac12 y^T T_k y+ c_M^-1 e_1^T ymboxsubject to the constraint y_2leqDelta \\n (1)1/2 y^T Tk y+ ||c||M^{-1} e1^T y  subject to the constraint \\|y\\|2leqDelta, \\n and where e_1 is the first unit vector.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"If the solution to (1) lies interior to the constraint, the required solution x_k+1 may simply be found as the k-th (preconditioned) conjugate-gradient iterate. This solution can be obtained without the need to access the whole matrix Q_k. These conjugate-gradient iterates  increase in M-norm, and thus once one of them exceeds Delta in M-norm, the solution must occur on the constraint boundary. Thereafter, the solution to (1) is less easy to obtain, but an efficient inner iteration to solve (1) is nonetheless achievable because T_k  is tridiagonal It is possible to observe the optimality measure H x+lambda M x+c_M^-1 without computing x_k+1, and thus without needing Q_k  Once this measure is sufficiently small a second pass is required to obtain the estimate x_k+1  from y_k  As this second pass is an additional expense a record is kept of the optimal objective function values for each value of k, and the second pass is only performed so far as to ensure a given fraction of the final optimal objective value. Large savings may be made in the second pass by choosing the required fraction to be significantly smaller than one.","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"A cheaper alternative is to use the Steihuag-Toint strategy, which is simply to stop at the first boundary point encountered along the piecewise linear path generated by the conjugate-gradient iterates. Note that if H is significantly indefinite, this strategy often produces a far from optimal point, but is effective when H is positive definite or almost","category":"page"},{"location":"gltr/#Reference","page":"gltr","title":"Reference","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"The method is described in detail in","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"N. I. M. Gould, S. Lucidi, M. Roma and Ph. L. Toint, Solving the trust-region subproblem using the Lanczos method. SIAM Journal on Optimization 9:2 (1999), 504-525.","category":"page"},{"location":"gltr/#Call-order","page":"gltr","title":"Call order","text":"","category":"section"},{"location":"gltr/","page":"gltr","title":"gltr","text":"To solve a given problem, functions from the gltr package must be called in the following order:","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_initialize - provide default control parameters and","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"set up initial data structures","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_read_specfile (optional) - override control values","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"by reading replacement values from a file","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_import_control - import control parameters prior to","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"solution","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_solve_problem - solve the problem by reverse","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"communication, a sequence of calls are made under control of a status parameter, each exit either asks the user to provide additional informaton and to re-enter, or reports that either the solution has been found or that an error has occurred","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_information (optional) - recover information about","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"the solution and solution process","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"gltr_terminate - deallocate data structures","category":"page"},{"location":"gltr/","page":"gltr","title":"gltr","text":"See Section~\\ref{examples} for an example of use. See the <a href=\"examples.html\">examples tab</a> for an illustration of use. See the examples section for an illustration of use.","category":"page"},{"location":"dgo/#Introduction","page":"dgo","title":"Introduction","text":"","category":"section"},{"location":"dgo/#Purpose","page":"dgo","title":"Purpose","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"The dgo package uses a deterministic partition-and-bound trust-region method to find an approximation to the global minimizer of a differentiable objective function f(x) of n variables x, subject to a finite set of simple bounds x^l leq x leq x^u on the variables. The method offers the choice of direct and iterative solution of the key trust-region subproblems, and is suitable for large problems. First derivatives are required, and if second derivatives can be calculated, they will be exploited–-if the product of second derivatives with a vector may be found but not the derivatives themselves, that may also be exploited.","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Although there are theoretical guarantees, these may require a large number of evaluations as the dimension and nonconvexity increase. The alternative GALAHAD package bgo may sometimes be preferred.","category":"page"},{"location":"dgo/#Authors","page":"dgo","title":"Authors","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"J. Fowkes and N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"dgo/#Originally-released","page":"dgo","title":"Originally released","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"July 2021, C interface August 2021.","category":"page"},{"location":"dgo/#Terminology","page":"dgo","title":"Terminology","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"The gradient nabla_x f(x) of f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"dgo/#Method","page":"dgo","title":"Method","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Starting with the initial box x^l leq x leq x^u, a sequence of boxes is generated by considering the current set, and partitioning a promising candidate into three equally-sized sub-boxes by splitting along one of the box dimensions. Each partition requires only a pair of new function and derivative evaluations, and these values, together with estimates of Lipschitz constants, makes it possible to remove other boxes from further consideration as soon as they cannot contain a global minimizer. Efficient control of the dictionary of vertices of the sub-boxes is handled using a suitable hashing procedure provided by the GALAHAD package hash; each sub-box is indexed by the concatenated coordinates of a pair of opposite vertices. At various stages, local minimization in a promising sub-box, using the GALAHAD package trb, may be used to improve the best-known upper bound on the global minimizer. If n=1, the specialised GALAHAD univariate global minimization package ugo is called directly.","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"We reiterate that although there are theoretical guarantees, these may require a large number of evaluations as the dimension and nonconvexity increase. Thus the method should best be viewed as a heuristic to try to find a reasonable approximation of the global minimum.","category":"page"},{"location":"dgo/#References","page":"dgo","title":"References","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"The global minimization method employed is an extension of that due to","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Ya. D. Sergeyev and D. E. Kasov (2015), “A deterministic global optimization using smooth diagonal auxiliary functions”, Communications in Nonlinear Science and Numerical Simulation, Vol 21, Nos 1-3, pp. 99-111.","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"but adapted to use 2nd derivatives, while in the special case when n=1, a simplification based on the ideas in","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"D. Lera and Ya. D. Sergeyev (2013), “Acceleration of univariate global optimization algorithms working with Lipschitz functions and Lipschitz first derivatives” SIAM J. Optimization Vol. 23, No. 1, pp. 508–529","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"is used instead. The generic bound-constrained trust-region method used for local minimization is described in detail in","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint (2000), Trust-region methods. SIAM/MPS Series on Optimization.","category":"page"},{"location":"dgo/#Call-order","page":"dgo","title":"Call order","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"To solve a given problem, functions from the dgo package must be called in the following order:","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_initialize - provide default control parameters and","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"set up initial data structures","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_read_specfile (optional) - override control values","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"by reading replacement values from a file","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_import - set up problem data structures and fixed","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"values","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_reset_control (optional) - possibly change control","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"solve the problem by calling one of\ndgo_solve_with_mat - solve using function calls to","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_solve_without_mat - solve using function calls to","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_information (optional) - recover information about","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"the solution and solution process","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"dgo_terminate - deallocate data structures","category":"page"},{"location":"dgo/#Symmetric-matrix-storage-formats","page":"dgo","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"The symmetric n by n matrix H = nabla_xxf may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"dgo/#Dense-storage-format","page":"dgo","title":"Dense storage format","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value H{ij}$ (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"dgo/#Sparse-co-ordinate-storage-format","page":"dgo","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"dgo/#Sparse-row-wise-storage-format","page":"dgo","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"dgo/","page":"dgo","title":"dgo","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"presolve/#Introduction","page":"presolve","title":"Introduction","text":"","category":"section"},{"location":"presolve/#Purpose","page":"presolve","title":"Purpose","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Presolving aims to improve the formulation of a given optimization problem by applying a sequence of simple transformations, and thereby to produce a \\a reduced problem in a \\a standard \\a form that should be simpler to solve.This reduced problem may then be passed to an appropriate solver.Once the reduced problem has been solved, it is then \\a restored to recover the solution for the original formulation.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"This package applies presolving techniques to a linear mboxminimize l(x) = g^T x + f  n minimize l(x) = g^T x + f n or **quadratic program** mboxminimize q(x) = frac12 x^T H x + g^T x + f  n minimize q(x) = 12 x^T H x + g^T x + f n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric matrix H, the vectors g, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"In addition, bounds on the Lagrange multipliers y associated with the general linear constraints and on the dual variables z associated with the simple bound constraints $ y{i}^{l}\\leqy{i}\\leqy{i}^{u}, \\;\\;\\;i = 1, \\ldots , m,$ \\n  yj^i [<=] yi [<=] yi^u, i = 1, ... , m, \\n and z_i^lleqz_ileqz_i^u i = 1 ldots  n \\n  zj^l [<=] zj [<=] z_j^u, j = 1, ... , n, \\n are also provided, where the m-dimensional vectors y^l and y^u, as well as the n-dimensional vectors x^l and x^u are given.Any component of c^l, c^u, x^l, x^u, y^l, y^u, z^l or z^u may be infinite.","category":"page"},{"location":"presolve/#Authors","page":"presolve","title":"Authors","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England and Ph. L. Toint, University of Namur, Belgium","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"presolve/#Originally-released","page":"presolve","title":"Originally released","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"March 2002, C interface March 2022.","category":"page"},{"location":"presolve/#Terminology","page":"presolve","title":"Terminology","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace58mm H x + g = A^T y + zhspace58mm}$ \\n (2a) H x + g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the vectors y and z are known as the Lagrange multipliers for2 the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"presolve/#Method","page":"presolve","title":"Method","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The purpose of presolving is to exploit these equations in order to reduce the problem to the standard form defined as follows:","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The variables are ordered so that their bounds appear in the order","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"beginarraylccccc\nmboxfree x \nmboxnon-negativity 0 leq  x \nmboxlower  x^l  leq  x  \nmboxrange  x^l  leq  x  leq  x^u\nmboxupper  x  leq  x^u \nmboxnon-positivity x  leq 0\nendarray","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"\\n free x non-negativity 0<= x lower x^l <= x range x^l <= x<= x^u upperx<= x^u non-positivity x<=0 \\n Fixed variables are removed. Within each category, the variables are further ordered so that those with non-zero diagonal Hessian entries occur before the remainder.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The constraints are ordered so that their bounds appear in the order","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"beginarraylccccc\nmboxnon-negativity  0 leq  A x \nmboxequality  c^l  = A x  \nmboxlower  c^l  leq  A x  \nmboxrange  c^l  leq  A x  leq  c^u\nmboxupper  A x  leq  c^u \nmboxnon-positivity  A x  leq  0\nendarray","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"\\n non-negativity 0<= A x equalityc^l= A x lower c^l <= A x range c^l <= A x <= c^u upperA x <= c^u non-positivity A x <=0 \\n Free constraints are removed.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"In addition, constraints may be removed or bounds tightened, to reduce the","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"size of the feasible region or simplify the problem if this is possible, and bounds may be tightened on the dual variables and the multipliers associatedwith the problem.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The presolving algorithm proceeds by applying a (potentially long) series of simple transformations to the problem, each transformation introducing a further simplification of the problem. These involve the removal of empty and singleton rows, the removal of redundant and forcing primal constraints, the tightening of primal and dual bounds, the exploitation of linear singleton, linear doubleton and linearly unconstrained columns, the merging dependent variables, row sparsification and split equalities. Transformations are applied in successive passes, each pass involving the following actions:","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"-# remove empty and singletons rows, -# try to eliminate variables that are linearly unconstrained, -# attempt to exploit the presence of linear singleton columns, -# attempt to exploit the presence of linear doubleton columns, -# complete the analysis of the dual constraints, -# remove empty and singletons rows, -# possibly remove dependent variables, -# analyze the primal constraints, -# try to make A sparser by combining its rows, -# check the current status of the variables, dual variables and multipliers.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"All these transformations are applied to the structure of the original problem, which is only permuted to standard form after all transformations are completed. <em>Note that the Hessian and Jacobian of the resulting reduced problem are always stored in sparse row-wise format.</em> The reduced problem is then solved by a quadratic or linear programming solver, thus ensuring sufficiently small primal-dual feasibility and complementarity. Finally, the solution of the simplified problem is re-translated in the variables/constraints/format of the original problem formulation by a \\a restoration phase.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"If the number of problem transformations exceeds \\p control.transfbuffersize,the transformation buffer size, then they are saved in a “history” file, whose name may be chosen by specifying the control.transffilename control parameter,When this is the case, this file is subsequently reread by \\p presolverestoresolution. It must not be altered by the user.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Overall, the presolving process follows one of the two sequences:","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"fboxinitialize rightarrow left fboxapply transformations\n rightarrow mbox(solve problem)\n rightarrow fboxrestore right rightarrow fboxterminate","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"or fboxinitialize rightarrow left fboxread specfile  rightarrow fboxapply transformations  rightarrow mbox(solve problem)  rightarrow fboxrestore right rightarrow fboxterminate  (ignore garbled doxygen phrase) \\n  –––––––[––––––––––––-  | initialize | -> [ | apply transformations | -> (solve problem) ->  –––––––[––––––––––––- –––––- ]––––––- | restore | ] -> | terminate | –––––- ]––––––-  or  –––––––[ –––––––––––––––––––––  | initialize | -> [ | read specfile | -> | apply transformations | ->  –––––––[ –––––––––––––––––––––  –––––- ]––––––- (solve problem) -> | restore | ] -> | terminate |  –––––- ]––––––- \\n","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"where the procedure's control parameter may be modified by reading the specfile, and where (solve problem) indicates that the reduced  problem is solved. Each of the “boxed” steps in these sequences corresponds to calling a specific routine of the package In the diagrams above, brackated subsequence of steps means that they can be repeated with problem having the same structure. The value of the \\p problem.newproblemstructure must be true on entry of \\p presolveapplytoproblem on the first time it is used in this repeated subsequence. Such a subsequence must be terminated by a call to\\p presolve\\terminate before presolving is applied to a problem with a different structure.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Note that the values of the multipliers and dual variables (and thus of their respective bounds) depend on the functional form assumed for the Lagrangian function associated with the problem.This form is given by L(xyz) = q x) - y_sign * y^T (Ax-c) - z_sign * z (considering only active constraints A x = c), where the parameters y{sign} and z{sign} are +1 or -1 and can be chosen by the user. Thus, if y_sign = +1, the multipliers associated to active constraints originally posed as inequalities are non-negative if the inequality is a lower bound and non-positive if it is an upper bound. Obvioulsy they are not constrained in sign for constraints originally posed as equalities. These sign conventions are reversed if y_sign = -1. Similarly, if z_sign = +1}, the dual variables associated to active bounds are non-negative if the original bound is an lower bound, non-positive if it is an upper bound, or unconstrained in sign if the variables is fixed; and this convention is reversed in z_sign = -1}. The values of z_sign and y_sign may be chosen by setting the corresponding components of the \\p control structure to \\p 1 or \\p -1.","category":"page"},{"location":"presolve/#Reference","page":"presolve","title":"Reference","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The algorithm is described in more detail in","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"N. I. M. Gould and Ph. L. Toint (2004). Presolving for quadratic programming. Mathematical Programming 100(1), pp 95–132.","category":"page"},{"location":"presolve/#Call-order","page":"presolve","title":"Call order","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"To solve a given problem, functions from the presolve package must be called in the following order:","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolve_initialize - provide default control parameters and","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"set up initial data structures","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolve_read_specfile (optional) - override control values","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"by reading replacement values from a file","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolve_import_problem - import the problem data and report","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"the dimensions of the transformed problem","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolvetransformproblem - apply the presolve algorithm","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"to transform the data","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolverestoresolution - restore the solution from","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"that of the transformed problem","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolve_information (optional) - recover information about","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"the solution and solution process","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"presolve_terminate - deallocate data structures","category":"page"},{"location":"presolve/#Unsymmetric-matrix-storage-formats","page":"presolve","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"presolve/#Dense-storage-format","page":"presolve","title":"Dense storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"presolve/#Sparse-co-ordinate-storage-format","page":"presolve","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"presolve/#Sparse-row-wise-storage-format","page":"presolve","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"presolve/#Symmetric-matrix-storage-formats","page":"presolve","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"presolve/#Dense-storage-format-2","page":"presolve","title":"Dense storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"presolve/#Sparse-co-ordinate-storage-format-2","page":"presolve","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"presolve/#Sparse-row-wise-storage-format-2","page":"presolve","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"presolve/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"presolve","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"presolve/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"presolve","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"presolve/#symmetric_matrix_identity-The-identity-matrix-format","page":"presolve","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"presolve/#symmetric_matrix_zero-The-zero-matrix-format","page":"presolve","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"presolve/","page":"presolve","title":"presolve","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"qpb/#Introduction","page":"qpb","title":"Introduction","text":"","category":"section"},{"location":"qpb/#Purpose","page":"qpb","title":"Purpose","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"This package uses a primal-dual interior-point trust-region method to solve the quadratic programming problem mboxminimize q(x) = frac12 x^T H x + g^T x + f  n minimize q(x) = 12 x^T H x + g^T x + f n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric matrix H, the vectors g, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H or the matrix A of vectors a_i.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"If the matrix H is positive semi-definite, a global solution is found. However, if H is indefinite, the procedure may find a (weak second-order) critical point that is not the global solution to the given problem.","category":"page"},{"location":"qpb/#Authors","page":"qpb","title":"Authors","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England, and Philippe L. Toint, University of Namur, Belgium.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"qpb/#Originally-released","page":"qpb","title":"Originally released","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"December 1999, C interface January 2022.","category":"page"},{"location":"qpb/#Terminology","page":"qpb","title":"Terminology","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace58mm H x + g = A^T y + zhspace58mm}$ \\n (2a) H x + g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the vectors y and z are known as the Lagrange multipliers for2 the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"qpb/#Method","page":"qpb","title":"Method","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The problem is solved in two phases. The goal of the first \"initial feasible point\" phase is to find a strictly interior point which is primal feasible, that is that {1a} is satisfied. The GALAHAD package LSQP is used for this purpose, and offers the options of either accepting the first strictly feasible point found, or preferably of aiming for the so-called \"analytic center\" of the feasible region. Having found such a suitable initial feasible point, the second \"optimality\" phase ensures that \\req{4.1a} remains satisfied while iterating to satisfy dual feasibility (2a) and complementary slackness (3).The optimality phase proceeds by approximately minimizing a sequence of barrier functions [\\frac{1}{2} x^T H x + g^T x + f -  \\mu \\left[ \\sum{i=1}^{m} \\log ( c{i}-c_{i}^{l} )","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"\\sum{i=1}^{m} \\log ( c{i}^{u}-c_{i} )\n\\sum{j=1}^{n} \\log ( x{j}-x_{j}^{l} )\n\\sum{j=1}^{n} \\log ( x{j}^{u}-x_{j} ) \\right],]","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"frac12 x^T H x + g^T x + f -\n mu left sum_i=1^m log ( c_i-c_i^l )\n + sum_i=1^m log ( c_i^u-c_i )\n + sum_j=1^n log ( x_j-x_j^l )\n + sum_j=1^n log ( x_j^u-x_j ) right","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"\\n 1/2 x^T H x + g^T x + f -  mu [ sum{i=1}^m log (ci-ci^l)+ sum{i=1}^m log (ci^u-ci ) + sum{j=1}^n log (xj-xj^l ) + sum{j=1}^n log (xj^u-xj ) ] \\n for an approriate sequence of positive barrier parameters mu converging to zero while ensuring that (1a) remain satisfied and that x and c are strictly interior points for (1b). Note that terms in the above sumations corresponding to infinite bounds are ignored, and that equality constraints are treated specially.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Each of the barrier subproblems is solved using a trust-region method. Such a method generates a trial correction step Delta (x c) to the current iterate (x c) by replacing the nonlinear barrier function locally by a suitable quadratic model, and approximately minimizing this model in the intersection of \\req{4.1a} and a trust region Delta (x c) leq Delta for some appropriate strictly positive trust-region radius Delta and norm  cdot .The step is accepted/rejected and the radius adjusted on the basis of how accurately the model reproduces the value of barrier function at the trial step. If the step proves to be unacceptable, a linesearch is performed along the step to obtain an acceptable new iterate. In practice, the natural primal \"Newton\" model of the barrier function is frequently less successful than an alternative primal-dual model, and consequently the primal-dual model is usually to be preferred.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Once a barrier subproblem has been solved, extrapolation based on values and derivatives encountered on the central path is optionally used to determine a good starting point for the next subproblem. Traditional Taylor-series extrapolation has been superceded by more accurate Puiseux-series methods as these are particularly suited to deal with degeneracy.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The trust-region subproblem is approximately solved using the combined conjugate-gradient/Lanczos method implemented in the GALAHAD package GLTR.Such a method requires a suitable preconditioner, and in our case, the only flexibility we have is in approximating the model of the Hessian. Although using a fixed form of preconditioning is sometimes effective, we have provided the option of an automatic choice, that aims to balance the cost of applying the preconditioner against the needs for an accurate solution of the trust-region subproblem.The preconditioner is applied using the GALAHAD matrix factorization package SBLS, but options at this stage are to factorize the preconditioner as a whole (the so-called \"augmented system\" approach), or to perform a block elimination first (the \"Schur-complement\" approach). The latter is usually to be prefered when a (non-singular) diagonal preconditioner is used, but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"In order to make the solution as efficient as possible, the variables and constraints are reordered internally by the GALAHAD package QPP prior to solution.In particular, fixed variables, and free (unbounded on both sides) constraints are temporarily removed.","category":"page"},{"location":"qpb/#Reference","page":"qpb","title":"Reference","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"with a number of enhancements described by","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"A. R. Conn, N. I. M. Gould, D. Orban and Ph. L. Toint (1999). A primal-dual trust-region algorithm for minimizing a non-convex function subject to general inequality and linear equality constraints. Mathematical Programming 87 215-249.","category":"page"},{"location":"qpb/#Call-order","page":"qpb","title":"Call order","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"To solve a given problem, functions from the qpb package must be called in the following order:","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_initialize - provide default control parameters and","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"set up initial data structures","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_read_specfile (optional) - override control values","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"by reading replacement values from a file","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_import - set up problem data structures and fixed","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"values","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_reset_control (optional) - possibly change control","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_solve_qp - solve the quadratic program\nqpb_information (optional) - recover information about","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"the solution and solution process","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"qpb_terminate - deallocate data structures","category":"page"},{"location":"qpb/#Unsymmetric-matrix-storage-formats","page":"qpb","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"qpb/#Dense-storage-format","page":"qpb","title":"Dense storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"qpb/#Sparse-co-ordinate-storage-format","page":"qpb","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"qpb/#Sparse-row-wise-storage-format","page":"qpb","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"qpb/#Symmetric-matrix-storage-formats","page":"qpb","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"qpb/#Dense-storage-format-2","page":"qpb","title":"Dense storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"qpb/#Sparse-co-ordinate-storage-format-2","page":"qpb","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"qpb/#Sparse-row-wise-storage-format-2","page":"qpb","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"qpb/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"qpb","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"qpb/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"qpb","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"qpb/#symmetric_matrix_identity-The-identity-matrix-format","page":"qpb","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"qpb/#symmetric_matrix_zero-The-zero-matrix-format","page":"qpb","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"qpb/","page":"qpb","title":"qpb","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"scu/#Introduction","page":"scu","title":"Introduction","text":"","category":"section"},{"location":"scu/#Purpose","page":"scu","title":"Purpose","text":"","category":"section"},{"location":"scu/","page":"scu","title":"scu","text":"Compute the the solution to an extended system of n + m sparse real linear equations in n + m unknowns, mbox(1) matcc A  B  C  D  vectx_1  x_2 =vectb_1  b_2  \\n  (1)( AB ) ( x1 ) = ( b1 ) ( CD ) ( x2 ) ( b2 )  \\n in the case where the n by n matrix A is nonsingular and solutions to the systems A x=b mboxand A^T y=c  \\n  A x=bandA^T y=c  \\n may be obtained from an external source, such as an existing factorization.The subroutine uses reverse communication to obtain the solution to such smaller systems.The method makes use of the Schur complement matrix S = D - C A^-1 B  \\n  S = D - C A^{-1} B.$  \\n The Schur complement is stored and factorized as a dense matrix and the subroutine is thus appropriate only if there is sufficient storage for this matrix. Special advantage is taken of symmetry and definiteness in the coefficient matrices. Provision is made for introducing additional rows and columns to, and removing existing rows and columns from, the extended matrix.","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"scu/#Authors","page":"scu","title":"Authors","text":"","category":"section"},{"location":"scu/","page":"scu","title":"scu","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"scu/#Originally-released","page":"scu","title":"Originally released","text":"","category":"section"},{"location":"scu/","page":"scu","title":"scu","text":"March 2005, C interface January 2022.","category":"page"},{"location":"scu/#Method","page":"scu","title":"Method","text":"","category":"section"},{"location":"scu/","page":"scu","title":"scu","text":"The subroutine galahad_factorize forms the Schur complement S = D - C A^-1 B of $ A$ in the extended matrix by repeated reverse communication to obtain the columns of A^-1 B. The Schur complement or its negative is then factorized into its QR or, if possible, Cholesky factors.","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"The subroutine galahad_solve solves the extended system using the following well-known scheme:  -# Compute the solution to $ A u=b1$;  -# Compute x2$ from $ S x2=b2-C u  - Compute the solution to  A v=B x_2; and  -# Compute x_1 = u - v.","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"The subroutines galahadappend and galahaddelete compute the factorization of the Schur complement after a row and column have been appended to, and removed from, the extended matrix, respectively. The existing factorization is updated to obtain the new one; this is normally more efficient than forming the factorization from scratch.","category":"page"},{"location":"scu/#Call-order","page":"scu","title":"Call order","text":"","category":"section"},{"location":"scu/","page":"scu","title":"scu","text":"To solve a given problem, functions from the scu package must be called in the following order:","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scu_initialize - provide default control parameters and","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"set up initial data structures","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scu_read_specfile (optional) - override control values","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"by reading replacement values from a file","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scuformand_factorize - form and factorize the","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"Schur-complement matrix S","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scu_solve_system - solve the block system (1)\nscuaddrowsandcols (optional) - update the factors of","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"the Schur-complement matrix when rows and columns are added to (1).","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scudeleterowsandcols (optional) - update the factors of","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"the Schur-complement matrix when rows and columns are removed from (1).","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scu_information (optional) - recover information about","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"the solution and solution process","category":"page"},{"location":"scu/","page":"scu","title":"scu","text":"scu_terminate - deallocate data structures","category":"page"},{"location":"lpa/#Introduction","page":"lpa","title":"Introduction","text":"","category":"section"},{"location":"lpa/#Purpose","page":"lpa","title":"Purpose","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"This package uses the ** simplex method** to solve the linear programming problem mboxminimize q(x) = g^T x + f  n minimize q(x) = g^T x + f n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the vectors g, w, x^0, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix A whose rows are the transposes of the vectors a_i.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"N.B. The package is simply a sophisticated interface to the HSL package LA04, and requires that a user has obtained the latter. ** LA04 is not included in GALAHAD** but is available without charge to recognised academics, see http://www.hsl.rl.ac.uk/catalogue/la04.html. If LA04 is unavailable, the GALAHAD interior-point linear programming package LPB is an alternative.","category":"page"},{"location":"lpa/#Authors","page":"lpa","title":"Authors","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"N. I. M. Gould and J. K. Reid, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lpa/#Originally-released","page":"lpa","title":"Originally released","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"October 2018, C interface September 2021.","category":"page"},{"location":"lpa/#Terminology","page":"lpa","title":"Terminology","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm g = A^T y + z}$ \\n (2a) g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"The so-called dual to this problem is another linear program - mboxminimize  c^lT y^l + c^uT y^u + x^lT z^l + x^uT z^u + f  mboxsubject to the constraints (2a) and (2b) \\n","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"minimize c^{lT} y^l + c^{uT} y^u + x^{lT} z^l + x^{uT} z^u + f","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"subject to the constraints (2a) and (2b) \\n that uses the same data. The solution to the two problems, it is exists, is the same, but if one is infeasible, the other is unbounded. It can be more efficient to solve the dual, particularly if m is much larger than n.","category":"page"},{"location":"lpa/#Method","page":"lpa","title":"Method","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"The bulk of the work is peformed by the HSL package LA04. The main subbroutine from this package requires that the input problem be transformed into the “standard form” [\\begin{array}{rl}\\mbox{minimize} & g^{\\prime T} x^{\\prime} \\(4)\\;\\; \\mbox{subject to} & A^{\\prime} x^{\\prime} = b \\ &li \\leq x^{\\prime}i \\leq ui, \\;\\;(i\\leq k) \\ \\mbox{and} & x^{\\prime}l \\geq 0, \\;\\; (i \\geq l) \\end{array} ] $ \\begin{array}{rl}\\mbox{minimize} & g^{\\prime T} x^{\\prime} \\(4)\\;\\; \\mbox{subject to} & A^{\\prime} x^{\\prime} = b \\ &li \\leq x^{\\prime}i \\leq ui, \\;\\;(i\\leq k) \\ \\mbox{and} & x^{\\prime}l \\geq 0, \\;\\; (i \\geq l) \\end{array} $ \\n  minimize g'^T x' (4)subject to A' x' = b li <= x'i <= ui, for i <= k and x'l >= 0, for i >= l \\n by introducing slack an surpulus variables, reordering and removing fixed variables and free constraints. The resulting problem involves n unknowns and m general constraints. In order to deal with the possibility that the general constraints are inconsistent or not of full rank, LA04 introduces additional “artifical” variables v and replaces the constraints of (4) by (5)  A x + v = b and gradually encourages v to zero as a first solution phase.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Once a selection of m independent non-basic variables is made, the constraints (5) determine the remaining m dependent basic variables. The simplex method is a scheme for systematically adjusting the choice of basic and non-basic variables until a set which defines an optimal solution of (4) is obtained. Each iteration of the simplex method requires the solution of a number of sets of linear equations whose coefficient matrix is the basis matrix B, made up of the columns of AI corresponding to the basic variables, or its transpose B^T. As the basis matrices for consecutive iterations are closely related, it is normally advantageous to update (rather than recompute) their factorizations as the computation proceeds.If an initial basis is not provided by the user, a set of basic variables which provide a (permuted) triangular basis matrix is found by the simple crash algorithm of Gould and Reid (1989), and initial steepest-edge weights are calculated.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Phases one (finding a feasible solution) and two (solving (4) of the simplex method are applied, as appropriate, with the choice of entering variable as described by Goldfarb and Reid (1977) and the choice of leaving variable as proposed by Harris (1973). Refactorizations of the basis matrix are performed whenever doing so will reduce the average iteration time or there is insufficient memory for its factors.The reduced cost for the entering variable is computed afresh. If it is found to be of a different sign from the recurred value or more than 10\\% different in magnitude, a fresh computation of all the reduced costs is performed.Details of the factorization and updating procedures are given by Reid (1982). Iterative refinement is encouraged for the basic solution and for the reduced costs after each factorization of the basis matrix and when they are recomputed at the end of phase 1.","category":"page"},{"location":"lpa/#References","page":"lpa","title":"References","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"D. Goldfarb and J. K. Reid (1977). A practicable steepest-edge simplex algorithm. Mathematical Programming 12 361-371.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"N. I. M. Gould and J. K. Reid (1989) New crash procedures for large systems of linear constraints. Mathematical Programming 45 475-501.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"P. M. J. Harris (1973). Pivot selection methods of the Devex LP code. Mathematical Programming 5 1-28.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"J. K. Reid (1982) A sparsity-exploiting variant of the Bartels-Golub decomposition for linear-programming bases. Mathematical Programming 24 55-69.","category":"page"},{"location":"lpa/#Call-order","page":"lpa","title":"Call order","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"To solve a given problem, functions from the lpa package must be called in the following order:","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_initialize - provide default control parameters and","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"set up initial data structures","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_read_specfile (optional) - override control values","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"by reading replacement values from a file","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_import - set up problem data structures and fixed","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"values","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_reset_control (optional) - possibly change control","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_solve_lp - solve the linear program\nlpa_information (optional) - recover information about","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"the solution and solution process","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"lpa_terminate - deallocate data structures","category":"page"},{"location":"lpa/#Unsymmetric-matrix-storage-formats","page":"lpa","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"lpa/#Dense-storage-format","page":"lpa","title":"Dense storage format","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"lpa/#Sparse-co-ordinate-storage-format","page":"lpa","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"lpa/#Sparse-row-wise-storage-format","page":"lpa","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"lpa/","page":"lpa","title":"lpa","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"lhs/#Introduction","page":"lhs","title":"Introduction","text":"","category":"section"},{"location":"lhs/#Purpose","page":"lhs","title":"Purpose","text":"","category":"section"},{"location":"lhs/","page":"lhs","title":"lhs","text":"This package computes an array of Latin Hypercube samples..","category":"page"},{"location":"lhs/","page":"lhs","title":"lhs","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"lhs/#Authors","page":"lhs","title":"Authors","text":"","category":"section"},{"location":"lhs/","page":"lhs","title":"lhs","text":"J. Burkardt, University of Pittsburgh (LGPL) adapted for GALAHAD by N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lhs/","page":"lhs","title":"lhs","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lhs/","page":"lhs","title":"lhs","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lhs/#Originally-released","page":"lhs","title":"Originally released","text":"","category":"section"},{"location":"lhs/","page":"lhs","title":"lhs","text":"June 2016, C interface March 2022. */","category":"page"},{"location":"ccqp/#Introduction","page":"ccqp","title":"Introduction","text":"","category":"section"},{"location":"ccqp/#Purpose","page":"ccqp","title":"Purpose","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"This package uses a primal-dual interior-point crossover method to solve the convex quadratic programming problem \\mbox{minimize}\\;\\; q(x) = \\frac{1}{2} x^T H x + g^T x + f $ \\n minimize q(x) := 1/2 x^T H x + g^T x + f \\n or the shifted least-distance problem \\mbox{minimize}\\;\\; \\frac{1}{2} \\sum{j=1}^n wj^2 ( xj - xj^0 )^2","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"g^T x + f $","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"\\n  minimize 1/2 \\sum{j=1}^n wj^2 ( xj - xj^0 )^2+ g^T x + f \\n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric, positive-semi-definite matrix H, the vectors g, w, x^0, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H or the matrix A of vectors a_i.","category":"page"},{"location":"ccqp/#Authors","page":"ccqp","title":"Authors","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"N. I. M. Gould and D. P. Robinson, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"ccqp/#Originally-released","page":"ccqp","title":"Originally released","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"November 2010, C interface September 2021.","category":"page"},{"location":"ccqp/#Terminology","page":"ccqp","title":"Terminology","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm H x + g = A^T y + z  (mboxor W^2 (x -x^0) + g = A^T y + z  mboxfor the shifted-least-distance type objective)}$ \\n (2a) H x + g = A^T y + z  (or W^2 (x -x^0) + g = A^T y + z for the shifted-least-distance type objective) \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"ccqp/#Method","page":"ccqp","title":"Method","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The method aims at each stage to reduce the overall violation of (1a), (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c y y^l y^u z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c y y^l y^u z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (1a), (2a) and a parameterized “residual trajectory” perturbation of (3); residual trajectories proposed by Zhang (1994) and Zhao and Sun (1999) are possibilities. An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1b) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate. The \"Schur-complement\" approach is usually to be preferred when all the weights are nonzero or when every variable is bounded (at least one side), but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Optionally, the problem may be pre-processed temporarily to eliminate dependent constraints using the GALAHAD package FDC. This may improve the performance of the subsequent iteration.","category":"page"},{"location":"ccqp/#Reference","page":"ccqp","title":"Reference","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"and","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"G. Zhao and J. Sun (1999). On the rate of local convergence of high-order infeasible path-following algorithms for the P_ast linear complementarity problems, Computational Optimization and Applications 14(1) 293-307,","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"with many enhancements described by","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"N. I. M. Gould, D. Orban and D. P. Robinson (2013). Trajectory-following methods for large-scaledegenerate convex quadratic programming, Mathematical Programming Computation 5(2) 113-142.","category":"page"},{"location":"ccqp/#Call-order","page":"ccqp","title":"Call order","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"To solve a given problem, functions from the ccqp package must be called in the following order:","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"ccqp_initialize - provide default control parameters and","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"set up initial data structures","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"ccqp_read_specfile (optional) - override control values","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"by reading replacement values from a file","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"ccqp_import - set up problem data structures and fixed","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"values","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"ccqp_reset_control (optional) - possibly change control","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"solve the problem by calling one of\nccqp_solve_qp - solve the quadratic program\nccqp_solve_sldqp - solve the shifted least-distance problem\nccqp_information (optional) - recover information about","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"the solution and solution process","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"ccqp_terminate - deallocate data structures","category":"page"},{"location":"ccqp/#Unsymmetric-matrix-storage-formats","page":"ccqp","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"ccqp/#Dense-storage-format","page":"ccqp","title":"Dense storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"ccqp/#Sparse-co-ordinate-storage-format","page":"ccqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"ccqp/#Sparse-row-wise-storage-format","page":"ccqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"ccqp/#Symmetric-matrix-storage-formats","page":"ccqp","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"ccqp/#Dense-storage-format-2","page":"ccqp","title":"Dense storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"ccqp/#Sparse-co-ordinate-storage-format-2","page":"ccqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"ccqp/#Sparse-row-wise-storage-format-2","page":"ccqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"ccqp/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"ccqp","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"ccqp/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"ccqp","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"ccqp/#symmetric_matrix_identity-The-identity-matrix-format","page":"ccqp","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"ccqp/#symmetric_matrix_zero-The-zero-matrix-format","page":"ccqp","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"ccqp/","page":"ccqp","title":"ccqp","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"cro/#Introduction","page":"cro","title":"Introduction","text":"","category":"section"},{"location":"cro/#Purpose","page":"cro","title":"Purpose","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"Provides a crossover from a solution to the convex quadratic programming problem mboxminimize q(x) = frac12 x^T H x + g^T x + f  n minimize q(x) = 12 x^T H x + g^T x + f n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n found by an interior-point method to one in which the matrix of defining active constraints/variables is of full rank. Here, the n by n symmetric, positive-semi-definite matrix H, the vectors g, ai c^l, c^u, x^l, x^u, the scalar f are given. In addition a solution x along with optimal Lagrange multipliers y for the general constraints and dual variables z for the simple bounds must be provided (see Section~\\ref{galmethod}). These will be adjusted as necessary. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H or the matrix A of vectors a_i.","category":"page"},{"location":"cro/#Authors","page":"cro","title":"Authors","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"cro/#Originally-released","page":"cro","title":"Originally released","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"August 2010, C interface January 2022.","category":"page"},{"location":"cro/#Terminology","page":"cro","title":"Terminology","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"Any required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace58mm H x + g = A^T y + zhspace58mm}$ \\n (2a) H x + g = A^T y + z \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"cro/#Method","page":"cro","title":"Method","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"Denote the active constraints by A_A x = c_A and the active bounds by I_A x = x_A. Then any optimal solution satisfies the linear system left(beginarraycccH  - A_A^T  - I^T_A  A_A  0  0  I_A  0  0 endarrayright) left(beginarraycx  y_A  z_Aendarrayright) = left(beginarrayc- g  c_A  x_Aendarrayright) \\n  ( H - AA^T - IA^T ) (x) ( - g )  ( AA 0 0 ) ( yA ) = ( cA ),  ( IA 0 0 ) ( zA ) ( xA ) \\n where y_A and z_A are the corresponding active Lagrange multipliers and dual variables respectively. Consequently the difference between any two solutions (Delta x Delta y Delta z) must satisfy mbox(4) left(beginarraycccH  - A_A^T  - I^T_A  A_A  0  0  I_A  0  0 endarrayright) left(beginarraycDelta x  Delta y_A  Delta z_Aendarrayright) = 0 \\n ( H - AA^T - IA^T ) (Delta x) (4) ( AA 0 0 ) ( Delta yA ) = 0, ( IA 0 0 ) ( Delta zA ) \\n Thus there can only be multiple solution if the coefficient matrix K of (4) is singular. The algorithm used in CRO exploits this. The matrix K is checked for singularity using the GALAHAD package ULS. If K is non singular, the solution is unique and the solution input by the user provides a linearly independent active set. Otherwise K is singular, and partitions A_A^T = ( A_B^T  A_N^T) and I_A^T = ( I_B^T  I_N^T) are found so that left(beginarraycccH  - A_B^T  - I_B^T  A_B  0  0  I_B  0  0 endarrayright) \\n  ( H - AB^T - IB^T )  ( AB 0 0 )  ( IB 0 0 ) \\n is non-singular and the non-basic constraints A_N^T and I_N^T are linearly dependent on the basic ones ( A_B^T  I_B^T). In this case (4) is equivalent to mbox(5) left(beginarraycccH  - A_B^T  - I_B^T  A_B  0  0  I_B  0  0 endarrayright) = left(beginarraycA_N^T  0  0endarrayright) Delta y_N + left(beginarraycI_N^T  0  0endarrayright) Delta z_N \\n ( H - AB^T - IB^T ) (Delta x) (5) ( AB 0 0 ) ( Delta yA ) = ( IB 0 0 ) ( Delta zA )","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"( AN^T ) ( IN^T ) ( 0 ) Delta yN + ( 0 ) Delta zN. ( 0 ) ( 0 ) \\n Thus, starting from the user's (x y z) and with a factorization of the coefficient matrix of (5) found by the GALAHAD package SLS, the alternative solution (x + alpha x y + alpha y z + alpha z), featuring (Delta x Delta y_B Delta z_B) from (5)in which successively one of the components of Delta y_N and Delta z_N in turn is non zero, is taken. The scalar alpha at each stage is chosen to be the largest possible that guarantees (2.b); this may happen when a non-basic multiplier/dual variable reaches zero, in which case the corresponding constraint is disregarded, or when this happens for a basic multiplier/dual variable, in which case this constraint is exchanged with the non-basic one under consideration and disregarded. The latter corresponds to changing the basic-non-basic partition in (5), and subsequent solutions may be found by updating the factorization of the coefficient matrix in (5) following the basic-non-basic swap using the GALAHAD package SCU.","category":"page"},{"location":"cro/#Reference","page":"cro","title":"Reference","text":"","category":"section"},{"location":"cro/#Call-order","page":"cro","title":"Call order","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"To solve a given problem, functions from the cro package must be called in the following order:","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"cro_initialize - provide default control parameters and","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"set up initial data structures","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"cro_read_specfile (optional) - override control values","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"by reading replacement values from a file","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"crocrossoversolution - move from a primal-dual soution","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"to a full rank one","category":"page"},{"location":"cro/","page":"cro","title":"cro","text":"cro_terminate - deallocate data structures","category":"page"},{"location":"cro/#fdc*array*indexing-Array-indexing","page":"cro","title":"fdcarrayindexing Array indexing","text":"","category":"section"},{"location":"cro/","page":"cro","title":"cro","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; add 1 to input integer arrays if fortran-style indexing is used, and beware that return integer arrays will adhere to this.","category":"page"},{"location":"sbls/#Introduction","page":"sbls","title":"Introduction","text":"","category":"section"},{"location":"sbls/#Purpose","page":"sbls","title":"Purpose","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Given a block, symmetric matrix K_H = matcc H  A^T  A - C  \\n KH = ( HA^T ) ( A- C ) \\n this package constructs a variety of preconditioners of the form K{G} = \\mat{cc}{ G & A^T \\ A& - C }.$ \\n KG = ( GA^T ). ( A- C ) \\n Here, the leading-block matrix G is a suitably-chosen approximation to H; it may either be prescribed explicitly, in which case a symmetric indefinite factorization of KG$ will be formed using the GALAHAD symmetric matrix factorization package SLS, or implicitly, by requiring certain sub-blocks of G be zero. In the latter case, a factorization of K_G will be obtained implicitly (and more efficiently) without recourse to SLS. In particular, for implicit preconditioners, a reordering K_G = P matccc G_11^  G_21^T  A_1^T G_21^  G_22^  A_2^T \nA_1^  A_2^  - C P^T  n ( G_11G_21^TA_1^T ) K_G = P ( G_21 G_22 A_2^T ) P^T (A_1 A_2 - C) n involving a suitable permutation P will be found, for some invertible sub-block (“basis”) A_1 of the columns of A; the selection and factorization of A_1 uses the GALAHAD unsymmetric matrix factorization package ULS. Once the preconditioner has been constructed, solutions to the preconditioning system matcc G  A^T  A - C  vect x  y   = vecta  b  n ( GA^T ) ( x ) = ( a ) ( A- C ) ( y ) ( b ) n may be obtained by the package Full advantage is taken of any zero coefficients in the matrices H, A and C.","category":"page"},{"location":"sbls/#Authors","page":"sbls","title":"Authors","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"H. S. Dollar and N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"sbls/#Originally-released","page":"sbls","title":"Originally released","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"April 2006, C interface November 2021.","category":"page"},{"location":"sbls/#Method","page":"sbls","title":"Method","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The method used depends on whether an explicit or implicit factorization is required. In the explicit case, the package is really little more than a wrapper for the GALAHAD symmetric, indefinite linear solver SLS in which the system matrix K_G is assembled from its constituents A, C and whichever G is requested by the user. Implicit-factorization preconditioners are more involved, and there is a large variety of different possibilities. The essential ideas are described in detail in","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"H. S. Dollar, N. I. M. Gould and A. J. Wathen. “On implicit-factorization constraint preconditioners”. InLarge Scale Nonlinear Optimization (G. Di Pillo and M. Roma, eds.) Springer Series on Nonconvex Optimization and Its Applications, Vol. 83, Springer Verlag (2006) 61–82","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"and","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"H. S. Dollar, N. I. M. Gould, W. H. A. Schilders and A. J. Wathen “On iterative methods and implicit-factorization preconditioners for regularized saddle-point systems”. SIAM Journal on Matrix Analysis and Applications, 28(1) (2006) 170–189.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The range-space factorization is based upon the decomposition K_G = matcc G  0  A  I matcc G^-1  0  0  - Smatcc G  A^T  0  I  n K_G = ( G0 ) ( G^-1 0 ) ( G A^T ) ( AI ) ( 0 -S ) ( 0I) n where the Schur complement S = C + A G^-1 A^T. Such a method requires that S is easily invertible. This is often the case when G is a diagonal matrix, in which case S is frequently sparse, or when m ll n in which case S is small and a dense Cholesky factorization may be used.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"When C = 0, the null-space factorization is based upon the decomposition K_{G} = P\\mat{ccc}{G{11}^{} & 0 & I \\\nG{21}^{} & I & A{2}^{T} A{1}^{-T} \\A{1}^{} & 0 & 0 } \\mat{ccc}{0 & 0 & I \\ \\;\\;\\; 0 \\;\\; & \\;\\; R \\;\\; & 0 \\ I & 0 & - G{11}^{}} \\mat{ccc}{G{11}^{} & G{21}^T & A{1}^T \\0 & I & 0 \\\nI & A{1}^{-1} A{2}^{} & 0} P^T, $ \\n ( G110I) ( 00 I ) KG = P ( G21IA2^T A1^{-T} ) ( 0R 0 ) ( A1 00) ( I0 -G11 )","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"( G11 G21^T A1^T ) . (0I0) P^T, (IA1^{-1} A20 ) \\n where the “reduced Hessian” R = ( - A{2}^{T} A1^{-T} \\;\\; I ) \\mat{cc}{G{11}^{} & G{21}^{T} \\ G{21}^{} & G{22}^{}} \\vect{ - A1^{-1} A2^{} \\ I} $ \\n  R = ( -A2^T A1^{-T}I )( G11G21^T ) ( -A1^{-1} A2 )  ( G21 G22) ( I ) \\n and P is a suitably-chosen permutation for which A1$ is invertible. The method is most useful when m approx n as then the dimension of R is small and a dense Cholesky factorization may be used.","category":"page"},{"location":"sbls/#Call-order","page":"sbls","title":"Call order","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"To solve a given problem, functions from the sbls package must be called in the following order:","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_initialize - provide default control parameters and","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"set up initial data structures","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_read_specfile (optional) - override control values","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"by reading replacement values from a file","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_import - set up matrix data structures\nsbls_reset_control (optional) - possibly change control","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sblsfactorize\\matrix - form and factorize the block","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"matrix from its components","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_solve_system - solve the block linear system of","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"equations","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_information (optional) - recover information about","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"the solution and solution process","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"sbls_terminate - deallocate data structures","category":"page"},{"location":"sbls/#Unsymmetric-matrix-storage-formats","page":"sbls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"sbls/#Dense-storage-format","page":"sbls","title":"Dense storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"sbls/#Sparse-co-ordinate-storage-format","page":"sbls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"sbls/#Sparse-row-wise-storage-format","page":"sbls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"sbls/#Symmetric-matrix-storage-formats","page":"sbls","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Likewise, the symmetric n by n matrix H, as well as the m by m matrix C,may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal). We focus on H, but everything we say applies equally to C.","category":"page"},{"location":"sbls/#Dense-storage-format-2","page":"sbls","title":"Dense storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"sbls/#Sparse-co-ordinate-storage-format-2","page":"sbls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"sbls/#Sparse-row-wise-storage-format-2","page":"sbls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"sbls/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"sbls","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"sbls/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"sbls","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"sbls/#symmetric_matrix_identity-The-identity-matrix-format","page":"sbls","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"sbls/#symmetric_matrix_zero-The-zero-matrix-format","page":"sbls","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"sbls/","page":"sbls","title":"sbls","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"blls/#Introduction","page":"blls","title":"Introduction","text":"","category":"section"},{"location":"blls/#Purpose","page":"blls","title":"Purpose","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"This package uses a preconditioned, projected-gradient method to solve the  bound-constrained regularized linear least-squares problem mboxminimize q(x) = q(x) = frac12  A x - b_2^2 + frac12 sigma x^2 \\n minimize q(x) := 1/2 || A x - b ||^2 + sigma ||x||^2 \\n subject to the simple bound constraints x_j^lleqx_j leq x_j^u  j = 1 ldots  n \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the m by n real matrix A, the vectors b, x^l, x^u and the non-negative weight sigma are given. Any of the constraint bounds xj^l$ and x_j^u may be infinite.Full advantage is taken of any zero coefficients of the Jacobian matrix A of the residuals c(x) = A x - b;the matrix need not be provided as there are options to obtain matrix-vector products involving A and its transpose either by reverse communication or from a user-provided subroutine.","category":"page"},{"location":"blls/#Authors","page":"blls","title":"Authors","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"blls/#Originally-released","page":"blls","title":"Originally released","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"October 2019, C interface March 2022.","category":"page"},{"location":"blls/#Terminology","page":"blls","title":"Terminology","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"The required solution x necessarily satisfies the primal optimality conditions x^l leq x leq x^u \\n  x^l [<=] x [<=] x^u, \\n the dual optimality conditions (A^T A + sigma I ) x = A^T b + z \\n  ( A^T A + sigma I ) x = A^T b + z \\n where $ z = z^l + z^u, \\,\\,  z^l \\geq 0 \\;\\; \\mbox{and} \\;\\; z^u \\leq 0,$ \\n  z = z^l + z^u, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  n (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0 n where the vector z is known asthe dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"blls/#Method","page":"blls","title":"Method","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"The method is iterative. Each iteration proceeds in two stages. Firstly, a search direction s from the current estimate of the solution x is computed. This may be in a scaled steepest-descent direction, or, if the working set of variables on bounds has not changed dramatically, in a direction that provides an approximate minimizer of the objective over a subspace comprising the currently free-variables. The latter is computed either using an appropriate sparse factorization by the GALAHAD package SBLS, or by theconjugate-gradient least-squares (CGLS) method; tt may be necessary to regularize the subproblem very slightly to avoid a ill-posedness. Thereafter, a piecewise linesearch (arc search) is carried out along the arc x(alpha) = P( x + alpha s) for alpha  0, where the projection operator is defined component-wise at any feasible point v to be P_j(v) = min( max( x_j x_j^l) x_j^u) thus this arc bends the search direction into the feasible region. The arc search is performed either exactly, by passing through a set of increasing breakpoints at which it changes direction, or inexactly, by evaluating a sequence of different alphaon the arc. All computation is designed to exploit sparsity in A.","category":"page"},{"location":"blls/#Reference","page":"blls","title":"Reference","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"Full details are provided in","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"N. I. M. Gould (2022). Numerical methods for solving bound-constrained linear least squares problems. In preparation.","category":"page"},{"location":"blls/#Call-order","page":"blls","title":"Call order","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"To solve a given problem, functions from the blls package must be called in the following order:","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_initialize - provide default control parameters and","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"set up initial data structures","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_read_specfile (optional) - override control values","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"by reading replacement values from a file","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"set up problem data structures and fixed values by caling one of\nblls_import - in the case that A is explicitly","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"available","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_import_without_a - in the case that only the","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"effect of applying A and its transpose to a vector is possible","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_reset_control (optional) - possibly change control","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"solve the problem by calling one of\nblls_solvegivena - solve the problem using values","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"of A","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_solve_reverseaprod - solve the problem by returning","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"to the caller for products of A and its transpose with specified vectors","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_information (optional) - recover information about","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"the solution and solution process","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"blls_terminate - deallocate data structures","category":"page"},{"location":"blls/#Unsymmetric-matrix-storage-formats","page":"blls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"The unsymmetric m by n matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"blls/","page":"blls","title":"blls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"blls/#unsymmetric_matrix*dense*row-Dense-row-storage-format","page":"blls","title":"unsymmetric_matrixdenserow Dense row storage format","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"blls/#unsymmetric_matrix*dense*column-Dense-column-storage-format","page":"blls","title":"unsymmetric_matrixdensecolumn Dense column storage format","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"The matrix A is stored as a compactdense matrix by columns, that is, the values of the entries of each column in turn are stored in order within an appropriate real one-dimensional array. In this case, component m ast j + iof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"blls/#Sparse-co-ordinate-storage-format","page":"blls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"blls/#Sparse-row-wise-storage-format","page":"blls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessors.","category":"page"},{"location":"blls/#unsymmetric_matrix*column*wise-Sparse-column-wise-storage-format","page":"blls","title":"unsymmetric_matrixcolumnwise Sparse column-wise storage format","text":"","category":"section"},{"location":"blls/","page":"blls","title":"blls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in column j appear directly before those in column j+1. For the j-th column of A the j-th component of the integer array Aptr holds the position of the first entry in this column, while Aptr(n) holds the total number of entries plus one. The row indices i, 0 leq i leq m-1, and values A_ij of thenonzero entries in the j-th column are stored in components l = Aptr(j), ldots, Aptr(j+1)-1,0 leq j leq n-1, of the integer array Arow, and real array Aval, respectively. Once again, for sparse matrices, this scheme almost always requires less storage than the dense of coordinate formats.","category":"page"},{"location":"bsc/#Introduction","page":"bsc","title":"Introduction","text":"","category":"section"},{"location":"bsc/#Purpose","page":"bsc","title":"Purpose","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Given matrices A and (diagonal) D, build the \"Schur complement\" S=A D A^T in sparse co-ordinate (and optionally sparse column) format(s). Full advantage is taken of any zero coefficients in the matrix A.","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"bsc/#Authors","page":"bsc","title":"Authors","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"bsc/#Originally-released","page":"bsc","title":"Originally released","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"October 2013, C interface January 2022.","category":"page"},{"location":"bsc/#Call-order","page":"bsc","title":"Call order","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"To solve a given problem, functions from the bsc package must be called in the following order:","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"bsc_initialize - provide default control parameters and","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"set up initial data structures","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"bsc_read_specfile (optional) - override control values","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"by reading replacement values from a file","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"bsc_import - set up matrix data structures for A.\nbsc_reset_control (optional) - possibly change control","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"bsc_form - form the Schur complement S\nbsc_information (optional) - recover information about","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"the process","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"bsc_terminate - deallocate data structures","category":"page"},{"location":"bsc/#main_topics-Further-topics","page":"bsc","title":"main_topics Further topics","text":"","category":"section"},{"location":"bsc/#Unsymmetric-matrix-storage-formats","page":"bsc","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"An unsymmetric m by n matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"bsc/#Dense-storage-format","page":"bsc","title":"Dense storage format","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"bsc/#Dense-by-columns-storage-format","page":"bsc","title":"Dense by columns storage format","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"The matrix A is stored as a compactdense matrix by columns, that is, the values of the entries of each column in turn are stored in order within an appropriate real one-dimensional array. In this case, component m ast j + iof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"bsc/#Sparse-co-ordinate-storage-format","page":"bsc","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"bsc/#Sparse-row-wise-storage-format","page":"bsc","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"bsc/#unsymmetric_matrix*column*wise-Sparse-column-wise-storage-format","page":"bsc","title":"unsymmetric_matrixcolumnwise Sparse column-wise storage format","text":"","category":"section"},{"location":"bsc/","page":"bsc","title":"bsc","text":"Once again only the nonzero entries are stored, but this time they are ordered so that those in column j appear directly before those in column j+1. For the j-th column of A the j-th component of the integer array Aptr holds the position of the first entry in this column, while Aptr(n) holds the total number of entries plus one. The row indices i, 0 leq i leq m-1, and values A_ij of thenonzero entries in the j-th columnsare stored in components l = Aptr(j), ldots, Aptr(j+1)-1, 0 leq j leq n-1, of the integer array Arow, and real array Aval, respectively. As before, for sparse matrices, this scheme almost always requires less storage than the co-ordinate format.","category":"page"},{"location":"cqp/#Introduction","page":"cqp","title":"Introduction","text":"","category":"section"},{"location":"cqp/#Purpose","page":"cqp","title":"Purpose","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"This package uses a primal-dual interior-point method to solve the convex quadratic programming problem \\mbox{minimize}\\;\\; q(x) = \\frac{1}{2} x^T H x + g^T x + f $ \\n minimize q(x) := 1/2 x^T H x + g^T x + f \\n or the shifted least-distance problem \\mbox{minimize}\\;\\; \\frac{1}{2} \\sum{j=1}^n wj^2 ( xj - xj^0 )^2","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"g^T x + f $","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"\\n  minimize 1/2 \\sum{j=1}^n wj^2 ( xj - xj^0 )^2+ g^T x + f \\n subject to the general linear constraints c_i^lleqa_i^Txleq c_i^u  i = 1 ldots  m \\n  ci^l [<=] ai^Tx [<=] ci^u, i = 1, ... , m, \\n and the simple bound constraints xj^l\\leqxj \\leq xj^u, \\;\\;\\; j = 1, \\ldots , n,$ \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric, positive-semi-definite matrix H, the vectors g, w, x^0, ai c^l, c^u, x^l, x^u and the scalar f are given. Any of the constraint bounds c_i^l, c_i^u, x_j^l and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H or the matrix A of vectors a_i.","category":"page"},{"location":"cqp/#Authors","page":"cqp","title":"Authors","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"N. I. M. Gould and D. P. Robinson, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"cqp/#Originally-released","page":"cqp","title":"Originally released","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"November 2010, C interface September 2021.","category":"page"},{"location":"cqp/#Terminology","page":"cqp","title":"Terminology","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1a) hspace66mm A x = chspace66mm}$ \\n (1a) A x = c \\n and mbox(1b) hspace52mm c^l leq c leq c^u  x^l leq x leq x^uhspace52mm} $ \\n (1b) c^l [<=] c [<=] c^u, x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm H x + g = A^T y + z  (mboxor W^2 (x -x^0) + g = A^T y + z  mboxfor the shifted-least-distance type objective)}$ \\n (2a) H x + g = A^T y + z  (or W^2 (x -x^0) + g = A^T y + z for the shifted-least-distance type objective) \\n where mbox(2b) hspace24mm y = y^l + y^u  z = z^l + z^u   y^l geq 0  y^u leq 0    z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) y = y^l + y^u, z = z^l + z^u, y^l [>=] 0, y^u [<=] 0, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm ( A x - c^l )^T y^l = 0( A x - c^u )^T y^u = 0 (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (A x - c^l)^T y^l = 0, (A x - c^u)^T y^u = 0, (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, where the vectors y and z are known as the Lagrange multipliers for the general linear constraints, and the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"cqp/#Method","page":"cqp","title":"Method","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (1a), (2a) and (3), while ensuring that (1b) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (1a), (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1b) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The method aims at each stage to reduce the overall violation of (1a), (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c y y^l y^u z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c y y^l y^u z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (1a), (2a) and a parameterized “residual trajectory” perturbation of (3); residual trajectories proposed by Zhang (1994) and Zhao and Sun (1999) are possibilities. An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1b) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate. The \"Schur-complement\" approach is usually to be preferred when all the weights are nonzero or when every variable is bounded (at least one side), but may be inefficient if any of the columns of A is too dense.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Optionally, the problem may be pre-processed temporarily to eliminate dependent constraints using the GALAHAD package FDC. This may improve the performance of the subsequent iteration.","category":"page"},{"location":"cqp/#Reference","page":"cqp","title":"Reference","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"and","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"G. Zhao and J. Sun (1999). On the rate of local convergence of high-order infeasible path-following algorithms for the P_ast linear complementarity problems, Computational Optimization and Applications 14(1) 293-307,","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"with many enhancements described by","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"N. I. M. Gould, D. Orban and D. P. Robinson (2013). Trajectory-following methods for large-scaledegenerate convex quadratic programming, Mathematical Programming Computation 5(2) 113-142.","category":"page"},{"location":"cqp/#Call-order","page":"cqp","title":"Call order","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"To solve a given problem, functions from the cqp package must be called in the following order:","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"cqp_initialize - provide default control parameters and","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"set up initial data structures","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"cqp_read_specfile (optional) - override control values","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"by reading replacement values from a file","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"cqp_import - set up problem data structures and fixed","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"values","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"cqp_reset_control (optional) - possibly change control","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"solve the problem by calling one of\ncqp_solve_qp - solve the quadratic program\ncqp_solve_sldqp - solve the shifted least-distance problem\ncqp_information (optional) - recover information about","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"the solution and solution process","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"cqp_terminate - deallocate data structures","category":"page"},{"location":"cqp/#Unsymmetric-matrix-storage-formats","page":"cqp","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The unsymmetric m by n constraint matrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"cqp/#Dense-storage-format","page":"cqp","title":"Dense storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"cqp/#Sparse-co-ordinate-storage-format","page":"cqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"cqp/#Sparse-row-wise-storage-format","page":"cqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"cqp/#Symmetric-matrix-storage-formats","page":"cqp","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Likewise, the symmetric n by n objective Hessian matrix H may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"cqp/#Dense-storage-format-2","page":"cqp","title":"Dense storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"cqp/#Sparse-co-ordinate-storage-format-2","page":"cqp","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"cqp/#Sparse-row-wise-storage-format-2","page":"cqp","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"cqp/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"cqp","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"cqp/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"cqp","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"cqp/#symmetric_matrix_identity-The-identity-matrix-format","page":"cqp","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"cqp/#symmetric_matrix_zero-The-zero-matrix-format","page":"cqp","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"cqp/","page":"cqp","title":"cqp","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"hash/#Introduction","page":"hash","title":"Introduction","text":"","category":"section"},{"location":"hash/#Purpose","page":"hash","title":"Purpose","text":"","category":"section"},{"location":"hash/","page":"hash","title":"hash","text":"Set up, insert into, remove from and search a chained scatter table (Williams, CACM 2, 21-24, 1959).","category":"page"},{"location":"hash/","page":"hash","title":"hash","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"hash/#Authors","page":"hash","title":"Authors","text":"","category":"section"},{"location":"hash/","page":"hash","title":"hash","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"hash/","page":"hash","title":"hash","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"hash/","page":"hash","title":"hash","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"hash/#Originally-released","page":"hash","title":"Originally released","text":"","category":"section"},{"location":"hash/","page":"hash","title":"hash","text":"December 1990, C interface January 2022.","category":"page"},{"location":"gls/#Introduction","page":"gls","title":"Introduction","text":"","category":"section"},{"location":"gls/#Purpose","page":"gls","title":"Purpose","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"This package solves sparse unsymmetric system of linear equations.. Given an m by n sparse matrix A = a_ij, the package solves the system A x = b (or optionally A^T x = b). The matrix A can be rectangular.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"N.B. The package is simply a sophisticated interface to the HSL package MA33, and requires that a user has obtained the latter. ** MA33 is not included in GALAHAD** but is available without charge to recognised academics, see https://www.hsl.rl.ac.uk/archive/specs/ma33.pdf . The package offers additional features to MA33. The storage required for the factorization is chosen automatically and, if there is insufficient space for the factorization, more space is allocated and the factorization is repeated.The package also returns the number of entries in the factors and has facilities for identifying the rows and columns that are treated specially when the matrix is singular or rectangular.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces. Extended functionality is available using the GALAHAD package uls.","category":"page"},{"location":"gls/#Authors","page":"gls","title":"Authors","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"gls/#Originally-released","page":"gls","title":"Originally released","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"March 2006, C interface December 2021.","category":"page"},{"location":"gls/#Unsymmetric-matrix-storage-formats","page":"gls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"The unsymmetric m by nmatrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"gls/","page":"gls","title":"gls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"gls/#Dense-storage-format","page":"gls","title":"Dense storage format","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"gls/#Sparse-co-ordinate-storage-format","page":"gls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"gls/#Sparse-row-wise-storage-format","page":"gls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"gls/","page":"gls","title":"gls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"sha/#Introduction","page":"sha","title":"Introduction","text":"","category":"section"},{"location":"sha/#Purpose","page":"sha","title":"Purpose","text":"","category":"section"},{"location":"sha/","page":"sha","title":"sha","text":"Find an approximation to a sparse Hessian using componentwise secant approximation.","category":"page"},{"location":"sha/","page":"sha","title":"sha","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"sha/#Authors","page":"sha","title":"Authors","text":"","category":"section"},{"location":"sha/","page":"sha","title":"sha","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"sha/","page":"sha","title":"sha","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"sha/","page":"sha","title":"sha","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"sha/#Originally-released","page":"sha","title":"Originally released","text":"","category":"section"},{"location":"sha/","page":"sha","title":"sha","text":"April 2013, C interface January 2022.","category":"page"},{"location":"sls/#Introduction","page":"sls","title":"Introduction","text":"","category":"section"},{"location":"sls/#Purpose","page":"sls","title":"Purpose","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"This package ** solves dense or sparse symmetric systems of linear equations** using variants of Gaussian elimination.Given a sparse symmetric n times n matrix A, and an n-vector b, this subroutine solves the system A x = b.The matrix A need not be definite.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The package provides a common interface to a variety of well-known solvers from HSL and elsewhere. Currently supported solvers include MA27/SILS, HSL_MA57, HSL_MA77, HSL_MA86, HSL_MA87 and HSL_MA97 from HSL, SSIDS from SPRAL, PARDISO both from the Pardiso Project and Intel's MKL and WSMP from the IBM alpha Works, as well as POTR, SYTR and SBTR from LAPACK. Note that ** the solvers themselves do not form part of this package and must be obtained separately.** Dummy instances are provided for solvers that are unavailable. Also note that additional flexibility may be obtained by calling the solvers directly rather that via this package.","category":"page"},{"location":"sls/#Authors","page":"sls","title":"Authors","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"sls/#Originally-released","page":"sls","title":"Originally released","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"August 2009, C interface December 2021.","category":"page"},{"location":"sls/#Terminology","page":"sls","title":"Terminology","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"The solvers used each produce an L D L^T factorization of A or a perturbation thereof, where L is a permuted lower triangular matrix and D is a block diagonal matrix with blocks of order 1 and 2. It is convenient to write this factorization in the form A + E = P L D L^T P^T where P is a permutation matrix and E is any diagonal perturbation introduced.","category":"page"},{"location":"sls/#sls_solvers-Supported-external-solvers","page":"sls","title":"sls_solvers Supported external solvers","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"The key features of the external solvers supported by sls are given in the following table.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"(ignore next paragraph - doxygen bug!)","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"<table> <caption>External solver characteristics</caption> <tr><th> solver <th> factorization <th> indefinite A <th> out-of-core <th> parallelised <tr><td> SILS/MA27 <td> multifrontal <td> yes <td> no <td> no <tr><td> HSLMA57 <td> multifrontal <td> yes <td> no <td> no <tr><td> HSLMA77 <td> multifrontal <td> yes <td> yes <td> OpenMP core <tr><td> HSLMA86 <td> left-looking <td> yes <td> no <td> OpenMP fully <tr><td> HSLMA87 <td> left-looking <td> no <td> no <td> OpenMP fully <tr><td> HSLMA97 <td> multifrontal <td> yes <td> no <td> OpenMP core <tr><td> SSIDS <td> multifrontal <td> yes <td> no <td> CUDA core <tr><td> PARDISO <td> left-right-looking <td> yes <td> no <td> OpenMP fully <tr><td> MKLPARDISO <td> left-right-looking <td> yes <td> optionally  <td> OpenMP fully <tr><td> WSMP <td> left-right-looking <td> yes <td> no <td> OpenMP fully <tr><td> POTR <td> dense <td> no <td> no <td> with parallel LAPACK <tr><td> SYTR <td> dense <td> yes <td> no <td> with parallel LAPACK <tr><td> PBTR <td> dense band <td> no <td> no <td> with parallel LAPACK </table>","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"External solver characteristics (ooc = out-of-core factorization)","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"solver factorization indefinite Aoocparallelised  SILS/MA27 multifrontalyes nono  HSLMA57multifrontalyes nono  HSLMA77multifrontalyesyesOpenMP core  HSLMA86left-lookingyes noOpenMP fully  HSLMA87left-looking no noOpenMP fully  HSLMA97multifrontalyes noOpenMP core  SSIDS multifrontalyes noCUDA core  PARDISO left-right-lookingyes noOpenMP fully  MKLPARDISO left-right-lookingyesoptionallyOpenMP fully  WSMPleft-right-lookingyes noOpenMP fully  POTRdenseno nowith parallel LAPACK  SYTRdense yes nowith parallel LAPACK  PBTRdense band no nowith parallel LAPACK","category":"page"},{"location":"sls/#Method","page":"sls","title":"Method","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"Variants of sparse Gaussian elimination are used.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solver SILS is available as part of GALAHAD and relies on the HSL Archive package MA27. To obtain HSL Archive packages, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"http://hsl.rl.ac.uk/archive/ .","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solvers HSL_MA57, HSL_MA77, HSL_MA86, HSL_MA87 and HSL_MA97, the ordering packages MC61 and HSL_MC68, and the scaling packages HSL_MC64 and MC77 are all part of HSL 2011. To obtain HSL 2011 packages, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"http://hsl.rl.ac.uk","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solver SSIDS is from the SPRAL sparse-matrix collection, and is available as part of GALAHAD.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solver PARDISO is available from the Pardiso Project; version 4.0.0 or above is required. To obtain PARDISO, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"http://www.pardiso-project.org/ .","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solver MKL PARDISO is available as part of Intel's oneAPI Math Kernel Library (oneMKL). To obtain this version of PARDISO, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"https://software.intel.com/content/www/us/en/develop/tools/oneapi.html .","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solver WSMP is available from the IBM alpha Works; version 10.9 or above is required. To obtain WSMP, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"http://www.alphaworks.ibm.com/tech/wsmp .","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"The solvers POTR, SYTR and PBTR, are available as S/DPOTRF/S, S/DSYTRF/S and S/DPBTRF/S as part of LAPACK. Reference versions are provided by GALAHAD, but for good performance machined-tuned versions should be used.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Explicit sparsity re-orderings are obtained by calling the HSL package HSL_MC68. Both this, HSL_MA57 and PARDISO rely optionally on the ordering package MeTiS (version 4) from the Karypis Lab. To obtain METIS, see","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"http://glaros.dtc.umn.edu/gkhome/views/metis/ .","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Bandwidth, Profile and wavefront reduction is supported by calling HSL's MC61.","category":"page"},{"location":"sls/#Reference","page":"sls","title":"Reference","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"The methods used are described in the user-documentation for","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"HSL 2011, A collection of Fortran codes for large-scale scientific  computation (2011). http://www.hsl.rl.ac.uk","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"and papers","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"O. Schenk and K. G&auml;rtner, “Solving Unsymmetric Sparse Systems of Linear Equations with PARDISO”. Journal of Future Generation Computer Systems \\b, 20(3) (2004) 475–487,","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"O. Schenk and K. G&auml;rtner, “On fast factorization pivoting methods for symmetric indefinite systems”. Electronic Transactions on Numerical Analysis \\b 23 (2006) 158–179, and","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"A. Gupta, “WSMP: Watson Sparse Matrix Package Part I - direct solution of symmetric sparse systems”. IBM Research Report RC 21886, IBM T. J. Watson Research Center, NY 10598, USA (2010).","category":"page"},{"location":"sls/#Call-order","page":"sls","title":"Call order","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"To solve a given problem, functions from the sls package must be called in the following order:","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"sls_initialize - provide default control parameters and","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"set up initial data structures","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"sls_read_specfile (optional) - override control values","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"by reading replacement values from a file","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"slsanalyse\\matrix - set up matrix data structures","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"and analyse the structure to choose a suitable order for factorization","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"sls_reset_control (optional) - possibly change control","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"slsfactorize\\matrix - form and factorize the","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"matrix A","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"one of\nsls_solve_system - solve the linear system of","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"equations Ax=b","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"slspartial\\solve_system - solve a linear system","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Mx=b","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"involving one of the matrix factors M of A","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"sls_information (optional) - recover information about","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"the solution and solution process","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"sls_terminate - deallocate data structures","category":"page"},{"location":"sls/#Symmetric-matrix-storage-formats","page":"sls","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"The symmetric n by n coefficient matrix A may be presented and stored in a variety of convenient input formats.Crucially symmetry is exploitedby only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"sls/","page":"sls","title":"sls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"sls/#Dense-storage-format","page":"sls","title":"Dense storage format","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since A is symmetric, only the lower triangular part (that is the part A_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array val will hold the value A_ij (and, by symmetry, A_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"sls/#Sparse-co-ordinate-storage-format","page":"sls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays row and col and real array val, respectively, while the number of nonzeros is recorded as ne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"sls/#Sparse-row-wise-storage-format","page":"sls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"sls/","page":"sls","title":"sls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array ptr holds the position of the first entry in this row, while ptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values A_ij of theentries in the i-th row are stored in components l = ptr(i), ldots, ptr(i+1)-1 of the integer array col, and real array val, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"uls/#Introduction","page":"uls","title":"Introduction","text":"","category":"section"},{"location":"uls/#Purpose","page":"uls","title":"Purpose","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"This package ** solves dense or sparse unsymmetric systems of linear equations** using variants of Gaussian elimination. Given a sparse symmetric m times n matrix A = a_ij, and an m-vector b, this subroutine solves the system A x = b. If b is an n-vector, the package may solve instead the system A^T x = b. Both square (m=n) and rectangular (m neq n)matrices are handled; one of an infinite class of solutions for consistent systems will be returned whenever A is not of full rank.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"The method provides a common interface to a variety of well-known solvers from HSL. Currently supported solvers include MA28/GLS and HSL_MA48. Note that ** the solvers themselves do not form part of this package and must be obtained separately.** Dummy instances are provided for solvers that are unavailable. Also note that additional flexibility may be obtained by calling the solvers directly rather that via this package.","category":"page"},{"location":"uls/#Authors","page":"uls","title":"Authors","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"uls/#Originally-released","page":"uls","title":"Originally released","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"August 2009,C interface December 2021.","category":"page"},{"location":"uls/#Terminology","page":"uls","title":"Terminology","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"The solvers used each produce an P_R L U P_C factorization of A, where L and U are lower and upper triangular matrices, and P_R and P_C are row and column permutation matrices respectively.","category":"page"},{"location":"uls/#Method","page":"uls","title":"Method","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"Variants of sparse Gaussian elimination are used.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"The solver GLS is available as part of GALAHAD and relies on the HSL Archive packages MA33. To obtain HSL Archive packages, see","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"http://hsl.rl.ac.uk/archive/ .","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"The solver HSL_MA48 is part of HSL 2007. To obtain HSL 2007 packages, see","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"http://hsl.rl.ac.uk/hsl2007/ .","category":"page"},{"location":"uls/#Reference","page":"uls","title":"Reference","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"The methods used are described in the user-documentation for","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"HSL 2007, A collection of {F}ortran codes for large-scale scientific computation (2007).\\n http://www.cse.clrc.ac.uk/nag/hsl","category":"page"},{"location":"uls/#Call-order","page":"uls","title":"Call order","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"To solve a given problem, functions from the uls package must be called in the following order:","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_initialize - provide default control parameters and","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"set up initial data structures","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_read_specfile (optional) - override control values","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"by reading replacement values from a file","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"ulsfactorize\\matrix - set up matrix data structures,","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"analyse the structure to choose a suitable order for factorization,  and then factorize the matrix A","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_reset_control (optional) - possibly change control","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_solve_system - solve the linear system of","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"equations Ax=b or A^Tx=b","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_information (optional) - recover information about","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"the solution and solution process","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"uls_terminate - deallocate data structures","category":"page"},{"location":"uls/#Unsymmetric-matrix-storage-formats","page":"uls","title":"Unsymmetric matrix storage formats","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"The unsymmetric m by nmatrix A may be presented and stored in a variety of convenient input formats.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"uls/","page":"uls","title":"uls","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"uls/#Dense-storage-format","page":"uls","title":"Dense storage format","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"The matrix A is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. In this case, component n ast i + jof the storage array Aval will hold the value A{ij}$ for 0 leq i leq m-1, 0 leq j leq n-1.","category":"page"},{"location":"uls/#Sparse-co-ordinate-storage-format","page":"uls","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"uls/#Sparse-row-wise-storage-format","page":"uls","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"uls/","page":"uls","title":"uls","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of A the i-th component of the integer array Aptr holds the position of the first entry in this row, while Aptr(m) holds the total number of entries plus one. The column indices j, 0 leq j leq n-1, and values A_ij of thenonzero entries in the i-th row are stored in components l = Aptr(i), ldots, Aptr(i+1)-1,0 leq i leq m-1, of the integer array Acol, and real array Aval, respectively. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"fdc/#Introduction","page":"fdc","title":"Introduction","text":"","category":"section"},{"location":"fdc/#Purpose","page":"fdc","title":"Purpose","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"Given an under-determined set of linear equations/constraints a_i^T x = b_i^, i = 1 ldots m involving n geq m unknowns x, this package determines whether the constraints are consistent, and if so how many of the constraints are dependent; a list of dependent constraints, that is, those which may be removed without changing the solution set, will be found and the remaining a_i will be linearly independent.Full advantage is taken of any zero coefficients in the vectors a_i.","category":"page"},{"location":"fdc/#Authors","page":"fdc","title":"Authors","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"fdc/#Originally-released","page":"fdc","title":"Originally released","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"August 2006, C interface January 2021","category":"page"},{"location":"fdc/#Method","page":"fdc","title":"Method","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"A choice of two methods is available. In the first, the matrix K = matcc alpha I  A^T  A  0  is formed and factorized for some small alpha  0 using the GALAHAD package SLS–-the factors K = P L D L^T P^T are used to determine whether A has dependent rows. In particular, in exact arithmetic dependencies in A will correspond to zero pivots in the block diagonal matrix D.","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"The second choice of method finds factors A = P L U Q of the rectangular matrix A using the GALAHAD package ULS. In this case, dependencies in A will be reflected in zero diagonal entries in U in exact arithmetic.","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"The factorization in either case may also be used to determine whether the system is consistent.","category":"page"},{"location":"fdc/#Call-order","page":"fdc","title":"Call order","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"To solve a given problem, functions from the fdc package must be called in the following order:","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"fdc_initialize - provide default control parameters and","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"set up initial data structures","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"fdc_read_specfile (optional) - override control values","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"by reading replacement values from a file","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"fdcfinddependent_rows - find the number of dependent","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"rows and, if there are any, whether the constraints are independent","category":"page"},{"location":"fdc/","page":"fdc","title":"fdc","text":"fdc_terminate - deallocate data structures","category":"page"},{"location":"fdc/#fdc*array*indexing-Array-indexing","page":"fdc","title":"fdcarrayindexing Array indexing","text":"","category":"section"},{"location":"fdc/","page":"fdc","title":"fdc","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; add 1 to input integer arrays if fortran-style indexing is used, and beware that return integer arrays will adhere to this.","category":"page"},{"location":"ir/#Introduction","page":"ir","title":"Introduction","text":"","category":"section"},{"location":"ir/#sls_purpose-Purpose","page":"ir","title":"sls_purpose Purpose","text":"","category":"section"},{"location":"ir/","page":"ir","title":"ir","text":"Given a sparse symmetric n times n matrix A = a_ij and the factorization of A found by the GALAHAD package SLS, this package ** solves the system of linear equations A x = b using iterative refinement.**","category":"page"},{"location":"ir/","page":"ir","title":"ir","text":"Currently, only the control and inform parameters are exposed; these are provided and used by other GALAHAD packages with C interfaces.","category":"page"},{"location":"ir/#Authors","page":"ir","title":"Authors","text":"","category":"section"},{"location":"ir/","page":"ir","title":"ir","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"ir/","page":"ir","title":"ir","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"ir/","page":"ir","title":"ir","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"ir/#Originally-released","page":"ir","title":"Originally released","text":"","category":"section"},{"location":"ir/","page":"ir","title":"ir","text":"October 2008, C interface January 2022","category":"page"},{"location":"bqpb/#Introduction","page":"bqpb","title":"Introduction","text":"","category":"section"},{"location":"bqpb/#Purpose","page":"bqpb","title":"Purpose","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"This package uses a primal-dual interior-point method to solve the convex quadratic programming problem \\mbox{minimize}\\;\\; q(x) = \\frac{1}{2} x^T H x + g^T x + f $ \\n minimize q(x) := 1/2 x^T H x + g^T x + f \\n or the shifted least-distance problem \\mbox{minimize}\\;\\; \\frac{1}{2} \\sum{j=1}^n wj^2 ( xj - xj^0 )^2","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"g^T x + f $","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"\\n  minimize 1/2 \\sum{j=1}^n wj^2 ( xj - xj^0 )^2+ g^T x + f \\n subject to the simple bound constraints x_j^lleqx_j leq x_j^u  j = 1 ldots  n \\n  xj^l [<=] xj [<=] xj^u, j = 1, ... , n, \\n where the n by n symmetric, positive-semi-definite matrix H, the vectors g, w, x^0, x^l,x^u and the scalar f are given. Any of the constraint bounds xj^l$ and x_j^u may be infinite. Full advantage is taken of any zero coefficients in the matrix H.","category":"page"},{"location":"bqpb/#Authors","page":"bqpb","title":"Authors","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"bqpb/#Originally-released","page":"bqpb","title":"Originally released","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"July 2021, C interface December 2021.","category":"page"},{"location":"bqpb/#Method","page":"bqpb","title":"Method","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The required solution x necessarily satisfies the primal optimality conditions mbox(1) hspace52mm x^l leq x leq x^uhspace52mm} $ \\n (1) x^l [<=] x [<=] x^u, \\n the dual optimality conditions mbox(2a) hspace3mm H x + g = z  (mboxor W^2 (x -x^0) + g = z  mboxfor the shifted-least-distance type objective)}$ \\n (2a) H x + g = z  (or W^2 (x -x^0) + g = z for the shifted-least-distance type objective) \\n where mbox(2b) hspace24mm z = z^l + z^u   z^l geq 0  mboxand  z^u leq 0hspace24mm} $ \\n  (2b) z = z^l + z^u, z^l [>=] 0 and z^u [<=] 0, \\n and the complementary slackness conditions mbox(3) hspace12mm (x -x^l )^T z^l = 0 mboxand  (x -x^u )^T z^u = 0hspace12mm  \\n (3) (x -x^l)^T z^l = 0 and (x -x^u)^T z^u = 0, \\n where the diagonal matrix W^2 has diagonal entries w_j^2, j = 1 ldots  n, where the vector z is known as the dual variables for the bounds, respectively, and where the vector inequalities hold component-wise.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Primal-dual interior point methods iterate towards a point that satisfies these conditions by ultimately aiming to satisfy (2a) and (3), while ensuring that (1) and (2b) are satisfied as strict inequalities at each stage.Appropriate norms of the amounts bywhich (2a) and (3) fail to be satisfied are known as the primal and dual infeasibility, and the violation of complementary slackness, respectively. The fact that (1) and (2b) are satisfied as strict inequalities gives such methods their other title, namely interior-point methods.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The method aims at each stage to reduce the overall violation of (2a) and (3), rather than reducing each of the terms individually. Given an estimate v = (x c z z^l z^u) of the primal-dual variables, a correction Delta v = Delta (x c z z^l z^u) is obtained by solving a suitable linear system of Newton equations for the nonlinear systems (2a) and a parameterized “residual trajectory” perturbation of (3); residual trajectories proposed by Zhang (1994) and Zhao and Sun (1999) are possibilities. An improved estimate v + alpha Delta v is then used, where the step-size alpha is chosen as close to 1.0 as possible while ensuring both that (1) and (2b) continue to hold and that the individual components which make up the complementary slackness (3) do not deviate too significantly from their average value. The parameter that controls the perturbation of (3) is ultimately driven to zero.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The Newton equations are solved by applying the GALAHAD matrix factorization package SBLS, but there are options to factorize the matrix as a whole (the so-called \"augmented system\" approach), to perform a block elimination first (the \"Schur-complement\" approach), or to let the method itself decide which of the two previous options is more appropriate.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The package is actually just a front-end to the more-sophisticated GALAHAD package CQP that saves users from setting unnecessary arguments.","category":"page"},{"location":"bqpb/#Reference","page":"bqpb","title":"Reference","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The basic algorithm is a generalisation of those of","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Y. Zhang (1994),  On the convergence of a class of infeasible interior-point methods for the  horizontal linear complementarity problem,  SIAM J. Optimization 4(1) 208-227,","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"and","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"G. Zhao and J. Sun (1999). On the rate of local convergence of high-order infeasible path-following algorithms for the P_ast linear complementarity problems, Computational Optimization and Applications 14(1) 293-307,","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"with many enhancements described by","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"N. I. M. Gould, D. Orban and D. P. Robinson (2013). Trajectory-following methods for large-scaledegenerate convex quadratic programming, Mathematical Programming Computation 5(2) 113-142.","category":"page"},{"location":"bqpb/#Call-order","page":"bqpb","title":"Call order","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"To solve a given problem, functions from the bqpb package must be called in the following order:","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_initialize - provide default control parameters and","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"set up initial data structures","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_read_specfile (optional) - override control values","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"by reading replacement values from a file","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_import - set up problem data structures and fixed","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"values","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_reset_control (optional) - possibly change control","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"solve the problem by calling one of\nbqpb_solve_qp - solve the bound-constrained","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"quadratic program","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_solve_sldqp - solve the bound-constrained","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"shifted least-distance problem","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_information (optional) - recover information about","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"the solution and solution process","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"bqpb_terminate - deallocate data structures","category":"page"},{"location":"bqpb/#Symmetric-matrix-storage-formats","page":"bqpb","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The symmetric n by n objective Hessian matrix H may be presented and stored in a variety of convenient formats. But crucially symmetry is exploitedby only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"bqpb/#Dense-storage-format","page":"bqpb","title":"Dense storage format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part h_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value h{ij}$ (and, by symmetry, h_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"bqpb/#Sparse-co-ordinate-storage-format","page":"bqpb","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"bqpb/#Sparse-row-wise-storage-format","page":"bqpb","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values h_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"},{"location":"bqpb/#symmetric_matrix_diagonal-Diagonal-storage-format","page":"bqpb","title":"symmetric_matrix_diagonal Diagonal storage format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"If H is diagonal (i.e., H_ij = 0 for all 0 leq i neq j leq n-1) only the diagonals entries H_ii, 0 leq i leq n-1 need be stored, and the first n components of the array H_val may be used for the purpose.","category":"page"},{"location":"bqpb/#symmetric_matrix*scaled*identity-Multiples-of-the-identity-storage-format","page":"bqpb","title":"symmetric_matrixscaledidentity Multiples of the identity storage format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"If H is a multiple of the identity matrix, (i.e., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val.","category":"page"},{"location":"bqpb/#symmetric_matrix_identity-The-identity-matrix-format","page":"bqpb","title":"symmetric_matrix_identity The identity matrix format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"If H is the identity matrix, no values need be stored.","category":"page"},{"location":"bqpb/#symmetric_matrix_zero-The-zero-matrix-format","page":"bqpb","title":"symmetric_matrix_zero The zero matrix format","text":"","category":"section"},{"location":"bqpb/","page":"bqpb","title":"bqpb","text":"The same is true if H is the zero matrix.","category":"page"},{"location":"lstr/#Introduction","page":"lstr","title":"Introduction","text":"","category":"section"},{"location":"lstr/#Purpose","page":"lstr","title":"Purpose","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"Given a real m by n matrix A, a real m vector b and a scalar Delta0, this package finds an ** approximate minimizer of  A x - b_2, where the vector x is required to satisfy the “trust-region” constraint x_2 leqDelta.** This problem commonly occurs as a trust-region subproblem in nonlinear optimization calculations, and may be used to regularize the solution of under-determined or ill-conditioned linear least-squares problems. The method may be suitable for large m and/or n as no factorization involving A is required. Reverse communication is used to obtain matrix-vector products of the form u + A v and v + A^T u.","category":"page"},{"location":"lstr/#Authors","page":"lstr","title":"Authors","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"lstr/#Originally-released","page":"lstr","title":"Originally released","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"November 2007, C interface December 2021.","category":"page"},{"location":"lstr/#Terminology","page":"lstr","title":"Terminology","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"The required solution x necessarily satisfies the optimality condition A^T ( A x - b ) + lambda x = 0, where lambda geq 0 is a Lagrange multiplier corresponding to the trust-region constraint x_2leqDelta.","category":"page"},{"location":"lstr/#Method","page":"lstr","title":"Method","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"The method is iterative. Startingwith the vector u_1 = b, a bi-diagonalisation process is used to generate the vectors v_k and u_k+1 so that the n by k matrix V_k = ( v_1 ldots v_k) and the m by (k+1) matrix U_k = ( u_1 ldots u_k+1) together satisfy A V_k = U_k+1 B_k mboxand b = b U_k+1 e_1 \\n  A Vk = U{k+1} Bk and b = ||b|| U{k+1} e1, \\n where Bk$ is (k+1) by k and lower bi-diagonal, U_k and V_k have orthonormal columns and e_1 is the first unit vector. The solution sought is of the form x_k = V_k y_k, where y_k solves the bi-diagonal least-squares trust-region problem (1)  min  B_k y - b e_1 _2 mboxsubject to y_2 leq Delta \\n  (1)min || Bk y - \\|b\\| e1 ||2 subject to ||y||2 <= Delta. \\n","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"If the trust-region constraint is inactive, the solution y_k may be found, albeit indirectly, via the LSQR algorithm of Paige and Saunders which solves the bi-diagonal least-squares problem $ \\min \\| Bk y - \\|b\\| e1 \\|2$ \\n  min || Bk y - ||b|| e1 ||2 \\n using a QR factorization of B_k. Only the most recent v_k and u_k+1 are required, and their predecessors discarded, to compute x_k from x_k-1. This method has the important property that the iterates y (and thus x_k) generated increase in norm with k. Thus as soon as an LSQR iterate lies outside the trust-region, the required solution to (1) and thus to the original problem must lie on the boundary of the trust-region.","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"If the solution is so constrained, the simplest strategy is to interpolate the last interior iterate with the newly discovered exterior one to find the boundary point–-the so-called Steihaug-Toint point–-between them. Once the solution is known to lie on the trust-region boundary, further improvement may be made by solving $ \\min \\| Bk y - \\|b\\| e1 \\|2 \\;\\mbox{subject to}\\;|\\|y\\|2 = \\Delta,$ \\n  min || Bk y - ||b|| e1 ||2 subject to ||y||2 = Delta, \\n for which the optimality conditions require that y_k = y(lambda_k) where lambda_k is the positive root of B_k^T ( B_k^ y(lambda) - b e_1^ ) + lambday(lambda) = 0 mboxandy(lambda)_2 = Delta \\n Bk^T ( Bk y(lambda) - ||b|| e1 ) + lambda y(lambda) = 0 and ||y(lambda)||2 = Delta \\n The vector y(lambda) is equivalently the solution to the regularized least-squares problem minleft  vect B_k  lambda^frac12 I  y - b e_1^ right  \\n min||Bk y - ||b|| e1 ||  ||lambda^{1/2} y|| \\n and may be found efficiently. Giveny(lambda), Newton's method is then used to find lambda_k as the positive root of y(lambda)_2 = Delta. Unfortunately, unlike when the solution lies in the interior of the trust-region, it is not known how to recur x_k from x_k-1 given y_k, and a second pass in which x_k = V_k y_k is regenerated is needed–-this need only be done once x_k has implicitly deemed to be sufficiently close to optimality. As this second pass is an additional expense, a record is kept of the optimal objective function values for each value of k, and the second pass is only performed so far as to ensure a given fraction of the final optimal objective value. Large savings may be made in the second pass by choosing the required fraction to be significantly smaller than one.","category":"page"},{"location":"lstr/#Reference","page":"lstr","title":"Reference","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"A complete description of the unconstrained case is given by","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"C. C. Paige and M. A. Saunders, LSQR: an algorithm for sparse linear equations and sparse leastsquares. ACM Transactions on Mathematical Software, 8(1):43–71, 1982","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"and","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"C. C. Paige and M. A. Saunders, ALGORITHM 583: LSQR: an algorithm for sparse linear equations and sparse least squares. ACM Transactions on Mathematical Software, 8(2):195–209, 1982.","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"Additional details on how to proceed once the trust-region constraint is encountered are described in detail in","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"C. Cartis, N. I. M. Gould and Ph. L. Toint, Trust-region and other regularisation of linear least-squares problems. BIT 49(1):21-53 (2009).","category":"page"},{"location":"lstr/#Call-order","page":"lstr","title":"Call order","text":"","category":"section"},{"location":"lstr/","page":"lstr","title":"lstr","text":"To solve a given problem, functions from the lstr package must be called in the following order:","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_initialize - provide default control parameters and","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"set up initial data structures","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_read_specfile (optional) - override control values","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"by reading replacement values from a file","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_import_control - import control parameters prior to","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"solution","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_solve_problem - solve the problem by reverse","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"communication, a sequence of calls are made under control of a status parameter, each exit either asks the user to provide additional informaton and to re-enter, or reports that either the solution has been found or that an error has occurred","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_information (optional) - recover information about","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"the solution and solution process","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"lstr_terminate - deallocate data structures","category":"page"},{"location":"lstr/","page":"lstr","title":"lstr","text":"See Section~\\ref{examples} for an example of use. See the <a href=\"examples.html\">examples tab</a> for an illustration of use. See the examples section for an illustration of use.","category":"page"},{"location":"rpd/#Introduction","page":"rpd","title":"Introduction","text":"","category":"section"},{"location":"rpd/#Purpose","page":"rpd","title":"Purpose","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Read and write data for the linear program (LP) mboxminimize g^T x + f mboxsubject to c_l leq A x leq c_u mboxand x_l leqxleq x_u  n minimize g^T x + f  subject toc_l = A x = c_u  x_l =x= x_u n  the linear program with quadratic constraints (QCP) mboxminimize g^T x + f mboxsubject to c_l leq A x + frac12 mboxvec(xH_cx) leq c_u mboxand x_l leqxleq x_u  n minimize g^T x + f  subject toc_l = A x + 12 vec(xH_cx) = c_u  x_l =x= x_u n  the bound-constrained quadratic program (BQP) mboxminimize frac12 x^T H x + g^T x + f mboxsubject to x_l leqxleq x_u  n  minimize 12 x^T H x + g^T x + f  subject to x_l =x= x_u n  the quadratic program (QP) mboxminimize frac12 x^T H x + g^T x + f mboxsubject to c_l leq A x leq c_u mboxand x_l leqxleq x_u  n  minimize12 x^T H x + g^T x + f  subject toc_l = A x = c_u  x_l =x= x_u n  or the quadratic program with quadratic constraints (QCQP) mboxminimize frac12 x^T H x + g^T x + f mboxsubject to c_l leq A x + frac12 mboxvec(xH_cx) leq c_u mboxand x_l leqxleq x_u  n minimize 12 x^T H x + g^T x + f  subject toc_l = A x + 12 vec(xH_cx) = c_u  x_l =x= x_u n  where vec( x . Hc . x )$ is the vector whose  i-th component isx^T (Hc)_i x$ for the i-th  constraint, from and to a QPLIB-format data file.  Variables may be continuous, binary or integer.","category":"page"},{"location":"rpd/#Authors","page":"rpd","title":"Authors","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"rpd/#Originally-released","page":"rpd","title":"Originally released","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"January 2006, C interface January 2022.","category":"page"},{"location":"rpd/#Reference","page":"rpd","title":"Reference","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"The QPBLIB format is defined in","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"F. Furini, E. Traversi, P. Belotti, A. Frangioni, A. Gleixner, N. Gould, L. Liberti, A. Lodi, R. Misener, H. Mittelmann, N. V. Sahinidis, S. Vigerske and A. Wiegele(2019). QPLIB: a library of quadratic programming instances, Mathematical Programming Computation 11 237–265.","category":"page"},{"location":"rpd/#Call-order","page":"rpd","title":"Call order","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"To decode a given QPLIB file, functions from the rpd package must be called in the following order:","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpd_initialize - provide default control parameters and","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"set up initial data structures","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpdgetstats - read a given QPLIB file into internal","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"data structures, and report vital statistics","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"(optionally, and in any order, where relevant)\nrpdgetg - get the objective gradient term g\nrpdgetf - get the objective constant term f\nrpdgetxlu - get the variable bounds","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"x_l and x_u","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpdgetxlu - get the constraint bounds","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"c_l","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"and c_u","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpdgeth - get the objective Hessian term H\nrpdgeta - get the constrain Jacobian term A\nrpdgethc - get the constraint Hessian terms Hc$\nrpdgetx_type - determine the type of each variable","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"x","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpdgetx - get initial value of the variable x\nrpdgety - get initial value of Lagrange multipliers","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"y","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpdgetz - get initial value of the dual variables","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"z","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"rpd_terminate - deallocate data structures","category":"page"},{"location":"rpd/#Sparse-unsymmetric-co-ordinate-storage-format","page":"rpd","title":"Sparse unsymmetric co-ordinate storage format","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"The unsymmetric m by n constraint matrix A will be output in sparse co-ordinate format.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of A, its row index i, column index j and value A_ij, 0 leq i leq m-1,0 leq j leq n-1,are stored as the l-th components of the integer arrays Arow and Acol and real array Aval, respectively, while the number of nonzeros is recorded as Ane = ne.","category":"page"},{"location":"rpd/#Sparse-symmetric-co-ordinate-storage-format","page":"rpd","title":"Sparse symmetric co-ordinate storage format","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Likewise, the symmetric n by n objective Hessian matrix H will be returned in a sparse co-ordinate format. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value h_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"rpd/#joint_-Joint-sparse-symmetric-co-ordinate-storage-format","page":"rpd","title":"joint_ Joint sparse symmetric co-ordinate storage format","text":"","category":"section"},{"location":"rpd/","page":"rpd","title":"rpd","text":"The symmetric n by n constraint Hessian matrices $ (Hc)i$ are stored as a whole in a joint symmetric co-ordinate storage format. In addition to the row and column indices and values of each lower triangular matrix, record is also kept of the particular constraint invlved.","category":"page"},{"location":"rpd/","page":"rpd","title":"rpd","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its constraint index k, row index i, column index j and value (h_k)_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hcptr, Hcrow and Hccol and real array Hcval, respectively, while the number of nonzeros is recorded as Hcne = ne. Note as before that only the entries in the lower triangles should be stored.","category":"page"},{"location":"trb/#Introduction","page":"trb","title":"Introduction","text":"","category":"section"},{"location":"trb/#Purpose","page":"trb","title":"Purpose","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"The trb package uses a trust-region method to find a (local)  minimizer of a differentiable objective function mathbff(x) of many variables mathbfx, where the variables satisfy the simple bounds mathbfx^l leq x leq x^u. The method offers the choice of direct and iterative solution of the key subproblems, and is most suitable for large problems. First derivatives are required, and if second derivatives can be calculated, they will be exploited–-if the product of second derivatives with a vector may be found but not the derivatives themselves, that may also be exploited.","category":"page"},{"location":"trb/#Authors","page":"trb","title":"Authors","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"N. I. M. Gould, STFC-Rutherford Appleton Laboratory, England.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"C interface, additionally J. Fowkes, STFC-Rutherford Appleton Laboratory.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"Julia interface, additionally A. Montoison and D. Orban, Polytechnique Montréal.","category":"page"},{"location":"trb/#Originally-released","page":"trb","title":"Originally released","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"July 2021, C interface August 2021.","category":"page"},{"location":"trb/#Terminology","page":"trb","title":"Terminology","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"The gradient nabla_x f(x) of f(x) is the vector whose i-th component is partial f(x)partial x_i. The Hessian nabla_xx f(x) of f(x) is the symmetric matrix whose ij-th entry is partial^2 f(x)partial x_i partial x_j. The Hessian is sparse if a significant and useful proportion of the entries are universally zero.","category":"page"},{"location":"trb/#Method","page":"trb","title":"Method","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"A trust-region method is used. In this, an improvement to a current estimate of the required minimizer, x_k is sought by computing a step s_k. The step is chosen to approximately minimize a model m_k(s) of  f(x_k + s) within the intersection of the boundconstraints x^l leq x leq x^u and a trust region s_k leq Delta_k for some specified positive \"radius\" Delta_k. The quality of the resulting step s_k is assessed by computing the \"ratio\" (f(x_k) - f(x_k + s_k)) (m_k(0) - m_k(s_k)). The step is deemed to have succeeded if the ratio exceeds a given eta_s  0, and in this case x_k+1 = x_k + s_k. Otherwise x_k+1 = x_k, and the radius is reduced by powers of a given reduction factor until it is smaller than s_k. If the ratio is larger thaneta_v geq eta_d, the radius will be increased so that it exceeds s_k by a given increase factor. The method will terminate as soon as nabla_x f(x_k) is smaller than a specified value.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"Either linear or quadratic models m_k(s) may be used. The former will be taken as the first two terms f(x_k) + s^T nabla_x f(x_k) of a Taylor series about x_k, while the latter uses an approximation to the first three terms f(x_k) + s^T nabla_x f(x_k) + frac12 s^T B_k s, for which B_k is a symmetric approximation to the Hessian nabla_xxf(x_k); possible approximations include the true Hessian, limited-memory secant and sparsity approximations and a scaled identity matrix. Normally a two-norm trust region will be used, but this may change if preconditioning is employed.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"The model minimization is carried out in two stages. Firstly, the so-called generalized Cauchy point for the quadratic subproblem is found–-the purpose of this point is to ensure that the algorithm converges and that the set of bounds which are satisfied as equations at the solution is rapidly identified.Thereafter an improvement to the quadratic model on the face of variables predicted to be active by the Cauchy point is sought using either a direct approach involving factorization or an iterative (conjugate-gradient/Lanczos) approach based on approximations to the required solution from a so-called Krlov subspace. The direct approach is based on the knowledge that the required solution satisfies the linear system of equations (B_k + lambda_k I) s_k= - nabla_x f(x_k), involving a scalar Lagrange multiplier lambda_k, on the space of inactive variables. This multiplier is found by uni-variate root finding, using a safeguarded Newton-like process, by the GALAHAD package TRS. The iterative approach uses GALAHAD package GLTR, and is best accelerated by preconditioning with good approximations to B_k using GALAHAD's PSLS. The iterative approach has the advantage that only matrix-vector products B_k v are required, and thus B_k is not required explicitly. However when factorizations of B_k are possible, the direct approach is often more efficient.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"The iteration is terminated as soon as the Euclidean norm of the projected gradient, min(max( x_k - nabla_x f(x_k) x^l) x^u) -x_k_2 is sufficiently small. At such a point, nabla_x f(x_k) = z_k, where the i-th dual variable z_i is non-negative if x_i is on its lower bound x^l_i, non-positive if x_i is on its upper bound x^u_i, and zero if x_i lies strictly between its bounds.","category":"page"},{"location":"trb/#References","page":"trb","title":"References","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"The generic bound-constrained trust-region method is described in detail in","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"A. R. Conn, N. I. M. Gould and Ph. L. Toint, \"Trust-region methods\", SIAM/MPS Series on Optimization (2000).","category":"page"},{"location":"trb/#Call-order","page":"trb","title":"Call order","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"To solve a given problem, functions from the trb package must be called in the following order:","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_initialize - provide default control parameters and","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"set up initial data structures","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_read_specfile (optional) - override control values","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"by reading replacement values from a file","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_import - set up problem data structures and fixed","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"values","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_reset_control (optional) - possibly change control","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"parameters if a sequence of problems are being solved","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"solve the problem by calling one of\ntrb_solve_with_mat - solve using function calls to","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"evaluate function, gradient and Hessian values","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_solve_without_mat - solve using function calls to","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"evaluate function and gradient values and Hessian-vector products","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_solve_reverse_with_mat - solve returning to the","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"calling program to obtain function, gradient and Hessian values, or","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_solve_reverse_without_mat - solve returning to the","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"calling prorgram to obtain function and gradient values and  Hessian-vector products","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_information (optional) - recover information about","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"the solution and solution process","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"trb_terminate - deallocate data structures","category":"page"},{"location":"trb/#Symmetric-matrix-storage-formats","page":"trb","title":"Symmetric matrix storage formats","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"The symmetric n by n matrix H = nabla_xxf may be presented and stored in a variety of formats. But crucially symmetry is exploited by only storing values from the lower triangular part (i.e, those entries that lie on or below the leading diagonal).","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"Both C-style (0 based)and fortran-style (1-based) indexing is allowed. Choose control.f_indexing as false for C style and true for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version.","category":"page"},{"location":"trb/","page":"trb","title":"trb","text":"Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing.","category":"page"},{"location":"trb/#Dense-storage-format","page":"trb","title":"Dense storage format","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"The matrix H is stored as a compactdense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array. Since H is symmetric, only the lower triangular part (that is the part H_ij for 0 leq j leq i leq n-1) need be held. In this case the lower triangle should be stored by rows, that is component i ast i  2 + jof the storage array Hval will hold the value H{ij}$ (and, by symmetry, H_ji) for 0 leq j leq i leq n-1.","category":"page"},{"location":"trb/#Sparse-co-ordinate-storage-format","page":"trb","title":"Sparse co-ordinate storage format","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"Only the nonzero entries of the matrices are stored. For the l-th entry, 0 leq l leq ne-1, of H, its row index i, column index j and value H_ij, 0 leq j leq i leq n-1,are stored as the l-th components of the integer arrays Hrow and Hcol and real array Hval, respectively, while the number of nonzeros is recorded as Hne = ne. Note that only the entries in the lower triangle should be stored.","category":"page"},{"location":"trb/#Sparse-row-wise-storage-format","page":"trb","title":"Sparse row-wise storage format","text":"","category":"section"},{"location":"trb/","page":"trb","title":"trb","text":"Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1. For the i-th row of H the i-th component of the integer array Hptr holds the position of the first entry in this row, while Hptr(n) holds the total number of entries plus one. The column indices j, 0 leq j leq i, and values H_ij of theentries in the i-th row are stored in components l = Hptr(i), ldots, Hptr(i+1)-1 of the integer array Hcol, and real array Hval, respectively. Note that as before only the entries in the lower triangle should be stored. For sparse matrices, this scheme almost always requires less storage than its predecessor.","category":"page"}]
}
